{"meta":{"title":"blog","subtitle":"普普通通小码农的日常工作学习的一些粗俗浅显的记录。","description":"普普通通小码农的日常工作学习的一些粗俗浅显的记录。","author":"Qiong Qiong Woo","url":"https://qiongqiongwoo.github.io/blog"},"pages":[],"posts":[{"title":"redis","slug":"redis","date":"2020-11-04T14:08:15.000Z","updated":"2021-03-25T09:50:06.494Z","comments":true,"path":"2020/11/04/redis/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2020/11/04/redis/","excerpt":"","text":"1、redis为什么快Redis的qps可以达到10w/s，Redis将数据存储在内存中，读写操作不会因为磁盘的IO速度限制。基于内存的数据库和基于内存的数据库的区别： Redis是单进程单线程模型的kv数据库，由c语言编写，不比单进程多线程的基于内存的KV数据库memcached差。 Redis 6.0（redis的当前稳定版本：6.6）之后，开始支持使用多线程，可以通过设置进行设置，但默认是关闭的； 以前的版本的“单线程”(4.0之后)并非指所有的操作只有一个线程处理，而是处理用户请求的线程只有一个，像数据持久化等会有其他的线程处理; 高效的数据结构（后面会单独介绍）； redis一直使用单线程的官方回答：cpu不是制约性能的原因，它受限于内存和网络； redis的网络模型是epoll； 2、redis的数据结构redis命令不区分大小写，但redis的key值区分大小写的。 string 其中: embstr和raw都是由SDS动态字符串构成的。SDS结构ruxiatu : 123456789101112127.0.0.1:6389&gt; set name &quot;test&quot;OK127.0.0.1:6389&gt; get name&quot;test&quot;127.0.0.1:6389&gt; set age 11OK127.0.0.1:6389&gt; get age&quot;11&quot;127.0.0.1:6389&gt; incr age (incr 是原子操作，如果两个client同时操作，不需要考虑锁的问题，因此常用来做统计)(integer) 12127.0.0.1:6389&gt; get age&quot;12&quot; listziplist为连续的字节数组，每个元素的长度不同，结构如下。元素的结构为：quicklist是将ziplist和双向链表融合。 123456789101112131415127.0.0.1:6389&gt; lpush mylist 1(integer) 1127.0.0.1:6389&gt; lpush mylist &quot;a&quot;(integer) 2127.0.0.1:6389&gt; lrange mylist 0 -11) &quot;a&quot;2) &quot;1&quot;127.0.0.1:6389&gt; rpush mylist &quot;b&quot;(integer) 3127.0.0.1:6389&gt; lrange mylist 0 -1 （这个特性用来做翻页很方便）1) &quot;a&quot;2) &quot;1&quot;3) “b&quot;#list在实现上是链表，所以lpush和rpush在效率上是一致的，这样产生的弊端是元素的定位会慢一些；#list可以用来做消息队列，也可以用来存储博客或者商品的评论 set用hashtable实现时候，不关注value值。 12345678910111213141516171819127.0.0.1:6389&gt; sadd myset &quot;tooe&quot;(integer) 1127.0.0.1:6389&gt; sadd myset &quot;one&quot;(integer) 1127.0.0.1:6389&gt; SMEMBERS myset1) &quot;tooe&quot;2) &quot;one&quot;127.0.0.1:6389&gt; SISMEMBER myset &quot;one&quot;(integer) 1127.0.0.1:6389&gt; sadd myset2 1(integer) 1127.0.0.1:6389&gt; sadd myset2 2(integer) 1127.0.0.1:6389&gt; SUNION myset myset21) &quot;2&quot;2) &quot;1&quot;3) &quot;tooe&quot;4) “one&quot;# set 可以用来保存标签等信息 zset跳表是拿空间换时间，来优化链表的查询效率。 1234567891011121314127.0.0.1:6389&gt; zadd myzset 1 baidu.com(integer) 1127.0.0.1:6389&gt; zadd myzset 2 360.com(integer) 1127.0.0.1:6389&gt; zadd myzset 3 yahoo.com(integer) 1127.0.0.1:6389&gt; ZRANGE myzset 0 -1 WITHSCORES1) &quot;baidu.com&quot;2) &quot;1&quot;3) &quot;360.com&quot;4) &quot;2&quot;5) &quot;yahoo.com&quot;6) “3&quot;# 有序集合，比如用来存url的评分 hash redis中的hash在不满足ziplist的时候使用hashtable实现的。这类结构容易存在扩容的问题，redis用rehash来解决；即当hashtable中的元素个数大于数组长度时，就开始搬迁到h[1]，完成后，删除旧的。rehash的过程会插入到每次的插入、删除等操作中。 12345678910111213127.0.0.1:6389&gt; HMSET user:001 username aa passwd bb age 23OK127.0.0.1:6389&gt; HGETALL user:0011) &quot;username&quot;2) &quot;aa&quot;3) &quot;passwd&quot;4) &quot;bb&quot;5) &quot;age&quot;6) &quot;23&quot;127.0.0.1:6389&gt; HSET user:001 age 34(integer) 0127.0.0.1:6389&gt; HGET user:001 age&quot;34&quot; 3、redis集群主从架构（一主二从）单机的redis的qps最高只能达到10w+，如果要提高并发，可以使用集群；一主多从的支持10w+且支持水平扩容的，读写分离架构图： mater node一定要做数据持久化，并且冷备方案也要做； slave node 做复制的时候不会block对自己的查询操作；它会用旧的数据集来提供服务，但是复制完成，删除旧的数据集，加载新的数据集时会暂停对外服务； slave node 做复制时不会block master的正常工作； master和slave数据同步支持断点续传； slave node 用来做横向扩容，提供吞吐量； slave不会处理过期key，由master删除过期的key，然后同步del给slave；（slave也会scan过期的key进行处理） 主从数据复制有全量和部分两种方式，在redis2.8之前，每次slave启动，都会做数据的全量复制；在redis2.8之后，每次slave会传runid和offset，如果master发现runid和自己的runid一致且偏移量在缓存范围内，则执行部分复制； 主从会相互发送heartbeat信息，master默认是10s发送一次，slave是1秒发送一次； master向slave未同步完信息，直接down机会导致主从复制信息的丢失。 masterdown机后，会先根据最后同步时间过滤掉很久未同步的slave，然后优先选优先级最高的slave，其实是offset最大的slave，最终由投票选出slave升级为master 哨兵机制（一主二从三哨兵）单个slave挂掉不影响系统稳定性，如果master挂掉整个redis集群会down掉，解决方式是：哨兵机制sentinal；哨兵是一个独立的进程，监控多个redis实例；当master挂掉后会选举出一个新的master；当一个slave挂掉后会通知客户端；单个哨兵并不可靠，通常会设置三个哨兵；这样保证一个哨兵挂掉后还能进行redis的监控和主备切换；哨兵 + redis 主从的部署架构，是不会保证数据零丢失的，只能保证 redis 集群的高可用性。脑裂（master的假down机导致的）：解决方式是redis提供的两个配置，一方面组织客户端写入，一方面阻止新master的产生：min-slaves-to-write：这个配置项设置了主库能进行数据同步的最少从库数量；如果master和slave断开，他会拒绝客户端的写入请求；min-slaves-max-lag：这个配置项设置了主从库间进行数据复制时，从库给主库发送ACK消息的最大延迟（以秒为单位）。 客户端通过sentinel来连接redis，如下： 1234567891011121314151617181920212223242526from redis.sentinel import Sentineldef get_redis_conn_instance(self): conf &#x3D; &#123; &#39;sentinel&#39;: [(&#39;10.153.225.21&#39;, 26379), (&#39;10.153.224.16&#39;, 26379)], &#39;master_group_name&#39;: &#39;mymaster&#39;, &#39;connection_conf&#39;: &#123; &#39;socket_timeout&#39;: self.__conn_timeout, &#39;retry_on_timeout&#39;: True, &#39;socket_keepalive&#39;: True, &#39;max_connections&#39;: 100, &#39;db&#39;: 0, &#39;encoding&#39;: &#39;UTF-8&#39;, &#39;decode_responses&#39;: True, &#125; &#125; sentinel &#x3D; Sentinel(conf[&#39;sentinel&#39;], **conf[&#39;connection_conf&#39;]) sentinel.discover_master(conf[&#39;master_group_name&#39;]) redis_conn &#x3D; sentinel.master_for(conf[&#39;master_group_name&#39;]) try: redis_conn.ping() # 测试redis是否可达 self.__redis_conn &#x3D; redis_conn return True except redis.exceptions.ConnectionError: logging.exception(&quot;can not connection redis!&quot;) return False redis cluster主从架构只是解决了qps的问题，没有解决大的数据量的问题。主从架构的限制是master内存的大小。如果需要存储1T的数据，就需要对master进行扩容。即redis cluster: redis cluster = 多 master + 多slave + 高可用 主从架构：如果数据量很少，主要是承载高并发高性能的场景，比如缓存一般就几个G； redis cluster: 主要是针对海量数据+高并发+高可用的场景，比如海量数据； redis cluster采用无中心的架构，每个节点保存部分数据和整个集群状态,每个节点都和其他所有节点连接。节点之间通讯采用gossip协议。redis cluster采用的虚拟槽分区算法将数据分割到不同的节点。 上图所示，假设有三个缓存节点分别是 1、2、3。Redis Cluster 将存放缓存数据的槽（Slot）分别放入这三个节点中： 缓存节点1存放的是（0-5000）Slot 的数据 缓存节点2存放的是（5001-10000）Slot 的数据 缓存节点3存放的是（10000-16383）Slot 的数据 Redis Client需要根据一个 Key 获取对应的 Value 的数据的流程： 首先通过 CRC16(key)%16383 计算出Slot的值，假设计算的结果是5002。 将这个数据传送给 Redis Cluster，集群接收到以后会到一个对照表中查找这个 Slot=5002 属于那个缓存节点。 发现属于“缓存节点 2”，于是顺着红线的方向调用缓存节点 2 中存放的 Key-Value 的内容并且返回给 Redis Client。 cluster中的每个节点与其他节点通信时，会带上自己的节点信息和其他的节点信息。每个节点用bit的数组保存自己管理的槽信息，如下图，如果为1则表示节点保存该槽位信息。每个节点会保存一个clusterState结构来存储群居的节点信息： 在redis cluster集群中，salve节点不再提供读操作，读写都由master完成，slave节点仅仅为了提高可用性。 如果cluster master下的某个master没有了slave ，其他master中有多余的slave 的话，集群会自动slave迁移，这在生产环境中，适当的添加冗余的slave 实例，可以很大程度上提高集群的高可用性。 集群是去中心化的，任意一个master都可以对外提供读写操作； 集群无法保证强一致性； redis cluster的缺点： redis cluster 只是用db0； 对于mset、mget等mutl-key操作以及对事务的支持只能在一个slot上完场，即使同一个节点的多个slot之间也不能支持。 不能将一个很大的键映射到多个slot； master-slave架构只能是单层，不能是树形状；redis cluster proxyredis cluster proxy 是 redis 6.0新出现的集群代理。这个是独立于redis项目的。作用： 解决了跨节点mset，mget的问题。 自动路由，屏蔽master、slave的详细信息； 集群中遇到的问题 fork进程导致高并发请求延迟: 控制redis的内存在10G以内 aof阻塞问题：优化硬盘写入速度，比如用SSD 主从复制延迟问题：写监控脚本，超时就报警 主从复制风暴问题：master-slave不用星状结构，用树状结构； 4、redis持久化为什么要持久化redis持久化的意义在于故障恢复。redis有两种持久化备份的机制，RDB和AOF。 RDBRDB是每隔几分钟，生成一份完整的快照。 RDB的优点： 适合做冷备； 性能影响小，只需要主进程fork一个子进程定时做RDB持久化即可； 数据恢复快（相对于AOF），RDB直接将数据加载进内存即可；缺点： 故障时，丢的数据多。比如5分钟存一次，那最近五分钟的数据都会丢失；AOFAOF是每条写入命令作为日志更新到AOF文件中。每隔一秒会强制将os cache中的数据刷入到磁盘；AOF默认是关闭的，对应的配置在“append only mode”区，需要将appendonly改为yes;appendfsync为always虽然能保证不丢数据，但性能及差；通常设置为 everysec（单机可以达到上万qps）；由于AOF存放的是每条写入命令，所以会不断膨胀，当达到一定的大小时，会执行rewrite操作:即基于当前的redis内存，重新构造一个更小的aof文件，然后删除旧的aof文件。rewrite相关的配置： auto-aof-rewrite-percentage: 增长百分比，比上一次增长多少内容的时候就会触发rewrite操作； auto-aof-rewrite-min-size：超过该大小才会执 rewrite操作;AOF的优点： 故障时数据丢的少 AOF是append-only模式，数据丢的少缺点： 文件很大且只有一个，需要自己手动做备份； 性能稍低，因为AOF会是每秒fsync一次日志文件，会对性能造成影响。 数据恢复较慢，要一条条的执行命令；实操两种持久化机制都会将数据存到磁盘上，还应该定时将数据备份到别的地方，比如阿里云，boss等云服务。如果同时使用RDB和AOF，在redis重启时，会优先使用AOF来重新构造数据。一般来说都是用RDB做冷备，用AOF防止数据丢失；企业的数据备份方案：写crontab定时调度脚本去做数据备份： 小时级：每小时都copy一份rdb的备份，到一个目录中去，仅仅保留最近 48 小时的备份； 日级：每天都保留一份当日的 rdb 的备份，到一个目录中去，仅仅保留最近 1 个月的备份； 每天晚上将当前服务器上所有的数据备份，发送一份到远程的云服务上去；5、redis过期策略redis是基于内存的，内存有限制，所以会在数据达到一定的量之后将数据进行清理。 volatile-lru：设置了过期时间的key使用LRU算法淘汰； allkeys-lru：所有key使用LRU算法淘汰； volatile-lfu：设置了过期时间的key使用LFU算法淘汰； allkeys-lfu：所有key使用LFU算法淘汰； volatile-random：设置了过期时间的key使用随机淘汰； allkeys-random：所有key使用随机淘汰； volatile-ttl：设置了过期时间的key根据过期时间淘汰，越早过期越早淘汰； noeviction：默认策略，当内存达到设置的最大值时，所有申请内存的操作都会报错(如set,lpush等)，只读操作如get命令可以正常执行； redis中的lru是近似的，即随机选取N（5）个，从中选取访问时间最早的。 除了内存满的情况，redis的key过期也需要被清理。已过期未被访问的数据仍保持在内存中，消耗内存资源； 惰性删除：当key被访问时检查该key的过期时间，若已过期则删除； 定期删除：每隔一段时间，随机检查设置了过期的key并删除已过期的key；维护定时器消耗CPU资源； 在RDB和AOF持久化中都不会将过期的key带入持久化文件；6、redis多线程redis单线程处理流程 用户提交命令； 主线程获取socket； 主线程读取socket； 主线程解析并执行用户命令； 主线程回写socket； 用户获取响应数据；cpu处理是不耗费时间的，瓶颈在内存和网络IO：即主要耗时在主线程读取和回写socket；redis开始支持多线程的原因 redis的单线程可以达到8w-10w的qps，但有些场景下有上亿的交易量，qps要求更高； 常规的做法是利用分布式的架构进行数据分区，但这种方案的缺点是管理的redis服务器太多，维护成本大； redis因为是单线程，同一时刻只有一个线程在执行，耗时的操作会导致读写并发的下降； 分析redis的耗时，只要在网络IO上（cpu的耗时很低，不是瓶颈），提高网络IO，最简单的方式是多线程：即由多个IO线程来分摊redis同步IO的负荷；官方建议线程数要小于内核数量，比如4核机器设置2-3个线程，一旦超过8个线程，意义就已经不大； redis多线程的流程图 多线程是指一个主线程和多个IO线程； IO线程只负责socket数据的读写；一个线程要么是在读，要么是在写，不会既读又写； IO线程可以发挥多核的优势； 命令的执行还是由主线程执行，因此不会有并发的问题； redis多线程模型和memcached的区别 redis处理是在主线程中进行，解决了并发的问题； memcache是传统的master-worker模式，处理也是由worker线程处理，线程模型如下：7、其他redis 6.0新引入了ACl（访问控制权限），基于此功能可以设置多个用户，并且给多个用户单独设置命令权限和数据权限；redis 6.0引入了基于RESP3协议的客户端缓存。redis支持lua脚本，作用是减少网络开销，可复用，原子性。","categories":[{"name":"DataBase","slug":"DataBase","permalink":"https://qiongqiongwoo.github.io/blog/categories/DataBase/"}],"tags":[]},{"title":"MQ","slug":"MQ","date":"2020-10-18T13:29:12.000Z","updated":"2021-03-26T09:21:44.436Z","comments":true,"path":"2020/10/18/MQ/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2020/10/18/MQ/","excerpt":"","text":"MQ的作用：解耦、异步、削峰常见的MQ有rocketMQ（阿里参照kafka设计思想用java实现的一套mq）、RabbitMQ、redis（本身支持MQ的功能）、kafka 解耦比如A的信息需要同步给多个模块，一种实现是A中调用BCD甚至新加入的E的接口进行同步；如果同步的模块发生变化，A中逻辑就需要发生变化。用MQ实现为：A生产数据放入MQ，谁需要谁去消费；引入的问题是，需要保证MQ的高可用性。 异步对于比较耗时的操作，如下图：改为异步后，用户体验大幅度提升，但是也会引来不一致的问题，比如B模块操作完成，而C和D模块操作失败。 削峰用户请求暴增的情况下，可以用MQ起到一个缓冲的作用 。 redis和MQ的区别redis多用于实时性较高的消息推送，但并不保证可靠（不保证不丢数据）。MQ保证可靠，但是会有一些延迟。","categories":[{"name":"DataBase","slug":"DataBase","permalink":"https://qiongqiongwoo.github.io/blog/categories/DataBase/"}],"tags":[]},{"title":"网络模型","slug":"网络模型","date":"2020-10-11T09:24:27.000Z","updated":"2021-03-22T07:46:33.814Z","comments":true,"path":"2020/10/11/网络模型/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2020/10/11/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"注： IO分为磁盘IO和网络IO，以下所说的都是网络IO。 同步和异步、阻塞和非阻塞是独立的状态，同步不等于阻塞，异步不等于非阻塞； 同步和异步分为：网络模型的同步和异步、IO的同步和异步，这二者不同。 网络模型的同步和异步描述的是客户端和server端是同步交互还是异步交互。 IO的同步和异步是指用户线程和内核处理线程的同步和异步。 以下所说的同步和异步指的是IO的同步和异步；1、同步阻塞IO模型（BIO）同步阻塞模型在server端有单线程和多线程两种实现方式，方式都是建立连接后一直等到数据传输结束后才会释放连接；此处的阻塞是指是否等待数据传输（IO）时是否阻塞；单线程的处理流程为： 123456789while(1) &#123; fd &#x3D; accept(listen_fd) &#x2F;&#x2F; 判断是否有连接进来 fds.append(fd) for (fd in fds) &#123; if (recv(fd)) &#123; &#x2F;&#x2F; 阻塞等待数据传输，此处会影响上面accept接收连接 &#125; &#125; &#125; 多线程的处理流程为： 12345678910while(1) &#123; fd &#x3D; accept(listen_fd) &#x2F;&#x2F; 开启线程read数据（fd增多导致线程数增多） new Thread func() &#123; &#x2F;&#x2F; recv阻塞（多线程不影响上面的accept） if (recv(fd)) &#123; &#x2F;&#x2F; logic &#125; &#125; &#125; 此模型适用于连接数比较小的架构，100万个用户则需要100万个线程，而同时发生读写操作的线程数不超过20%，所以容易造成浪费； 2、同步非阻塞模型（NIO）为什么是单线程，没有多线程处理？因为：网络IO是非阻塞的，没必要开着线程处理。 12345678910111213141516171819202122setNonblocking(listen_fd)while(1) &#123; &#x2F;&#x2F; accept非阻塞（cpu一直忙轮询） client_fd &#x3D; accept(listen_fd) if (client_fd !&#x3D; null) &#123; &#x2F;&#x2F; 有人连接 fds.append(client_fd) &#125; else &#123; &#x2F;&#x2F; 无人连接 &#125; for (fd in fds) &#123; &#x2F;&#x2F; recv非阻塞， 此处只判断是否有数据，如果没有数据，直接返回，不阻塞 setNonblocking(client_fd) &#x2F;&#x2F; recv 为非阻塞命令 if (len &#x3D; recv(fd) &amp;&amp; len &gt; 0) &#123; &#x2F;&#x2F; 有读写数据 &#x2F;&#x2F; logic &#125; else &#123; 无读写数据 &#125; &#125; &#125; 3、IO多路复用模型通过一个线程专门管理客户端的连接，通过记录IO流的状态来管理多个IO，提高服务器的吞吐时间。多路：指的是多个网络连接（多个文件句柄），复用的是同一个io线程（即下图的控制线程）； IO多路复用模型的实现的三种方式有select、poll、epoll三种，整个过程只在调用select、poll、epoll的时候才会阻塞，accept/recv是不会阻塞。三者的区别如下： IO多路复用模型无论是select、poll还是epoll的实现方式下，都是由应用程序来做“拷贝数据”的，因此属于同步IO。 select的处理select的实现用的是三个bitmap，用来记录可读、可写和异常的fd。 123456789101112131415161718192021222324#include &lt;sys&#x2F;select.h&gt;#include &lt;sys&#x2F;time.h&gt;#define FD_SETSIZE 1024 # 此处限制了最大连接数为1024#define NFDBITS (8 * sizeof(unsigned long))#define __FDSET_LONGS (FD_SETSIZE&#x2F;NFDBITS)&#x2F;&#x2F; 数据结构 (bitmap)typedef struct &#123; unsigned long fds_bits[__FDSET_LONGS];&#125; fd_set;&#x2F;&#x2F; APIint select( int max_fd, fd_set *readset, fd_set *writeset, fd_set *exceptset, struct timeval *timeout) &#x2F;&#x2F; 返回值就绪描述符的数目FD_ZERO(int fd, fd_set* fds) &#x2F;&#x2F; 清空集合FD_SET(int fd, fd_set* fds) &#x2F;&#x2F; 将给定的描述符加入集合FD_ISSET(int fd, fd_set* fds) &#x2F;&#x2F; 判断指定描述符是否在集合中 FD_CLR(int fd, fd_set* fds) &#x2F;&#x2F; 将给定的描述符从文件中删除 select 系统调用是用来监视多个文件句柄的状态变化的。select函数原型如下：int select (int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); 函数的第一个参数是加集合的句柄值的最大值+1，而不是句柄数量+1。函数的最后一个参数timeout是一个超时时间值，其类型一个struct timeval结构的变量的指针。第2、3、4三个参数是一样的类型: fd_set* ，比如检测了三个socket，&amp;rdfds,&amp;wtfds,&amp;exfds这三个参数分别用来记录这三个socker中可读的、可写的、以及异常的fd。比如只想检测某个socket是否有数据可读，我们可以这样： 12345678910111213141516171819202122bind(listenfd);listen(listenfd);FD_ZERO(&amp;allset);FD_SET(listenfd, &amp;allset);for(;;)&#123; select(...); if (FD_ISSET(listenfd, &amp;rset)) &#123;&#x2F;*有新的客户端连接到来*&#x2F; clifd &#x3D; accept(); cliarray[] &#x3D; clifd; &#x2F;*保存新的连接套接字*&#x2F; FD_SET(clifd, &amp;allset);&#x2F;*将新的描述符加入监听数组中*&#x2F; &#125; for(;;) &#123;&#x2F;*这个for循环用来检查所有已经连接的客户端是否由数据可读写*&#x2F; fd &#x3D; cliarray[i]; if (FD_ISSET(fd , &amp;rset)) dosomething(); &#125;&#125; select的缺点为： 单个进程所打开的FD是有限制的，通过FD_SETSIZE设置，默认1024； 每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大； 对socket扫描时是线性扫描，采用轮询的方法，效率较低（高并发时）；poll的处理poll和select的区别是：poll用数组来存储FD，而不是bitmap，因此他没有了最大描述符1024的限制；其他和select相同；12345678910#include &lt;poll.h&gt;&#x2F;&#x2F; 数据结构struct pollfd &#123; int fd; &#x2F;&#x2F; 需要监视的文件描述符 short events; &#x2F;&#x2F; 需要内核监视的事件 short revents; &#x2F;&#x2F; 实际发生的事件&#125;;&#x2F;&#x2F; 用revent来判断一个fd发生了什么事件&#x2F;&#x2F; APIint poll(struct pollfd fds[], nfds_t nfds, int timeout); select/poll在接收到一个连接时，会通知内核（发生从用户态复制句柄到内核态度），让操作系统内核去查询这些套接字上是否有事件发生，轮询完后，内核将句柄数据复制到用户态，让服务器应用程序处理已经发生的网络事件，这轮询的过程资源消耗较大，因此，select/poll一般只能处理几千的并发连接。 epoll的处理epoll只能工作在linux下，epoll是基于双向链表和红黑树木来实现的。每一个epoll对象都有一个独立的eventpoll结构体。 123456struct eventpoll &#123; &#x2F;*红黑树的根节点，这颗树中存储着所有添加到epoll中的需要监控的事件*&#x2F; struct rb_root rbr; &#x2F;*双链表中则存放着将要通过epoll_wait返回给用户的满足条件的事件*&#x2F; struct list_head rdlist;&#125;; 在epoll中，每一个事件都会创建一个epitem的结构体 1234567struct epitem&#123; struct rb_node rbn; &#x2F;&#x2F; 红黑树节点 struct list_head rdllink; &#x2F;&#x2F; 双向链表节点 struct epoll_filefd ffd; &#x2F;&#x2F; 事件句柄信息 struct eventpoll *ep; &#x2F;&#x2F; 指向其所属的eventpoll对象 struct epoll_event event; &#x2F;&#x2F; 期待发生的事件类型&#125; epoll解决select的三个问题的方式：从api上可以看出，select，poll都是一个函数（每执行一次都会做一次fd的拷贝），epoll是三个函数：epoll_create, epoll_ctl和epoll_wait; epoll_create就是返回一个eventpoll的句柄； epoll_ctl是注册要监听的事件类型（即将fd插入到红黑树中，红黑树的插入效率是logn，n为树的高度），在这个函数中，会把所有的fd拷贝进内核，且只copy这一次，解决了重复copy的问题。 epoll_ctl还会对每一个fd注册一个回调函数，一旦有事件发生，会执行回调函数（即将就绪的fd放到双向链表中），epoll_wait是查看双向链表中是否有就绪的fd，解决了循环遍历的问题。 epoll支持的最大连接数是系统可以打开的文件数，在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max查看，这个值和内存大小有关。 linux2.6 之后使用了mmap技术，数据不在需要从内核复制到用户空间，零拷贝 epoll有EPOLLLT和EPOLLET两种触发模式，LT是默认的模式，ET是“高速”模式。 LT模式下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作。libevent、asio都是用的LT模式，因为简单。 ET模式下，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论fd中是否还有数据可读。所以在ET模式下，read一个fd的时候一定要把它的buffer读完，或者遇到EAGAIN错误。epoll在ET模型的使用示例如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157#include &lt;sys&#x2F;socket.h&gt;#include &lt;sys&#x2F;wait.h&gt;#include &lt;netinet&#x2F;in.h&gt;#include &lt;netinet&#x2F;tcp.h&gt;#include &lt;sys&#x2F;epoll.h&gt;#include &lt;sys&#x2F;sendfile.h&gt;#include &lt;sys&#x2F;stat.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;strings.h&gt;#include &lt;fcntl.h&gt;#include &lt;errno.h&gt; #define MAX_EVENTS 10#define PORT 8080&#x2F;&#x2F;设置socket连接为非阻塞模式void setnonblocking(int sockfd) &#123; int opts; opts &#x3D; fcntl(sockfd, F_GETFL); if(opts &lt; 0) &#123; perror(&quot;fcntl(F_GETFL)\\n&quot;); exit(1); &#125; opts &#x3D; (opts | O_NONBLOCK); if(fcntl(sockfd, F_SETFL, opts) &lt; 0) &#123; perror(&quot;fcntl(F_SETFL)\\n&quot;); exit(1); &#125;&#125;int main()&#123; struct epoll_event ev, events[MAX_EVENTS]; int addrlen, listenfd, conn_sock, nfds, epfd, fd, i, nread, n; struct sockaddr_in local, remote; char buf[BUFSIZ]; &#x2F;&#x2F;创建listen socket if( (listenfd &#x3D; socket(AF_INET, SOCK_STREAM, 0)) &lt; 0) &#123; perror(&quot;sockfd\\n&quot;); exit(1); &#125; setnonblocking(listenfd); bzero(&amp;local, sizeof(local)); local.sin_family &#x3D; AF_INET; local.sin_addr.s_addr &#x3D; htonl(INADDR_ANY);; local.sin_port &#x3D; htons(PORT); if( bind(listenfd, (struct sockaddr *) &amp;local, sizeof(local)) &lt; 0) &#123; perror(&quot;bind\\n&quot;); exit(1); &#125; listen(listenfd, 20);&#x2F;&#x2F;设置为监听描述符 epfd &#x3D; epoll_create(MAX_EVENTS); if (epfd &#x3D;&#x3D; -1) &#123; perror(&quot;epoll_create&quot;); exit(EXIT_FAILURE); &#125; ev.events &#x3D; EPOLLIN; ev.data.fd &#x3D; listenfd; if (epoll_ctl(epfd, EPOLL_CTL_ADD, listenfd, &amp;ev) &#x3D;&#x3D; -1) &#123; perror(&quot;epoll_ctl: listen_sock&quot;); exit(EXIT_FAILURE); &#125; for (;;) &#123; nfds &#x3D; epoll_wait(epfd, events, MAX_EVENTS, -1);&#x2F;&#x2F;超时时间-1，永久阻塞直到有事件发生 if (nfds &#x3D;&#x3D; -1) &#123; perror(&quot;epoll_pwait&quot;); exit(EXIT_FAILURE); &#125; for (i &#x3D; 0; i &lt; nfds; ++i) &#123; fd &#x3D; events[i].data.fd; if (fd &#x3D;&#x3D; listenfd) &#x2F;&#x2F;如果是监听的listenfd，那就是连接来了，保存来的所有连接 &#123; &#x2F;&#x2F;每次处理一个连接，while循环直到处理完所有的连接 while ((conn_sock &#x3D; accept(listenfd,(struct sockaddr *) &amp;remote, (size_t *)&amp;addrlen)) &gt; 0) &#123; setnonblocking(conn_sock); ev.events &#x3D; EPOLLIN | EPOLLET;&#x2F;&#x2F;边沿触发非阻塞模式 ev.data.fd &#x3D; conn_sock; &#x2F;&#x2F;把连接socket加入监听结构体 if (epoll_ctl(epfd, EPOLL_CTL_ADD, conn_sock, &amp;ev) &#x3D;&#x3D; -1) &#123; perror(&quot;epoll_ctl: add&quot;); exit(EXIT_FAILURE); &#125; &#125; &#x2F;&#x2F;已经处理完所有的连：accept返回-1，errno为EAGAIN &#x2F;&#x2F;出错：返回-1，errno另有其值 if (conn_sock &#x3D;&#x3D; -1) &#123; if (errno !&#x3D; EAGAIN &amp;&amp; errno !&#x3D; ECONNABORTED &amp;&amp; errno !&#x3D; EPROTO &amp;&amp; errno !&#x3D; EINTR) perror(&quot;accept&quot;); &#125; continue;&#x2F;&#x2F;继续循环，但是不执行该循环后面的部分 &#125; if (events[i].events &amp; EPOLLIN) &#x2F;&#x2F;可读事件 &#123; n &#x3D; 0; while ((nread &#x3D; read(fd, buf + n, BUFSIZ-1)) &gt; 0) &#123; n +&#x3D; nread; &#125; if (nread &#x3D;&#x3D; -1 &amp;&amp; errno !&#x3D; EAGAIN) &#123; perror(&quot;read error&quot;); &#125; ev.data.fd &#x3D; fd; ev.events &#x3D; events[i].events | EPOLLOUT; &#x2F;&#x2F;修改该fd监听事件类型，监测是否可写 if (epoll_ctl(epfd, EPOLL_CTL_MOD, fd, &amp;ev) &#x3D;&#x3D; -1) &#123; perror(&quot;epoll_ctl: mod&quot;); &#125; &#125; if (events[i].events &amp; EPOLLOUT) &#x2F;&#x2F;可写事件 &#123; sprintf(buf, &quot;HTTP&#x2F;1.1 200 OK\\r\\nContent-Length: %d\\r\\n\\r\\nHello World&quot;, 11); int nwrite, data_size &#x3D; strlen(buf); n &#x3D; data_size; while (n &gt; 0) &#123; nwrite &#x3D; write(fd, buf + data_size - n, n); if (nwrite &lt; n) &#123; if (nwrite &#x3D;&#x3D; -1 &amp;&amp; errno !&#x3D; EAGAIN) &#123; perror(&quot;write error&quot;); &#125; break; &#125; n -&#x3D; nwrite; &#125; &#x2F;&#x2F;写完就关闭该连接socket close(fd); &#125; &#125; &#125; return 0;&#125; 4、信号量模型信号量模型和异步IO的区别仅仅是：拷贝数据是由内核进程完成还是由应用程序完成。 5、异步IO如下图所示，应用程序完成系统调用后，就去处理其他事情了，一直等着内核通知数据”拷贝完成“（数据拷贝是内核进程完成的），二者属于异步IO。 6、Proactor 和 Reactorproactor和reactor是两种描述应用程序如何实现的架构设计，而不是网络模型。二者的区别： proactor是基于异步IO的的网络模型，reactor是基于多路复用Io的网络模型； Proactor不需要将数据从内核复制到用户空间，这一步是由系统完成的。 Reactorreactor是基于多路复用IO的网络模型，他将应用程序侧的接收连接和数据copy工作分成不同的线程来处理，从而优化IO阻塞的问题。工作线程的数量不同可以分为以下两种模式： 单线程+reactor：主线程负责接收连接，work线程负责处理请求； 多线程+reactor：主线程负责接收连接，每次从work线程池中取一个work来处理请求； Proactor 6、常见的几种网络模型实现redis和nginx的网络模型都是epoll；brpc的网络模型也是epoll；Netty是基于NIO实现的，server端的流程图如下：Netty客户端的流程图： 参考：https://juejin.cn/post/6892687008552976398","categories":[{"name":"网络","slug":"网络","permalink":"https://qiongqiongwoo.github.io/blog/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"matrix、docker、k8s的对应关系","slug":"matrix、docker、k8s的对应关系","date":"2020-08-17T13:03:15.000Z","updated":"2021-03-26T09:25:47.187Z","comments":true,"path":"2020/08/17/matrix、docker、k8s的对应关系/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2020/08/17/matrix%E3%80%81docker%E3%80%81k8s%E7%9A%84%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB/","excerpt":"","text":"1、matrix的生态 Matrix: 百度最早的容器调度系统，在2012年就已经发布，对应于docker， docker是在2013年开源。 solaria：索拉里，matrix上的服务托管系统，协助用户完成日常线上服务的运维工作。 normandy：构建与集群操作系统matrix之上，面向离线计算框架而设计的统一资源调度系统。 opera：可视化的基于matrix的容器管理平台；2、matrix中的概念 instance：Matrix中最小的运行单位是实例（Instance），一个Instance提交给Matrix，至少需要包含如下要素 实例名（Instance ID）：Instance ID = offset.Service Name 包（Package）：这个实例的可执行文件、配置、以及脚本等，按照特定规则（例如Archer规范）打出的压缩包（的远程源路径）。 资源需求（Resource）：实例在单机运行起来需要的资源，例如CPU需要2个core（归一化），内存需要40G，硬盘空间需要400M，网卡带宽需要10MB（还有硬盘IO等等，Matrix Team正在努力实现） 实例标记（Tag）：可以认为类比于传递给包的命令行参数，例如这个实例需要哪块数据等等，Tag通过K-V方式组织 container：一个Instance提交给Matrix，Matrix会根据资源需求选定一台服务器，建立资源容器（Container）将Instance启动在这个资源容器中。 一个Container中有且仅有一个Instance，Container的生命周期和Instance相同。 单机上各个资源容器相互之间有一定的隔离性，不会相互干扰。 除了提供资源隔离，Container还负责一些轻量级的虚拟化，以提高易用性，例如所有Instance都可以认为自己独占/home、/tmp目录（实际上Container作了虚拟）。 Service：是Matrix对OP的最小运维单位，上线/升级/回滚等都是以Service粒度完成。 一个Service不能跨Matrix集群，如果需要在多个机房（集群）部署，请分别提交不同的Service（例如BS.jx，BS.tc） Matrix概念上认为一些资源需求相同，包相同的实例组成一个Service，一个Service中各个实例按照 . 命名。 Matrix可以容忍短时间一个Service内各个实例资源/包层面不同（例如一个Service升级的过程中）。 Application:概念上，一组相关服务的DAG图组成一个应用，例如Nova应用可以包含AS/BS/CS/PFS/UFS等Service。 一个应用可以包含不同Matrix集群的Service。 当前Application的概念在Matrix中相当弱化，更多由应用自己考虑这一层的概念，后继不排除Marix会在这一层中提供一些高级功能，例如根据服务的依赖管理来自动管理应用。3、基于matrix的业务分层4、matrix生态和k8s生态的层级对比关系5、和k8s的功能对比：","categories":[{"name":"K8S","slug":"K8S","permalink":"https://qiongqiongwoo.github.io/blog/categories/K8S/"}],"tags":[]},{"title":"k8s&docker","slug":"k8s&docker","date":"2020-08-11T13:20:27.000Z","updated":"2021-03-22T07:47:33.524Z","comments":true,"path":"2020/08/11/k8s&docker/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2020/08/11/k8s&docker/","excerpt":"","text":"1、一个k8s集群中环境角色如下： 架构图为： 或者如图： 或者： 其中master的架构为：分层的架构： 从图中可以看出：一个kubenetes集群有一个master节点，和多个node节点；master组件： kube-apiserver：集群的统一入口，所有对象资源的增删改查都交给apiservice处理后，再转交给etcd进行存储，默认创建的命名空间的有default、kube-system、kube-public、kube-node-lease四个； kube-controller-manager：处理集群后台任务； kube-scheduler： 根据调度算法为新创建的pod选择一个合适的node；（挖资源） etcd: 分布式键值存储系统，用于保存集群状态数据，比如pod，service信息等；node组件： kubelet：node节点上的agent，管理本机运行容器的生命周期，比如创建容器，和master同步容器和pod状态等； kube-proxy：运行在node节点上的一个网络代理，用来做负载均衡和网络转发的，提供一个虚拟的ip，将多个pod上的服务以service的形式对外提供服务； flannel：是一套网络方案，使同机或者多台机器上pod通信成为可能； docker： 容器；2、kubenetes中的名词 namespace： 命名空间，是k8s在多个用户之间划分集群资源的一种方法；使用namespace可以做到在一个物理集群上划分多个虚拟的集群；namespace为集群中的pods、services和deployments提供了作用域； pod：最小的部署单元，一组容器的集合，容器共享网络命名空间 replicaSet：预期的pod副本数量 deployment： 无状态应用部署deployment并不直接管理pod，他是通过replicaSet来进行管理；三者关系如下： statefulset：有状态应用部署 heapster：做数据收集，收集每一个node下的（cpu、mem，filesystem等监控数据）， 他以pod的形式运行在kube-system下； kubectl：一个cli的命令行工具； helm： 是kubenetes的一个包管理器，想python的pip，centos的yum一样； K8s pod eviction策略： pod驱逐策略，也就是挖资源策略； Volumne: 卷，可以持久化的存储容器的资源；（容器销毁后，容器内的资源会被释放，可以通过volumen的形式保存下来）。volume的类型有emptyDir（空目录，pod销毁后volume的内容会丢失）、hostPath（将os上已经存在的目录映射到容器，pod销毁后volume的内容会保存下来）、外部存储（最常用，比如将bos、nfs、hdfs的文件mount到容器，这种方式将数据存储和k8s集群进行隔离，不考虑存储运维这是最好的volume的方式） headless service： 如果service定义时clusterIP定义为None，则为headless service。这类服务通过dns返回的是pod的列表，而不是clusterip。这类服务应用的场景：客户端来做负载均衡的情况或者pod之间需要相互访问的情况（因为没有clusterip，每一个pod会有一个dns，保证了pod之间可以相互访问）；3、docker3.1 docker容器技术对于计算机界好比与集装箱之于运输业；3.2 docker的作用： 环境的一致性：可以保证从开发到测试部署整个过程使用同一个环境，提高开发效率； 多平台兼容性：docker服务可以在任意有docker环境的平台部署； 隔离性：docker容器是隔离的，可以解耦依赖关系，方便弹性扩展；3.3 docker是一个c/s的服务： docker仓库：存储所有的docker镜像； docker镜像：一个docker镜像对应一个docker服务； docker容器：启动的一个docker镜像； docker宿主机：任意一台装有docker环境的服务器，可以pull、push、启动、停止一个docker服务； docker客户端：docker client命令工具； 3.4 DockerfileDockerfile是生成image的源文件，Dockerfile有自己的语法： FROM：基于哪个docker image 来生成； COPY：将当前目录的某文件copy到镜像的什么位置 EXPOSE：对外提供什么端口服务； CMD：容器启动时应该跑什么脚本；3.5 docker 常用问题： 拉取的镜像默认在/var/lib/docker下（var盘容易慢，可以指定到其他的目录） 镜像如果不指定tag，默认tag为latest； 镜像如果删不掉可以用-f，或者删除依赖的父镜像后再删除； docker的三大技术支柱： cgroup：使得资源限制成为可能； namspace：内核级别的资源隔离方式； AUFS：advanced multilayered unificationfile system3.6 docker常用的命令：1234567891011* docker pull：拉取镜像* docker images ：列举当前的docker 镜像* docker rmi 删除某个镜像* docker built -t [name]:[tag] [dockerfile path] : 用本地的dockerfile构建一个镜像；* docker push ： 镜像推送到仓库* docker run -it bin&#x2F;bash ： 运行镜像* docker ps： 查看运行中的镜像；* docker kill [容器id]：终止容器；* docker run -v host机的目录:docker实例内的目录 -p host主机的端口:映射后的端口* docker logs [container id]: 查看docker容器的日志;* docker exec -it [container id] bash: 容器内执行bash命令 4、docker、docker swarm &amp; k8s的关系 Docker swarm 是docker官方推出的容器调度服务平台； kubenetes的基础是docker容器；kubenetes解决的是容器的集群化编排和生命周期管理； docker是单机方案，解决的是应用程序的镜像化和容器化，能力仅限于单机；docker swarm和k8s的区别如下图：5、helm、k8s、tiller的关系5.1 helm出现的原因用k8s管理一个应用需要deployment、service、pod等大量的yaml文件，每次更新、部署或者回滚需要更新和维护大量的配置文件，而helm就是解决这些问题。helm配置文件可以自己定义，也可以使用一些工具进行生成。5.2 helm主要模块 helm client：Helm是客户端运行的一个命令，将这些配置打包一个chart中，而chart被保存到chart仓库中，通过chart仓库可以存储和分享chart，并且可以做到发布可配置；解决了k8s应用部署的版本控制、打包、发布、删除、更新等操作； Tiller：服务端，以deployment的形式运行在k8s集群中，他可以接收helm client的请求，生成响应的配置，再通知k8s进行部署；6、kubenetes常用的命令6.1 命名空间和集群操作1234567* kubectl get namespace 查看所有的命名空间* kubectl create namespace &lt;命名空间名&gt; * kubectl create -f .&#x2F;命名空间配置.yaml #创建一个namespace* kubectl delete namespace &lt;命名空间名&gt; 删除命名空间* kubectl cluster-info 查看集群消息* kubectl get nodes -o wide 查看所有的node信息* kubectl describe node 6.2 pod操作pod的配置文件如下： 一个详细的pod的yaml配置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677apiVersion: v1 #版本号kind: Pod #Podmetadata: #元数据 name: string #Pod名称 namespace: string #Pod所属的命名空间 labels: #自定义标签 - name: string #自定义标签名字 annotations: #自定义注释列表 - name: stringspec: #Pod中容器的详细定义 containers: #Pod中容器列表 - name: string #容器名称 image: string #容器的镜像名称 imagePullPolicy: [Always | Never | IfNotPresent] #获取镜像的策略 Alawys表示下载镜像 IfnotPresent表示优先使用本地镜像，否则下载镜像，Nerver表示仅使用本地镜像 command: [string] #容器的启动命令列表，如不指定，使用打包时使用的启动命令 args: [string] #容器的启动命令参数列表 workingDir: string #容器的工作目录 volumeMounts: #挂载到容器内部的存储卷配置 - name: string #引用pod定义的共享存储卷的名称，需用volumes[]部分定义的的卷名 mountPath: string #存储卷在容器内mount的绝对路径，应少于512字符 readOnly: boolean #是否为只读模式 ports: #需要暴露的端口库号列表 - name: string #端口号名称 containerPort: int #容器需要监听的端口号 hostPort: int #容器所在主机需要监听的端口号，默认与Container相同 protocol: string #端口协议，支持TCP和UDP，默认TCP env: #容器运行前需设置的环境变量列表 - name: string #环境变量名称 value: string #环境变量的值 resources: #资源限制和请求的设置 limits: #资源限制的设置 cpu: string #Cpu的限制，单位为core数，将用于docker run --cpu-shares参数 memory: string #内存限制，单位可以为Mib&#x2F;Gib，将用于docker run --memory参数 requests: #资源请求的设置 cpu: string #Cpu请求，容器启动的初始可用数量 memory: string #内存请求，容器启动的初始可用数量 livenessProbe: #对Pod内个容器健康检查的设置，当探测无响应几次后将自动重启该容器，检查方法有exec、httpGet和tcpSocket，对一个容器只需设置其中一种方法即可 exec: #对Pod容器内检查方式设置为exec方式 command: [string] #exec方式需要制定的命令或脚本 httpGet: #对Pod内个容器健康检查方法设置为HttpGet，需要制定Path、port path: string port: number host: string scheme: string HttpHeaders: - name: string value: string tcpSocket: #对Pod内个容器健康检查方式设置为tcpSocket方式 port: number initialDelaySeconds: 0 #容器启动完成后首次探测的时间，单位为秒 timeoutSeconds: 0 #对容器健康检查探测等待响应的超时时间，单位秒，默认1秒 periodSeconds: 0 #对容器监控检查的定期探测时间设置，单位秒，默认10秒一次 successThreshold: 0 failureThreshold: 0 securityContext: privileged:false restartPolicy: [Always | Never | OnFailure]#Pod的重启策略，Always表示一旦不管以何种方式终止运行，kubelet都将重启，OnFailure表示只有Pod以非0退出码退出才重启，Nerver表示不再重启该Pod nodeSelector: obeject #设置NodeSelector表示将该Pod调度到包含这个label的node上，以key：value的格式指定 imagePullSecrets: #Pull镜像时使用的secret名称，以key：secretkey格式指定 - name: string hostNetwork:false #是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络 volumes: #在该pod上定义共享存储卷列表 - name: string #共享存储卷名称 （volumes类型有很多种） emptyDir: &#123;&#125; #类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。为空值 hostPath: string #类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录 path: string #Pod所在宿主机的目录，将被用于同期中mount的目录 secret: #类型为secret的存储卷，挂载集群与定义的secre对象到容器内部 scretname: string items: - key: string path: string configMap: #类型为configMap的存储卷，挂载预定义的configMap对象到容器内部 name: string items: - key: string path: string pod的常用操作如下： 12345678* kubectl run &lt;deploy名&gt; —image&#x3D;&lt;image名&gt;--replicas&#x3D;1 —namespace&#x3D;&lt;空间名&gt; 用命令创建一个deployment* kubectl get pods --namespace&#x3D;&lt;命名空间&gt;* kubectl create -f yaml配置文件 --namespace&#x3D;&lt;命名空间&gt; 创建pod* kubectl get pod &lt;pod name&gt; —namespace&#x3D;&lt;命名空间&gt; --output&#x3D;yaml 输出pod的yaml配置* kubectl describe pod &lt;pod name&gt; —namespace&#x3D;&lt;命名空间&gt; 查看pod的详细信息 * kubectl get pod &lt;pod名&gt; —namepsace&#x3D;&lt;命名空间&gt; —show-labels 查看pod的label信息* Kubectl exec -it &lt;pod名&gt; —namepsace&#x3D;&lt;命名空间&gt; bash 进入到pod内* kubectl delete pod &lt;pod name&gt; 删除pod 6.3 deployment操作deployment配置的样例： 123456789101112131415161718192021apiVersion: extensions&#x2F;v1beta1 kind: Deployment metadata: name: string #Deployment名称spec: replicas: 3 #目标副本数量 strategy: rollingUpdate: maxSurge: 1 #滚动升级时最大同时升级1个pod maxUnavailable: 1 #滚动升级时最大允许不可用的pod个数 template: metadata: labels: app: string #模板名称 sepc: #定义容器模板，该模板可以包含多个容器 containers: - name: string image: string ports: - name: http containerPort: 8080 #对service暴露端口 常用操作： 12* kubectl create -f &lt;deploy.yaml配置&gt; —namespace&#x3D;&lt;命名空间&gt; 创建deployment* kubectl get pod -l app&#x3D;&lt;app名&gt; —namespace&#x3D;&lt;命名空间&gt; 通过标签查找pod 123456* kubectl get pod --show-labels —namespace&#x3D;&lt;命名空间&gt; 查看标签* kubectl describe deploy&#x2F;&lt;deploy名&gt; —namespace&#x3D;&lt;命名空间&gt; 查看详情* kubectl set image deploy&#x2F;&lt;deploy名&gt; 镜像名&#x3D;镜像名:tag —namespace&#x3D;&lt;命名空间&gt; deploy镜像升级* Kubectl rollout undo deploy&#x2F;&lt;deploy名&gt; —namespace&#x3D;&lt;命名空间&gt; 回滚到上一个版本-* kubectl rollout undo deploy&#x2F;&lt;deploy名&gt; —to-revision&#x3D;&lt;版本&gt; —namespace&#x3D;&lt;命名空间&gt; 回滚到指定版本* kubectl rollout status deploy&#x2F;&lt;deploy名&gt; 镜像名&#x3D;镜像名:tag —namespace&#x3D;&lt;命名空间&gt; 查看发布状态，比如升级后可以看 1* kubectl rollout history deploy&#x2F;&lt;deploy名&gt; 镜像名&#x3D;镜像名:tag —namespace&#x3D;&lt;命名空间&gt; #查看历史发布 12* kubectl edit deploy&#x2F;&lt;deploy名&gt; —namespace&#x3D;&lt;命名空间&gt; 修改发布的配置* kubectl scale deploy&#x2F;&lt;deploy名&gt;—replicas&#x3D;&lt;分片数&gt; —namespace&#x3D;&lt;命名空间&gt; 指定分片数来扩容或者缩容 k8s的升级方式有： 1、recreate：删除已经存在的旧版本的pod，重新创建新版本的pod。好处是能保持服务版本的一致性，坏处是服务会间断； 2、rollingUpdate的方式：滚动升级，逐步替换已经存在的pod，支持设置最大不可用pod数量和最小升级间隔时间等参数： minReadySeconds:Kubernetes在等待设置的时间后才进行升级 如果没有设置该值，Kubernetes会假设该容器启动起来后就提供服务了 如果没有设置该值，在某些极端情况下可能会造成服务服务正常运行 maxSurge: 升级过程中最多可以比原先设置多出的POD数量 例如：maxSurage=1，replicas=5,则表示Kubernetes会先启动1一个新的Pod后才删掉一个旧的POD，整个升级过程中最多会有5+1个POD maxUnavaible: 升级过程中最多有多少个POD处于无法提供服务的状态 当maxSurge不为0时，该值也不能为0 例如：maxUnavaible=1，则表示Kubernetes整个升级过程中最多会有1个POD处于无法服务的状态。6.4 service操作service更像是一个网关层，负责pod的流量入口，分发和负载均衡；他会提供一个统一的ip来访问这一组pod，而不用关心pod的替换、变更等造成的pod的ip变更；创建service的配置文件： 配置的样例： 1234567891011121314151617181920212223242526apiVersion: v1kind: Servicematadata: #元数据 name: string #service的名称 namespace: string #命名空间 labels: #自定义标签属性列表 - name: string annotations: #自定义注解属性列表 - name: stringspec: #详细描述 selector: [] #label selector配置，将选择具有label标签的Pod作为管理 范围 type: string #service的类型，指定service的访问方式，默认为clusterIp clusterIP: string #虚拟服务地址 sessionAffinity: string #是否支持session ports: #service需要暴露的端口列表 - name: string #端口名称 protocol: string #端口协议，支持TCP和UDP，默认TCP port: int #服务监听的端口号 targetPort: int #需要转发到后端Pod的端口号 nodePort: int #当type &#x3D; NodePort时，指定映射到物理机的端口号 status: #当spce.type&#x3D;LoadBalancer时，设置外部负载均衡器的地址 loadBalancer: #外部负载均衡器 ingress: #外部负载均衡器 ip: string #外部负载均衡器的Ip地址值 hostname: string #外部负载均衡器的主机名 常用的操作： 1234* kubctl create -f &lt;service.yaml文件&gt; -n &lt;命名空间&gt; 根据配置生成一个service* kubectl expose deployment &lt;deployment名&gt; —port&#x3D;&lt;服务端口&gt; --target-port&#x3D;&lt;容器端口&gt; --type&#x3D;NodePort -n &lt;命名空间&gt; 可以直接将一组deployment组合成一个service* kubectl get svc -n &lt;命名空间&gt; 查找service* Kubectl get endpoints &lt;service名&gt; -n &lt;命名空间&gt; 查找service的所有叶子节点 Kubenetes service转发后端服务的四种方式： clusterIp： 提供集群内部的一个虚拟ip（和pod的ip不在同一个网段），供pod内部进行访问； NodePort: 这种方式除了提供一个虚拟ip，还为每一个node提供了一个nodeip+nodeport的方式供外部进行访问； loadbalance：负载均衡。Client端为多个server的形式，load balance根据策略，选择出往哪个server发送请求；k8s的lb是通过ingress实现的，ingress是一种k8s的路由转发机制， ingress是整个k8s集群的接入层，负责集群内外的通讯；Ingress和service的关系如下图： 6.5 port、nodePort、targetPort的区别 port: service暴露在cluster ip上的端口，port是提供给集群内部客户访问service的入口 nodePort： k8s提供给集群外部客户访问service的入口 targetPort：是pod上的端口，容器内服务占用的端口；6.6 configmapk8s的配置管理组件，比如A服务和B服务需要一些公用的环境配置，如果将这些环境配置打到镜像中，更新配置就需要重新打镜像。可以独立成configmap，与镜像解耦，且A和B镜像都可以使用； configmap受到namespace的限制，只有同一个namespace下的pod可以引用； configmap挂载到pod中可以通过env和volumne两种方式，volume挂载的方式使用更方便一些，支持热更新。创建方式：1234* kubectl create configmap nginxconfig --from-file &#x2F;server&#x2F;yaml&#x2F;nginx&#x2F;nginx.conf #通过文件创建，from-file可以有多个* kubectl create configmap &lt;test-config&gt; --from-literal&#x3D;env_model&#x3D;prd -n &lt;命名空间&gt; ###命令行的方式创建* kubectl create -f xxxxconfigmap.yaml #以yaml资源文件创建 Env方式挂载configmap volume方式挂载configmap","categories":[{"name":"K8S","slug":"K8S","permalink":"https://qiongqiongwoo.github.io/blog/categories/K8S/"}],"tags":[]},{"title":"Hadoop","slug":"hadoop","date":"2020-08-04T10:10:15.000Z","updated":"2021-04-23T10:58:50.450Z","comments":true,"path":"2020/08/04/hadoop/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2020/08/04/hadoop/","excerpt":"","text":"hadoop组成： hadoop common：各种工具配置； hadoop HDFS：分布式文件系统； hadoop MapReduce：分布式海量数据处理的软件框架集群； hadoop Yarn：作业调度和集群资源调度； mapreduce: 分布式计算系统；生态： 支持结构化数据存储的数据库HBASE； 分布式协调服务框架zookeeper； 基于内存的数据处理框架Spark； 数据仓库软件Hive； 可扩展的机器学习和挖掘框架Mahout; HDFS架构 client：客户端，提供一些命令来访问hdfs; nameNode: 就是master，是一个管理者，管理整个文件系统的元数据以及每一个文件所对应的数据块信息； dataNode: slave，存储实际的数据库，执行数据的读/写操作； secondaryNameNode：保存了一份和nameNode中一致的镜像文件和编辑日志，当NameNode发生故障时，可以从中恢复数据。常用命令1234567891011hadoop dfs –ls &#x2F;user&#x2F; # 查看指定目录hadoop dfs –cat &#x2F;user&#x2F;input.txt # 显示文件hadoop dfs –put test.txt &#x2F;user&#x2F; # 存储文件hadoop dfs –get &#x2F;user&#x2F;input.txt . # 拉取文件到本地hadoop dfs –rmr &#x2F;user&#x2F;input.txt # 删除文件hadoop dfs –mkdir &#x2F;user&#x2F;aa # 创建目录hadoop dfs –touchz &#x2F;user&#x2F;bb # 创建文件hadoop dfs –mv &#x2F;user&#x2F;bb &#x2F;user&#x2F;cc # 创建文件hadoop job -list # 列出jobhadoop job -kill job-id #删除一个job 文件存储 block: 是hdfs中的最小存储单位，它是物理划分；hdfs中的block默认是保存三份(dfs.replication设置)；blocksize默认是128mb。（可以通过参数dfs.block.size来设置）设置为128MB的原因：读取hdfs文件的时间=block寻址时间+读取block的时间，如果分块太小，会导致block寻址时间过大，因此不能设置太小。 MapReduceHadoop任务的核心思想是MapReduce，shuffle是MapReduce的核心。shuffle的主要工作是从Map结束到Reduce开始之间的过程。shuffle阶段又可以分为Map端的shuffle和Reduce端的shuffle。map和reduce的数量：totalSize: mapreduce job输入文件的总大小；numSplits: map的个数；（设置的希望切成多少份）goalSize: totalSize/numSplits；minSize: split的最小值；finalSplitSize=max(minSize,min(goalSize,blockSize))，最终的分片数；map的设置mapred.map.tasks参数只是一个引导值，最终的map数量为: default_num = total_size / split_size;reducer的数量完全依赖于mapred.reduce.tasks这个设置； 词频统计的例子： split阶段：逻辑划分阶段，目的是将输入划分给map；finalSplitSize=max(minSize,min(goalSize,blockSize)) map阶段：分工的阶段 12345678#!&#x2F;usr&#x2F;bin&#x2F;env python&quot;&quot;&quot; mapper.py &quot;&quot;&quot;import sysfor line in sys.stdin: line &#x3D; line.strip() words &#x3D; line.split() for word in words: print &#39;%s\\t%s&#39; % (word, 1) shuffle: 从map输出到reduce输入的中间过程为shuffle的阶段；它是将map输出的无规则的数据搭乱成有规则的数据，以便reduce端接收；分为map shuffle和reduce shuffle。map阶段的shuffle特点： map产生的kv结果是先放到缓冲区的，缓冲区满了再写io生成spill文件 map任务完成前利用多路归并算法合并spill文件 partition的作用是将数据排序归类分区，分区由用户定义的partition函数控制，默认是按照hash； combiner可有可无，目的是在map端做一次合并，减少传输的数据量，提升速度。reduce端的shuffle会进行数据的copy和再次sort合并，然后发给不同的reducer进行处理； reduce阶段: 汇总阶段 12345678910111213141516171819202122232425#!&#x2F;usr&#x2F;bin&#x2F;env pythonfrom operator import itemgetterimport syscurrent_word &#x3D; Nonecurrent_count &#x3D; 0word &#x3D; Nonefor line in sys.stdin: line &#x3D; line.strip() word, count &#x3D; line.split(&#39;\\t&#39;, 1) try: count &#x3D; int(count) except ValueError: continue if current_word &#x3D;&#x3D; word: current_count +&#x3D; count else: if current_word: print &#39;%s\\t%s&#39; % (current_word, current_count) current_count &#x3D; count current_word &#x3D; wordif current_word &#x3D;&#x3D; word: print &#39;%s\\t%s&#39; % (current_word, current_count) hadoop任务提交： 1234567891011121314hadoop streaming -input 输入文件 \\ -output 输出文件 \\ -mapper &quot;python mapper.py&quot; \\ -reducer &quot;python reducer.py&quot; \\ -file reducer.py #打包文件到提交的作业中 \\ -file mapper.py \\ -D mapred.job.name&#x3D;任务名 \\ -D mapred.job.map.capacity&#x3D;最多同时运行的map任务数 \\ -D mapred.map.tasks&#x3D;map任务个数 \\ -D mapred.reduce.tasks&#x3D;reduce任务个数 \\ -D mapred.map.over.capacity.allowed&#x3D;false \\ -D mapred.job.priority&#x3D;NORMAL \\ -D abaci.job.base.environment&#x3D;default 数据倾斜数据经过map后，由于key的数据量分布不均，相同的key打到同一个reducer，导致reducer的压力过大；处理方式： 加combiner，在mapper阶段提前进行聚合操作，减少reduce端的压力； 加两级reduce，第一级对key随机加值，第二级在去掉随机数对全局进行聚合。 mapreduce优化 数据输入：需要合并小文件。小文件是指小于block size的文件，小文件会导致namenode中的map过大，另外每个小文件会独占一个分片，导致任务的装载耗时； 通过设置，减少spill次数，增大一次merge的文件数目，从而减少merge的次数； 不影响业务的前提下，进行combiner处理； 合理设置map和reduce数，设置二者共存； spark &amp; mapreduce磁盘IO&amp;延迟 mapreduce必须依赖于磁盘以及大量的网络开销，磁盘的IO开销大，延迟也高； spark是基于内存的计算框架，中间结果直接放内存，可以更快的进行迭代计算；迭代运算效率spark : mapreduce = 110:0.9 表达能力*spark不仅仅是map reduce，还可以支持RDD等；","categories":[{"name":"DataBase","slug":"DataBase","permalink":"https://qiongqiongwoo.github.io/blog/categories/DataBase/"}],"tags":[]},{"title":"k8s的dns和bns","slug":"k8s的dns和bns","date":"2020-08-01T12:10:17.000Z","updated":"2021-03-25T10:37:42.105Z","comments":true,"path":"2020/08/01/k8s的dns和bns/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2020/08/01/k8s%E7%9A%84dns%E5%92%8Cbns/","excerpt":"","text":"1、负载均衡（load balance）的意义最大化吞吐量，最小化响应时间，且避免任何单一资源的过载； 2、LB的常用算法 RR（round robin）： 轮询，每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除，在实现RR算法的时候，还需要根据其他的因素: max_fails、fail_timeout、weight等因素进行综合评估 weight RR：带权重的轮询，适用于后端服务器性能不均的情况； IP_HASH：每个请求按照访问IP的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决”负载集群SESSION同步”的问题。 Fair：第三方插件，可以根据也没大小，后端响应时间来分配请求，比如nginx可以使用Fair插件来做负载均衡 URL_HASH：按访问URL的Hash结果来分配请求，使每个URL定向到同一个后端服务器（多用于缓存服务，比如同一个urlhash到同一台服务器，能提高缓存的命中率） 3、bns基本架构为：架构分为server端和client端，server端的服务包括： Uns：naming server，运行在服务端，缓存全量的服务单元数据； webfoot-agent：运行在node节点，收集node上的实例信息，并上报给server； naming-agent：客户端，提供命令行查询； 4、bns的作用通过matrix部署的应用，会生成一组bns，可以通过bns进行访问（类似于k8s的dns功能）； 5、k8s 的dns K8s的dns功能简单说：可以在集群的内部可以通过curl -s &lt;服务名：服务端口号&gt; 来访问服务。 service解决了服务发现和负载均衡的问题，有了clusterIp和nodePort类型的service的ip，为什么还需要dns? Ip是后生成的，只有在服务启动后才会存在，或者采用环境变量的方式带入到容器，但环境变量也是在依赖的服务已经启动后才有的。最简单的方式是ip和dns name之间可以自由互换，只知道名字就可以知道name。 k8s的dns架构： 其中，etcd用来保存dns数据， kube2sky用来监听service的变动并存储到etcd，skydns从etcd中读取dns信息并对外提供服务； 一个服务的dns地址： 服务名.namespace.svc.cluster.local k8s做pod探活的方式：livenessprobe和readnessProbe。","categories":[{"name":"K8S","slug":"K8S","permalink":"https://qiongqiongwoo.github.io/blog/categories/K8S/"}],"tags":[]},{"title":"神经网络&深度学习基础","slug":"神经网络&深度学习基础","date":"2020-03-17T08:01:23.000Z","updated":"2021-05-06T02:26:10.544Z","comments":true,"path":"2020/03/17/神经网络&深度学习基础/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2020/03/17/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/","excerpt":"","text":"神经网络分类 神经网络的发展 网络结构发展 算力发展神经网络在ACL中的占比图： 神经网络&amp;深度学习神经网络最开始是单层神经网络，单层神经网络只能处理线性分类的问题，后来有人提出了双层神经网络，也就是单层神经网络中加了一个隐藏层，可以很好的解决非线性分类的任务。但双层神经网络的隐藏层从设计完全依赖于经验，节点数需要不断调参，并且优化很难，研究人员不爱用。神经网络进入冰河期。2006年提出了多层神经网络，和传统的神经网络训练方式不同的是，他先有一个“预训练”（pre-training）的过程，找到一个接近最优解的值，然后在通过微调（fine-tuning）技术进行优化网络。这两个技术的利用减少了训练的时间和难度，这就是深度学习。 深度学习不等于多层神经网络，深度学习是让多层神经网络可训练，可以work的一套架构和方法；深度学习四大要素: 训练数据 模型 算力 应用 深度学习在自然语言处理的位置： BP算法BP算法：backPropagation，误差反向传播算法；正常情况下如果一个训练好的网络，给定输入，可以通过正向传播得到输出。但是训练网络才是最难的。训练的过程是为了减小LOSS值。BP算法的原理：在确认L+1层的误差向量以及权值矩阵后，就可以求出当前层的误差向量；因此如果得到最后一层的误差，就能找到所有的误差；训练过程为： 先将训练集沿正向传播走一遍，保存下各种中间变量 先计算出最后一层的误差； 用误差更新最后一层的权重； 计算前一层的误差； 更新前一层的权重； 再计算前一层的误差； 更新权重，直到所有权重更新完成； BPTT训练RNN的方法用BPTT（基于时间反向传播），本质还是BP算法。 梯度下降BP算法根据损失函数计算的误差通过反向传播的方式，指导深度网络参数的更新优化。优化的目的是减少误差，即取得loss函数最小值；求解最小值的方法在数学上即使用梯度下降法；求解最优不是只有梯度下降法，还有拉格朗日松弛、分支定界、启发式模型等等；使用梯度下降需要保证优化的函数是凸函数。 训练出现loss=NAN的情况 模型微调基于预训练模型去微调，比从头开始训练能节省大量的计算资源和计算时间，从而提高计算效率甚至提高准确率。浅层的卷积提取的是基础特征，深层的卷积层提取的是抽象的特征。预训练模型相当于已经具备了浅层的基础特征和深层的抽象特征能力。不同数据集下使用微调：（以下不具有指导意义，需要具体问题具体分析） 训练数据少，但数据相似度极高，只需要修改最后几层或者最终的softmax层。 数据量少，数据相似度低，可以冻结训练模型的前K层，重新训练剩余的n-k层。 训练数据量大，相似度低，可以从头训练神经网络。 数据量大，数据相似度高，使用预训练模型中的权重重新训练网络。 网络计算量大的优化方式： FPGA硬件加速：除了用GPU之外，卷积操作也可以通过FPGA硬件加速。 隐藏层共享，缓存； 将多个属性拆成几个独立的部分进行训练，直接降维，最后再进行特征整合； 进行模型蒸馏； transfer learning和fine tune的区别： fine-tuning：是一个trick，在迁移学习中有所涉及，但不仅仅出现在迁移学习中，指对参数进行微调； Transfer learning： 可以看成是一套完整的体系，是一种处理流程； 损失函数损失函数是为了衡量预测值和实际值之间的距离的，损失函数越小说明预测的约准确。假设真实值为y，预测值为f(x)，样本数为m，常见的几种损失函数有： 绝对值损失函数：m个样本的真实值和预测值之间距离的平均值； 均方差损失函数 交叉熵损失函数交叉熵损失函数常用于解决分类的问题，y的取值只有0或1。 激活函数引入激活函数的原因： 神经网络的每一层相当于一个线性函数，多个神经网络层次相乘，最终还是一个线性函数。因此需要进行非线性映射。非线性变换相当于对空间进行变换，把原来线性不可分的问题变为线性可分的。常见的激活函数 sigmoid：也称之为Logistic函数，是LR模型指定的激活函数；公式和导数为： 优点：平滑，易求导缺点：激活函数计算量大，正向和逆向都包含幂等运算；导数在【0，0.25】之间，容易发生梯度消失；输出不是0均值； tanh： 为sigmoid的平移和拉伸；解决了不是0均值的问题；但是梯度小时和幂等运算的问题依然存在； ReLu：修正线性单元函数；有效导数为1，解决了梯度消失和运算量的问题。导数为0，相当于一个去噪声的过程，但如果用ReLu，学习率不能设置的过大，容易导致模型学不到有效的特征； Leaky Relu为了防止模型”dead“的情况，在RELU的x&lt;0的部分不设置为0，而是给一个很小的负数； GELU：高斯误差线性单元激活函数。transformer使用的是gelu，似乎是当前最优秀的，能避免梯度爆炸、消失的问题。 ReLu的效果要优于tanh和sigmoid： 1. tanh和sigmoid需要求导，计算量大。ReLu计算量会节省很多。 2. Relu会使一部分的神经元的输出为0，会缓解过拟合的发生。 3. sigmoid和tanh在饱和区域的gradient非常平缓，接近于0，容易造成梯度消失的问题。而ReLu的gradient是常数。 梯度爆炸和消失产生的原因梯度下降作为一种最常见的迭代式优化策略，应用在神经网络的BP算法中，由于深度神经网络层级太深，在求导的过程中，由于链式法则，可能会出现梯度消失和梯度爆炸现象，为了搞清楚为什么会出现这些情况，以sigmoid激活函数为例子，从最简单的单层神经网络的求导过程着手，查看求导的结果。梯度消失：如果层层之间的梯度均在（0，1）之间，层层缩小，那么就会出现梯度消失；表现是训练变慢；梯度爆炸：如果层层传递的梯度大于1，那么经过层层扩大，就会出现梯度爆炸，表现为：训练波动很大，不稳定；可见梯度的消失与爆炸与激活函数没有特别大的关系，反而和权重有较大关系，因此权重的初始化对神经网络的训练很重要。总之梯度爆炸和梯度消失的产生主要是由于链式法则的求导、梯度层层缩放导致的，因为神经网络的不只有激活函数的作用，还有权重与神经元的相互作用。 解决梯度爆炸和消失的常用技术 【缓解爆炸】合理的随机初始化策略：随机选取一些较小的数值，防止参数过大导致梯度爆炸；但参数过小，收敛过慢； 【缓解消失】使用非饱和参数作为激活函数（如RELU） 【缓解消失和爆炸】使用批归一化（Batch Normalization ）。是指在每层的激活函数之前添加一个BN操作，使得特征图数据归一化为均值为0，标准差为1的分布；归一化：数据预处理，将数据限定在特定范围内；标准化：数据预处理，使数据符合标准正态分布；正则化：在损失函数中添加惩罚项，增加建模的模糊性； 【缓解爆炸】梯度剪裁（gradient clipping）：其思想是设置一个梯度剪切阈值，然后更新梯度的时候，如果梯度超过这个阈值，那么就将其强制限制在这个范围之内，通过这种直接的方法就可以防止梯度爆炸。 【缓解消失和爆炸】复用预训练层，直接使用已经训练好的网略来训练一个新的任务； 【缓解爆炸】权重正则化：比较常见的是l1正则，和l2正则，在各个深度框架中都有相应的API可以使用正则化，比如在tensorflow中，搭建网络的时候已经设置了正则化参数，则调用以下代码可以直接计算出正则损失：regularization_loss = tf.add_n(tf.losses.get_regularization_losses(scope=’my_resnet_50’))如果没有设置初始化参数，也可以使用以下代码计算l2正则损失：l2_loss = tf.add_n([tf.nn.l2_loss(var) for var in tf.trainable_variables() if ‘weights’ in var.name]) 【缓解消失】残差结构 【缓解消失】LSTM：长短期记忆网络（long-short term memory networks），是不那么容易发生梯度消失的，主要原因在于LSTM内部复杂的“门”(gates)，LSTM通过它内部的“门”可以接下来更新的时候“记住”前几次训练的”残留记忆“，因此，经常用于生成文本中。 FC-全连接网络每个节点都与上一层的所有节点相连。特点是参数剧多。 CNN-卷积神经网络卷积神经网络的分层： 输入层：一般做数据预处理 卷积层：是为了提取特征，在不断的训练过程中，最终优化的就是这个特征，特征在CNN中称之为卷积核。卷积层是局部连接+参数共享，它可以看做是计算量和准确度的一种妥协； 激活层：对卷积层的结果做一次非线性映射。 池化层：欠采样或者下采样，主要用于特征降维，压缩数据和参数的数量，减少过拟合；有max polling（最大池化）和average polling（平均池化）两种。 全连接FC层：作用是将前面学到的特征引用到样本标记空间；参数量最大，通常在卷积神经网络的尾部。除了最后一层是全连接层，前面几层均为局部连接层，原因是：全连接层的参数太多，并且一个像素只和他周边的点相关，因此用局部关联可以减少参数。 其他概念局部连接：CNN认为神经元没有必要对整个全局图像进行感知，他只和周边的元素联系较为紧密，因此只需要对其周边的神经元进行连接； 权值共享：定义一小块（卷积核，一般为3 * 3或者5 * 5），并已知这一块的每个像素点的权重参数，这一块的权重参数也会被其他块共享，这就是权值共享。局部连接和权值共享的作用是减少参数量，这两种措施组合在一起称之为卷积操作。步长：卷积核每次划过窗口的大小。零填充：为了不丢失图像边上的信息，在图像四周添加0信息；深度：卷积核的个数；内积：1* 1 + 0* 0 + 1* 1 + 0* 0 + 1* 1 + 0* 0 + 1* 1 + 0* 0 + 1* 1 = 5 RNN-循环神经网络传统神经网络输入和输出是独立的，RNN通过循环结构引入记忆的概念，输出不仅仅依赖输入，还依赖于记忆。RNN可以更好的处理具有时序关系的任务。Xt是时间t处的输入，Yt为时间t时刻的输出。U是从输入到隐藏态，W从前一隐藏态到下一个隐藏态，V是从隐藏态到输出。 LSTM（long short-term memory）长短期记忆模型LSTM拥有三个门（遗忘门、输入门，输出门）来保护和控制细胞状态遗忘门：决定丢弃信息；输入门：确定需要更新信息；输出门：输出信息；RNN的”记忆“在每个时间点都会被新的输入覆盖，但LSTM中”记忆”是与新的输入相加； GRU（Gate recurrent Unit）门控循环单元能够较好的处理训练文本中长距离依赖的问题。GRU只有两个门：重置门：控制忽略前一时刻状态信息的程度，重置门越小表示忽视的越多；更新门：控制前一时刻的状态信息被带入到当前状态中的程度，更新门越大表示前一时刻的状态信息带入的越多；","categories":[{"name":"NLP","slug":"NLP","permalink":"https://qiongqiongwoo.github.io/blog/categories/NLP/"}],"tags":[]},{"title":"文本表示和词向量","slug":"文本表示和词向量","date":"2019-11-17T11:10:51.000Z","updated":"2021-04-23T10:52:39.463Z","comments":true,"path":"2019/11/17/文本表示和词向量/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2019/11/17/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA%E5%92%8C%E8%AF%8D%E5%90%91%E9%87%8F/","excerpt":"","text":"自然语言处理 = 文本处理 + 机器学习文本处理的首要任务是文本表示，也就是将文字等符号数学化。 Distributional representation 和 Distributed representations属于文本表示的两种思路，而不是具体的算法，并且不是一个维度上的对比； Distributional representation：通过观察一个词的上下文，来得到这个词的语义，与之相对的是wordnet的方式； Distributed representations: 用在deep learning中，每个词语不是表示成稀疏的变量，而是表示为一个低纬度、稠密的向量，向量的每一项没有具体的指征意义。（词的分布式表示） 词向量和语言模型词向量是用一个向量的形式表示词，词向量可以作为很多模型的输入，比如计算相似度，做high-level的文本分类、命名实体识别、情感分析等任务； 词向量One-hot embedding构建词表，比如n维，根据词表将词在文本中的频次构建n维向量表示文本；缺点：丢失上下文信息；依赖词表大小，维度过大，过于稀疏； Word2vecword2vec: 根据神经网络，从大量无标注的文本中提取有用的信息而产生；word2vec可以理解为是一种降维的方式。 假设如下是一个三层的神经网络：如果上下文只考虑一个词，那就相当于用当前词x预测下一个词y，x和y用什么来表示？one hot encoder; 假设词表大小是|V|，则x和y都是一个|V|* 1维的向量。从输入层到隐藏层、从隐藏层到输出层的两个权重矩阵可以用反向传播算法来求得到；假设隐层层的节点数是N，则从输入层到隐藏层的权重矩阵是N * V维，根据one hot encoder的表示，x中只有一个1，这样只有这一个位置的权重被激活，得到的这个N维的向量就可以唯一的表示x。 同理从隐藏层到输出层，由于y中只有一个位置为1，这样同样能得到一个N维的向量来表示y;这两个向量分别被称为输入向量和输出向量；一般会使用输入向量；从这里可以看出，word2vec实际是一个降维的操作，将|V|维的one hot encoder向量降到N维的向量； CBOW &amp; skip-Gramembedding的两个训练算法CBOW和skip-Gram，前者的训练速度会更快，后者对生僻字的处理更好： CBOW：拿一个词的上下文来预测整个词语本身,输入是C个词串联组成的向量； Skip-Gram：拿这个词来预测它周围的上下文，输出为C个词y串联的向量; skip_grammar训练skip-gram的训练流程如下： 其中交叉熵的计算公式： 为了降低训练成本，提高训练效率，可以随机构造负样本，将问题处理成一个二分类的问题。 使用paddlepaddle训练的forward函数： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#定义skip-gram训练网络结构#这里我们使用的是paddlepaddle的1.8.0版本#一般来说，在使用fluid训练的时候，我们需要通过一个类来定义网络结构，这个类继承了fluid.dygraph.Layerclass SkipGram(fluid.dygraph.Layer): def __init__(self, vocab_size, embedding_size, init_scale&#x3D;0.1): #vocab_size定义了这个skipgram这个模型的词表大小 #embedding_size定义了词向量的维度是多少 #init_scale定义了词向量初始化的范围，一般来说，比较小的初始化范围有助于模型训练 super(SkipGram, self).__init__() self.vocab_size &#x3D; vocab_size self.embedding_size &#x3D; embedding_size #使用paddle.fluid.dygraph提供的Embedding函数，构造一个词向量参数 #这个参数的大小为：[self.vocab_size, self.embedding_size] #数据类型为：float32 #这个参数的名称为：embedding_para #这个参数的初始化方式为在[-init_scale, init_scale]区间进行均匀采样 self.embedding &#x3D; Embedding( size&#x3D;[self.vocab_size, self.embedding_size], dtype&#x3D;&#39;float32&#39;, param_attr&#x3D;fluid.ParamAttr( name&#x3D;&#39;embedding_para&#39;, initializer&#x3D;fluid.initializer.UniformInitializer( low&#x3D;-0.5&#x2F;embedding_size, high&#x3D;0.5&#x2F;embedding_size))) #使用paddle.fluid.dygraph提供的Embedding函数，构造另外一个词向量参数 #这个参数的大小为：[self.vocab_size, self.embedding_size] #数据类型为：float32 #这个参数的名称为：embedding_para_out #这个参数的初始化方式为在[-init_scale, init_scale]区间进行均匀采样 #跟上面不同的是，这个参数的名称跟上面不同，因此， #embedding_para_out和embedding_para虽然有相同的shape，但是权重不共享 self.embedding_out &#x3D; Embedding( size&#x3D;[self.vocab_size, self.embedding_size], dtype&#x3D;&#39;float32&#39;, param_attr&#x3D;fluid.ParamAttr( name&#x3D;&#39;embedding_out_para&#39;, initializer&#x3D;fluid.initializer.UniformInitializer( low&#x3D;-0.5&#x2F;embedding_size, high&#x3D;0.5&#x2F;embedding_size))) #定义网络的前向计算逻辑 #center_words是一个tensor（mini-batch），表示中心词 #target_words是一个tensor（mini-batch），表示目标词 #label是一个tensor（mini-batch），表示这个词是正样本还是负样本（用0或1表示） #用于在训练中计算这个tensor中对应词的同义词，用于观察模型的训练效果 def forward(self, center_words, target_words, label): #首先，通过embedding_para（self.embedding）参数，将mini-batch中的词转换为词向量 #这里center_words和eval_words_emb查询的是一个相同的参数 #而target_words_emb查询的是另一个参数 center_words_emb &#x3D; self.embedding(center_words) target_words_emb &#x3D; self.embedding_out(target_words) #center_words_emb &#x3D; [batch_size, embedding_size] #target_words_emb &#x3D; [batch_size, embedding_size] #我们通过点乘的方式计算中心词到目标词的输出概率，并通过sigmoid函数估计这个词是正样本还是负样本的概率。 word_sim &#x3D; fluid.layers.elementwise_mul(center_words_emb, target_words_emb) word_sim &#x3D; fluid.layers.reduce_sum(word_sim, dim &#x3D; -1) word_sim &#x3D; fluid.layers.reshape(word_sim, shape&#x3D;[-1]) pred &#x3D; fluid.layers.sigmoid(word_sim) #通过估计的输出概率定义损失s函数，注意我们使用的是sigmoid_cross_entropy_with_logits函数 #将sigmoid计算和cross entropy合并成一步计算可以更好的优化，所以输入的是word_sim，而不是pred loss &#x3D; fluid.layers.sigmoid_cross_entropy_with_logits(word_sim, label) loss &#x3D; fluid.layers.reduce_mean(loss) #返回前向计算的结果，飞桨会通过backward函数自动计算出反向结果。 return pred, loss 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#开始训练，定义一些训练过程中需要使用的超参数batch_size &#x3D; 512epoch_num &#x3D; 3embedding_size &#x3D; 200step &#x3D; 0learning_rate &#x3D; 0.001#定义一个使用word-embedding查询同义词的函数#这个函数query_token是要查询的词，k表示要返回多少个最相似的词，embed是我们学习到的word-embedding参数#我们通过计算不同词之间的cosine距离，来衡量词和词的相似度#具体实现如下，x代表要查询词的Embedding，Embedding参数矩阵W代表所有词的Embedding#两者计算Cos得出所有词对查询词的相似度得分向量，排序取top_k放入indices列表def get_similar_tokens(query_token, k, embed): W &#x3D; embed.numpy() x &#x3D; W[word2id_dict[query_token]] cos &#x3D; np.dot(W, x) &#x2F; np.sqrt(np.sum(W * W, axis&#x3D;1) * np.sum(x * x) + 1e-9) flat &#x3D; cos.flatten() indices &#x3D; np.argpartition(flat, -k)[-k:] indices &#x3D; indices[np.argsort(-flat[indices])] for i in indices: print(&#39;for word %s, the similar word is %s&#39; % (query_token, str(id2word_dict[i])))#将模型放到GPU上训练（fluid.CUDAPlace(0)），如果需要指定CPU，则需要改为fluid.CPUPlace()with fluid.dygraph.guard(fluid.CUDAPlace(0)): #通过我们定义的SkipGram类，来构造一个Skip-gram模型网络 skip_gram_model &#x3D; SkipGram(vocab_size, embedding_size) #构造训练这个网络的优化器 adam &#x3D; fluid.optimizer.AdamOptimizer(learning_rate&#x3D;learning_rate, parameter_list &#x3D; skip_gram_model.parameters()) #使用build_batch函数，以mini-batch为单位，遍历训练数据，并训练网络 for center_words, target_words, label in build_batch( dataset, batch_size, epoch_num): #使用fluid.dygraph.to_variable函数，将一个numpy的tensor，转换为飞桨可计算的tensor center_words_var &#x3D; fluid.dygraph.to_variable(center_words) target_words_var &#x3D; fluid.dygraph.to_variable(target_words) label_var &#x3D; fluid.dygraph.to_variable(label) #将转换后的tensor送入飞桨中，进行一次前向计算，并得到计算结果 pred, loss &#x3D; skip_gram_model( center_words_var, target_words_var, label_var) #通过backward函数，让程序自动完成反向计算 loss.backward() #通过minimize函数，让程序根据loss，完成一步对参数的优化更新 adam.minimize(loss) #使用clear_gradients函数清空模型中的梯度，以便于下一个mini-batch进行更新 skip_gram_model.clear_gradients() #每经过100个mini-batch，打印一次当前的loss，看看loss是否在稳定下降 step +&#x3D; 1 if step % 100 &#x3D;&#x3D; 0: print(&quot;step %d, loss %.3f&quot; % (step, loss.numpy()[0])) #经过10000个mini-batch，打印一次模型对eval_words中的10个词计算的同义词 #这里我们使用词和词之间的向量点积作为衡量相似度的方法 #我们只打印了5个最相似的词 if step % 10000 &#x3D;&#x3D; 0: get_similar_tokens(&#39;one&#39;, 5, skip_gram_model.embedding.weight) get_similar_tokens(&#39;she&#39;, 5, skip_gram_model.embedding.weight) get_similar_tokens(&#39;chip&#39;, 5, skip_gram_model.embedding.weight) doc2vec在处理文本任务时候，比如长文本相似度、文本分类等任务，一般会先提取关键词，然后用关键词的向量进行平均或者拼接，来计算相似度；其实使用word2vec往往会丢失语序信息，因此提出了doc2vec模型；doc2vec模型加入了一个paragraph vector信息表达语序意义；和关键词向量一起作为输入；","categories":[{"name":"NLP","slug":"NLP","permalink":"https://qiongqiongwoo.github.io/blog/categories/NLP/"}],"tags":[]},{"title":"odp框架","slug":"odp框架","date":"2019-08-18T13:39:25.000Z","updated":"2021-03-26T08:20:05.815Z","comments":true,"path":"2019/08/18/odp框架/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2019/08/18/odp%E6%A1%86%E6%9E%B6/","excerpt":"","text":"从使用上看，Odp框架和其他的php或者web框架项目比如django框架相比，规范比较严格，比如有严格的目录要求，类名和目录名要对应。 1、odp项目的主要目录结构 app：应用程序目录，存放置产品线业务（app）代码； conf：配置文件目录，包括app的配置、db的配置等, 比如代码中的auth.conf, bos.conf, db.conf； log：odp运行环境中产生的日志，包括webserver日志、app日志、ral日志等 data：放置组件和app生成的本机数据、缓存等 bin：ODP的插件的执行命令。包括php，pcheck，ptest等 install：ODP组件安装信息存储目录。ocm命令读取的即为该目录中的信息; php：php安装后所在的目录。php目录中的phplib目录为公共库目录，存放ODP和产品线的公共库； template：用于存放php的页面模板； webroot：默认的web文档目录，用于存放静态文件以及每个app的index.php webserver：web服务的安装目录，支持lighttpd以及nginx； Php-cgi 就是解析php脚本的程序而已， 作用和HHVM一样；Php-fpm是实现fastcgi协议的的进程管理器，有一个master和多个work，是一个进程管理池，用来处理web的请求； 2、app项目基本的目录结构如下： Odp框架app目录下的业务代码需要按照业务层规范来开发，Odp框架属于mvc框架，业务层粗略的可以分为controller，action、 model，controller是很薄的一层；action主要处理参数校验以及权限验证等；model层相比其他的框架划分的更细，下又分为 Pageservice、 dataservice以及dao层； Action的类名：必须以大写的Action开头，继承自Ap_Action_Abstract，命名方式为驼峰， 下面只有execute方法。Action层一般会调用PS层的类，来做后续的处理。 model目录下有dao和service， service下又分为pageService和dataService； 一个PageService层可对应多个Action,而一个Action则只能对应一个PageService。PageService层是唯一可以和action直接交互的，具体的数据处理逻辑应该在PageService层进行处理。pageService层和dataService层进行交互； DataService层并不是和DB层直接交互，而是作为数据库操作的一个封装，并将数据库中需要处理的数据进行一个与Dao层需要的参数格式一致的一个处理，并处理dao层返回的失败或成功信息。 Dao层是直接和数据库进行交互； 综上可得数据的流向为： action -&gt; pageService-&gt; dataService-&gt; Dao-&gt; DB，然后一层层向上级返回信息，最后还是在action层中返回信息。 3、ral组件服务除了访问mysql等数据库之外，还可能调用后端的服务，交互协议可能是http或者rpc，数据传输协议可能是string或者mcpack之类的；RAL组件就是ODP的资源访问层，实现了通过添加配置的方式就做到对后端服务端交互的支持;后端服务可以定义为IP或者bns group的形式； RAL组件的服务配置支持local和webfoot等方式 方便：添加相关配置即可实现与后端服务的交互 支持并发调用和异步接口、支持负载均衡、健康检查等 4、AP框架的流程Odp框架的底层是ap框架，一个用户请求到来，首先会经过nginx转发，然后转交到ap框架；Ap框架的处理流程还原了一个请求在整个业务系统中执行的完整流程；Ap框架规定类名中必须包含路径信息，也就是以下划线分割的目录信息。Ap将依照类名中的目录信息，完成类的自动加载，而不需要通过include与require语句载入类的具体实现的文件。odp框架禁止添加include和require语句，所有的类都通过ap框架来加载，load一个类的方式是：类名按照_分割成路径，然后按照路径完成加载；ap目录映射规则（加载类的规则）数据模型的类寻址目录是从model开始的，比如Service_Page_A的目录的地址映射路径为：&#123;项目目录&#125;/models/service/page/Sample.php Ap框架首先会初始化一个ap_application的对象，然后先去读取app目录下每个app中的Bootstrap.php文件，做app初始化的工作。Bootstrap.php文件是Ap提供的一个全局配置的入口, 可以做很多全局自定义的工作。比如路由的定义，插件的定义等；run方法主要包括两部分，一部分是路由功能Router，一部分是分发功能dispatch；Ap的Router模块的主要功能是从中解析出model、Controller以及Action信息。 odp框架默认的路由协议Ap_Route_Static, 就是分析请求中的request_uri,在去除掉base_uri以后, 获取到真正的负载路由信息的request_uri片段,具体的策略是, 根据”/“对request_uri分段,依次得到Module,Controller,Action, 在得到Module以后,还需要根据Ap_Application::$modules来判断Module是否是合法的Module，如果不是，则认为Module并没有体现在request_uri中，而把原Module当做Controller,原Controller当做Action。”ap框架默认的model和controller为index；controller中会记录所有的actions的地址，action为真正的业务入口，通过调用action的execute方法调用底层的业务逻辑。 4、下面以/api/project/list为例结合代码说明具体的流程；一个请求到来后，先经过nginx的rewrite规则进行转发，转发规则如下： 可以看到请求转发到 /dunker-pro/index.php 文件； Index.php入口文件中这两行的意义： Bd_Init::init（）方法中会new一个Ap_application的类，并返回Ap_application是ap框架的核心类；第二句是调用了Ap_application的boostrap和run方法； boostrap方法主要是找到Boostrap.php文件并执行一系列的init方法；duncker_pro目录的Boostrap文件内容如下： 首先路由是使用的aip_router，自定义的路由如下： 规则为：干掉结尾的/, 将uri分为controller和action; action默认为index，其中如果有/替换为”_“作为真正的action；controller层只做action的转发；action中通过执行execute方法调用底层的业务逻辑，处理完成后将结果返回； 5、ap插件AP插件会触发以下的几个hook函数：插件Init中实现了routerStartUp方法，主要功能是初始化、参数格式化和打印URI请求日志（URI、开始时间、当前内存占用）。 dispatchLoopShutdown方法，主要功能是打印日志，包括URI、耗时、内存占用；","categories":[{"name":"后端","slug":"后端","permalink":"https://qiongqiongwoo.github.io/blog/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[]},{"title":"网络知识总结","slug":"网络知识总结","date":"2019-01-07T07:55:45.000Z","updated":"2021-03-21T07:41:28.839Z","comments":true,"path":"2019/01/07/网络知识总结/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2019/01/07/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/","excerpt":"","text":"网络中的知识点1、网络层次分为物理层、数据链路层、网络层、传输层、会话层、表示层和应用层。IP协议对应于网络层，TCP协议对应于传输层，而HTTP协议对应于应用层，三者从本质上来说没有可比性。2、socket &amp; http &amp; tcp/ip socket是提供给程序员的接口API http是应用层协议，决定了怎么打包数据 TCP/IP是传输层协议，解决如何在网络中传输数据。3、http 和https区别（1）http是一种网络传输协议，https = http + ssl（ssl为非对称加密的一种形式，非对称加密就是利用公钥和私钥来以及数字证书来校验）（2）http传输的是明文，https传输的是加密后的数据（3）http是80端口，https是443端口（4）https常用在银行登录、支付、密码、网站验证等4、Tcp建立连接需要三次握手，建立连接后，任何一方均可以断开连接（1）A发送syn=1 &amp; sequence number 给B，然后A进入syn_send状态（2）B收到请求，发送syn=1 ack=1 acknowledge_number = 1 给A，然后B进入syn_recv状态（3）A收到反馈，验证ack以及acknowledge_number，进入establish状态5、Tcp是全双工的，任何一方都要单独进行关闭，过程需要四次（1）主机A发送FIN，用来关闭从A到B的数据传输，此时A进入FIN_WAIT状态，（2）主机B收到A发送的FIN，返回ACK和FIN, 此时B进入LAST_ACK状态；（3）主机A收到B返回的FIN和ACK，此时进入Time_WAIT状态；（4）主机A接收到B发送的FIN，然后返回ACK和FIN，A和B均进入到CLOSE状态。6、Tcp和Udp（1）tcp是面向连接的，因为有三次握手，因而保证了连接的可靠性（2）udp是播报性质，是无连接的，udp的连接开销小，传输速率高、实时性好7、http1.0和http1.1网络请求的影响因素最主要的是HOL （head of line）blocking： 浏览器对每个域名的连接数量有限制，最多是4个（不同的内核实现不同），超过数量会阻塞请求1.1对1.0的升级项有：（1）缓存的处理 引入cache-control 、entity tag（2）长链接(持久连接)：即多次http请求可以公用一个Tcp连接，这样省去了三次握手的时间，但每个单独网页的请求和应答还是要使用各自的连接。并且允许同一个连接中的请求同时发出，但后台服务器的处理需要是顺序处理。8、websocket：websocket基于tcp连接的全双工通讯协议，是一种持久化的协议。他利用http协议完成了一部分的握手工作。 浏览器缓存策略1、缓存类型：（1）强缓存：直接使用浏览器缓存，不请求服务器（2）协商缓存：发送请求到服务器，由服务器来判定是否取缓存数据2、浏览器缓存策略的整个过程过程详解（1）是否有缓存：到cache下去找这个文件是否存在（2）是否过期：用存储的文件的header中的信息expire、cach-control中的max-age、smax-age 以及Date信息，和当前的客户端时间进行比较，如果判定为缓存未过期，直接从缓存中取数据，此为强缓存。（smax-age &gt; max-age &gt;expire）expire返回的是服务器的时间，如果当前客户端的时间设置错误，会影响缓存是否过期的判断。（3）如果没有相关的是否过期的判断，可以根据响应头中的date和last-modified的10%来作为缓存周期，即启发式缓存。（4）如果缓存判定为过期，此时需要将服务器发送请求。其中If-Modified-Since = 缓存的文件头中的last-modified，If-None-Match = 缓存文件头中的eTag值。eTag可以理解为当前文件内容的一个md5值，内容发生变化，md5值会变化。（5）如果服务器判断文件未发生变化，直接返回304，浏览器取本地文件，否则返回200 以及新的文件，浏览器更新header信息。4、Cache-control中的no-cache 和 no-store（1）no-cache并非指的浏览器不允许缓存而是每次都需要向后端请求来判断是否使用缓存。（2）no-store: 绝对禁止缓存5、用户影响浏览器缓存的行为： Http请求的header、response以及状态码1、请求方式GET: 向Web服务器请求一个文件POST: 向Web服务器发送数据让Web服务器进行处理PUT: 向Web服务器发送数据并存储在Web服务器内部HEAD: 检查一个对象是否存在DELETE: 从Web服务器上删除一个文件CONNECT: 对通道提供支持TRACE: 跟踪到服务器的路径OPTIONS: 查询Web服务器的性能2、header中字段信息1、method：说明：请求方式2、Host 说明：请求的web服务器域名地址3、User-Agent：客户端运行的浏览器类型的详细信息。如：User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.114、Accept：指定客户端能够接收的内容类型，内容类型中的先后次序表示客户端接收的先后次序。例如：Accept:text/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,/;q=0.55、Accept-Language：指定HTTP客户端浏览器用来展示返回信息所优先选择的语言，此处是语言而非编码。如：Accept-Language: zh-cn,zh;q=0.5 ，此项是在浏览器中设置中可以随意设置的。6、Accept-Encoding：浏览器可以支持的内容压缩编码类型如：Accept-Encoding: gzip,deflate7、Accept-Charset：浏览器可以接受的字符编码集。如：Accept-Charset: gb2312,utf-8;q=0.7,*;q=0.78、Content-Type：显示此HTTP请求提交的内容类型。一般只有post提交时才需要设置该属性。如：Content-type: application/x-www-form-urlencoded;charset:UTF-8有关Content-Type属性值可以如下两种编码类型：（1）“application/x-www-form-urlencoded”： 表单数据向服务器提交时所采用的编码类型，默认的缺省值就是“application/x-www-form-urlencoded”。 然而，在向服务器发送大量的文本、包含非ASCII字符的文本或二进制数据时这种编码方式效率很低。（2）“multipart/form-data”： 在文件上载时，所使用的编码类型应当是“multipart/form-data”，它既可以发送文本数据，也支持二进制数据上载。当提交为单数据时，可以使用“application/x-www-form-urlencoded”；当提交的是文件时，就需要使用“multipart/form-data”编码类型。在Content-Type属性当中还是指定提交内容的charset字符编码。一般不进行设置，它只是告诉web服务器post提交的数据采用的何种字符编码。一般在开发过程，是由前端工程与后端工程师商量好使用什么字符编码格式来post提交的。9、Connection：是否需要持久连接。如果web服务器端看到这里的值为“Keep-Alive”，或者看到请求使用的是HTTP 1.1（HTTP 1.1默认进行持久连接），它就可以利用持久连接的优点，当页面包含多个元素时（例如Applet，图片），显著地减少下载所需要的时间。要实现这一点， web服务器需要在返回给客户端HTTP头信息中发送一个Content-Length（返回信息正文的长度）头，最简单的实现方法是：先把内容写入ByteArrayOutputStream，然 后在正式写出内容之前计算它的大小。10、Keep-Alive：显示此HTTP连接的Keep-Alive时间。如：Keep-Alive: 300。使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive功能避免了建立或者重新建立连接。以前HTTP请求是一站式连接，从HTTP/1.1协议之后，就有了长连接，即在规定的Keep-Alive时间内，连接是不会断开的。11、cookie：HTTP请求发送时，会把保存在该请求域名下的所有cookie值一起发送给web服务器。12、Referer：值为一个URL，表示用户从该URL代表的页面出发访问当前请求的页面。3、response中的字段1、Content-Length：表示web服务器返回消息正文的长度2、Content-Type：返回数据的类型（例如text/html文本类型）和字符编码格式。如 Content-Type: text/html;charset=utf-83、Date：显示当前的时间4、status：返回的请求状态码4、http返回的状态码200 &amp; OK: 请求成功；204 &amp; No Content: 请求处理成功，但没有资源可以返回；206 &amp; Partial Content: 对资源某一部分进行请求(比如对于只加载了一般的图片剩余部分的请求)；301 &amp; Move Permanently: 永久性重定向；302 &amp; Found： 临时性重定向；303 &amp; See Other: 请求资源存在另一个URI，应使用get方法请求；304 &amp; Not Modified: 服务器判断本地缓存未更新，可以直接使用本地的缓存；307 &amp; Temporary Redirect: 临时重定向；400 &amp; Bad Request: 请求报文存在语法错误；401 &amp; Unauthorized: 请求需要通过HTTP认证；403 &amp; Forbidden: 请求资源被服务器拒绝，访问权限的问题；404 &amp; Not Found: 服务器上没有请求的资源；500 &amp; Internal Server Error: 服务器执行请求时出现错误；502 &amp; Bad Gateway: 错误的网关；503 &amp; Service Unavailable: 服务器超载或正在维护，无法处理请求；504 &amp; Gateway timeout: 网关超时；","categories":[{"name":"网络","slug":"网络","permalink":"https://qiongqiongwoo.github.io/blog/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"gdb调试技巧","slug":"gdb调试技巧","date":"2019-01-07T03:49:55.000Z","updated":"2021-03-22T03:10:59.478Z","comments":true,"path":"2019/01/07/gdb调试技巧/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2019/01/07/gdb%E8%B0%83%E8%AF%95%E6%8A%80%E5%B7%A7/","excerpt":"","text":"","categories":[{"name":"后端","slug":"后端","permalink":"https://qiongqiongwoo.github.io/blog/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[]},{"title":"call和apply以及this的指向深入","slug":"call和apply以及this的指向深入","date":"2018-12-24T07:14:37.000Z","updated":"2019-01-04T10:49:32.000Z","comments":true,"path":"2018/12/24/call和apply以及this的指向深入/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2018/12/24/call%E5%92%8Capply%E4%BB%A5%E5%8F%8Athis%E7%9A%84%E6%8C%87%E5%90%91%E6%B7%B1%E5%85%A5/","excerpt":"","text":"1、call的一种实现， apply的实现同下，唯一不同的是传入的arguments是全部的变量数组 1234567891011121314151617var a = &#123; name: &#x27;zhangsan&#x27;&#125;var b = function(age) &#123;console.log(this.name)console.log(age)&#125;Function.prototype.call2 = function(context)&#123; // call 和 apply的作用 是在 要绑定的obj上添加一个fn， fn为当前要执行的fn，通过执行obj.fn改变真正执行时候的this context.fn = this var args = Array.prototype.slice.call(arguments,1); var result = context.fn(...args) delete context.fn return result&#125;b.call2(a, &#x27;23&#x27;) 2、执行上下文：js引擎在执行一段代码之前，会将当前代码中用到的变量、函数以及this放到一个object中。 12345678910111213141516171819202122232425262728var a = 1;function fun() &#123; &#x27;use strict&#x27;; var a = 2; return this.a;&#125;fun();//严格模式下函数中的this为undefined，非严格模式下this = window （非严格模式下this为undefined时会默认指向window）var a = 1;Var obj = &#123; a: 2, b: function()&#123; function test()&#123; console.log(this.a) &#125; test() &#125;&#125;obj.b() // 同样在输出为1 而不是2var a = 1;Var obj = &#123; a: 2, b: function()&#123; console.log(this.a) &#125;&#125;Obj.b() // this为obj，输出为2var t = obj.bt() // 输出为1 此时代码执行的上下文为window 3、箭头函数的this是不变的 123456789101112131415var a = 1;var obj = &#123; a: 2&#125;;var fun = () =&gt; console.log(this.a); // 箭头函数会捕获当前上下文的this作为执行的this并且保持不变，此处为windowfun();//1fun.call(obj)//1function Fun() &#123; this.name = &#x27;Damonare&#x27;;&#125;Fun.prototype.say = () =&gt; &#123; console.log(this);&#125;var f = new Fun();f.say();//window say在定义时已经确定上下文是window 4、构造函数中的this代表实例对象 12345678910function Fun() &#123; this.name &#x3D; &#39;Damonre&#39;; this.age &#x3D; 21; this.sex &#x3D; &#39;man&#39;; this.run &#x3D; function () &#123; return this.name + &#39;正在跑步&#39;; &#125;&#125;var a &#x3D; new Fun();a.run() &#x2F;&#x2F; Damonre 5、 12345678function Fun() &#123; this.name = &#x27;Damonare&#x27;; this.say = () =&gt; &#123; console.log(this); &#125;&#125;var f = new Fun();f.say();//Fun的实例对象 此时的箭头函数的上下文为构造函数，构造函数的上下文为实例对象 6、执行执行上下文的创建流程（1）默认是全局上下文global context， 每遇到一个函数会创建一个函数执行上下文，进入栈， 只有在栈顶时才会激活执行上下文。（2）闭包的执行上下文创建过程 123456789function f1()&#123; var n=999; function f2()&#123; alert(n); &#125; return f2;&#125;var result=f1();result(); 通过闭包的作用域链可以发现，innerFoo在全局中保留了一个引用，导致未被回收。（3）一个执行上下文的结构如下：执行过程中对属性的查找是按照作用域链条进行查找，并且查找过程是不可逆的， 只能向后查找，因此全局的无法访问内部函数的变量。 1234567891011var a = 20;function test() &#123; var b = a + 10; function innerTest() &#123; var c = 10; console.log(f); // f最后没查找到， 返回为undefined。 return a + b + c; // 此处对a的访问，首先查找AO(innerTest),然后查找AO(test), 最后查找vo(global)查找到。 &#125; return innerTest();&#125;test();","categories":[{"name":"JS/React","slug":"JS-React","permalink":"https://qiongqiongwoo.github.io/blog/categories/JS-React/"}],"tags":[]},{"title":"JS中的概念总结","slug":"js中概念总结","date":"2018-12-23T10:32:12.000Z","updated":"2019-01-04T10:49:44.000Z","comments":true,"path":"2018/12/23/js中概念总结/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2018/12/23/js%E4%B8%AD%E6%A6%82%E5%BF%B5%E6%80%BB%E7%BB%93/","excerpt":"","text":"1、call、apply、bind的区别 call apply 和bind都是用来改变this的指向的 call 和 bind都是顺序传参数，apply是传数组 利用call和apply会直接执行当前函数，bind不会2、reduce是es5中的内容1234var arr=“qweqrq&quot;var info= arr.split(&#x27;&#x27;).reduce((a,b)=&gt; (a[b]++ || (a[b]=1),a),&#123;&#125;)console.log(info) 3、forEach、 map 、 reduce的区别 forEach 方法是将数组中的每一个值取出做一些程序员想让他们做的事情 map 方法 是将数组中的每一个值放入一个方法中做一些程序员想让他们做的事情后返回一个新的数组 reduce 方法 将数组中的每一个值与前面的被返回相加的总和(初试值为数组的第一个值或者initialValue 4、async await 以及promisepromise解决的是回调场景中的状态处理问题，async/await解决的是回调嵌套的问题。（1）async是声明在回调环境函数（2）await是运行在等待回调结果过程中（3）promise是封装了回调操作的原子任务 5、require import &amp; export &amp; moudle.exports（1）node中用的是commonJs规范，export和require（2）为了在客户端使用，因此有了amd和cmd规范，二者都是异步加载，唯一不同的是依赖的模块执行的时机不同，amd是一边加载一边执行，cmd是加载完后才执行。（3）es6中的规范是export和import，但由于commonJs深入人心，因此还是有很多人使用commonJs规范。（4）require可以出现在代码中，import只能在代码的最顶层 6、JS异步的实现方式（1）回调 =&gt; 容易出现多重嵌套的问题，代码可读性差（2）事件监听（on和fire）（3）发布和订阅（4）promise对象（5）es6中的新加的generate 1234Function *gen(x) &#123; var y = yield x + 2; return y;&#125; generator函数函数名和function之间加*，所有的执行片段用yield分割。函数的返回值是一个iterator，每次调用next就返回当前当前yield片段的值。适合于返回值有多个状态的情况。（6）es7中的await和async 7、json和jsonp的区别：json是一种数据格式、jsonp是一种跨域的数据格式传输协议 8、浏览器同源策略限制不允许跨域。 非跨域是指： 相同的域名、相同的协议、相同的端口。实现跨域的方式：（1）所有含有src属性的标签都不受同源策略限制，比如img，script，iframe，因此可以使用JSONP的方式，即客户端传递一个callback，服务端用callback包裹json数据，返回js片段，这样客户端就可以随意使用json数据，实现跨域了。比如统计点击率时经常用img标签。（jsonp的形式只支持get请求，不支持post请求。）（2）基于jquery的跨域，方式见下（9） (3) 利用document.domain进行跨域，document.domain可以进行赋值，但只可以设置为当前的域名或者基础域名。因此对于同一个基础域名的相同协议相同端口的跨域请求，可以通过设置document.domain来实现跨域。（4）window.postMessage()（5）cors：跨域资源共享是w3c的一个规范，这个主要在服务器的实现，前端发送请求没有区别。这和jsonp的区别是jsonp只支持get，cors可以支持post。 9、用jquery实现跨域的方式（1）直接将dataType设置为jsonp/当前网址是localhost:3000/js代码 123456789101112131415161718192021222324252627282930$.ajax(&#123;type:&quot;get&quot;,url:&quot;http://localhost:3000/showAll&quot;,/*url写异域的请求地址*/dataType:&quot;jsonp&quot;,/*加上datatype*/Jsonp: ‘cb&#x27;, // 传递给请求处理程序或页面的，用以获得jsonp回调函数名的参数名(默认为:callback)jsonpCallback:”success&quot;,/*设置一个回调函数，名字随便取，和下面的函数里的名字相同就行*/success:function(data)&#123; console.log(data)&#125;&#125;);/*而在异域服务器上，*/app.jsapp.get(&#x27;/showAll&#x27;,students.showAll);/*这和不跨域的写法相同*//*在异域服务器的showAll函数里，*/var db = require(&quot;./database&quot;);exports.showAll = function(req,res)&#123;/**设置响应头允许ajax跨域访问**/res.setHeader(&quot;Access-Control-Allow-Origin&quot;,&quot;*&quot;);/*星号表示所有的异域请求都可以接受，*/res.setHeader(&quot;Access-Control-Allow-Methods&quot;,&quot;GET,POST&quot;);var con = db.getCon();con.query(&quot;select * from t_students&quot;,function(error,rows)&#123;if(error)&#123;console.log(&quot;数据库出错：&quot;+error);&#125;else&#123;/*注意这里，返回的就是jsonP的回调函数名+数据了*/res.send(&quot;cb(&quot;+JSON.stringify(r)+&quot;)&quot;);&#125;&#125;);&#125; （2）直接调用$.getJson进行跨域请求数据，其内部原理是判断是否跨域、如果非跨域，直接用ajax方式发送请求，否则用script标签的方式 123jQuery.getJSON(url,data,success(data,status,function(data)&#123; Console.log(data)&#125;)) // url是可以非同源的Url，data为一起传递到服务器的数据。10、xss和csrf的区别（1）xss通过输入框或者textare等，往页面上注入一段js，csrf是伪装成当前登录用户发送请求，甚至更改当前用户的信息。（2）csrf的一种实现方式是xss，csrf注重结果。（3）xss避免的一种方式是将html标签进行过滤或者对内容进行encode，另外cookie信息不要放用户名和密码，必要时需要加md5加密，csrf的方式是前后端交互加令牌。11、cookie &amp; session（1）cookie不设置过期时间则保存在内存中，否则保存在硬盘中，下次打开会话，还能读取。cookie可以设置path和domain，且具有不可跨域性。（2）cookie是保存在浏览器上，session是保存在服务器中，因此cookie不是很安全，别人可以分析并且伪装。（3）cookie的value最大为4M，有些浏览器有限制每个站最多设置20个cookie。（4）session会占用服务器资源。12： ajax防止重复发送请求（1）点击后disable掉button（2）发送此请求时，abort掉上一个请求13：xhr（ajax）和fetch的区别（1）ajax为xhr，有abort状态(因为ajax是一个xmlhttpRequest，有个表示状态的readystatus，abort会将此值置为0，readystatus小于3，接收到的responseText未空)，fetch是基于promise实现的，只有resolve和reject状态，因而fetch没有abort状态。（2）fetch发送请求是不带cookie的，只有通过fetch（url, {credentials: ‘inlucde’ }）来加上（3）服务器返回400以及500状态是，fetch并不能reject，只有网络请求失败时会。14、ajax的readystatux状态（1） 0: 未初始化或者被abort到初始状态（2）1：已经初始化正在send请求（3）2： send已经完成（4）3： 已经解析了部分返回内容，未解析完（5）4： 相应内容已经解析完成15、函数防抖和节流（1） 防抖： 一段时间内，没有执行该函数，则一定时间后执行该函数，如果再次触发了事件，则从0开始计数，到达一定时间后再执行事件。 123456789101112131415function debounce(fn, wait) &#123; var timer = null; return function() &#123; var context = this; var args = arguments; if( timer != null) clearTimeout(timer) timer = setTimeout(() =&gt; &#123; fn.apply(context, args) &#125;, wait) &#125;&#125;function handle() &#123; Console.log(‘handle&#x27;)&#125;window.addEventListener(’scroll’, debounce(handle, 1000)) （2）节流：持续触发事件，保证一段时间内，调用一次当前函数。( 且能保证一段时间内至少执行一次) 12345678910111213141516function throttle(fn, wait) &#123; var prev = Date.now(); return function() &#123; var now = Date.now(); var context = this; var args = arguments; If (prev - now &gt; delay) &#123; fn(context, args); Prev = Date.now(); &#125; &#125;&#125;function handle() &#123; console.log(&#x27;handle&#x27;)&#125;window.addEventListener(&#x27;scroll&#x27;, throttle(handle, 1000)) 16、vue和react的对比（1）vue和react都提倡组件化开发，都是数据驱动，都是通过props向组件传递参数，都有virtual dom（2）数据绑定： vue是双向数据绑定、react是单向（3）大规模协作的项目用react方便，小的项目用vue方便（2）开发风格：react用的是jsx，vue推荐使用的是 js css都在一个文件17、 gulp 和 webpack的区别18、原型和原型链（1）每个对象都有 proto 属性， 但只有函数对象才有 prototype属性（2）对象的__proto__属性指向他的构造函数 person1.proto = Person.prototype Person.proto = Function.prototype Person.prototype.proto = Object.prototype19、img的加载 - 懒加载（1）用img的src进行加载或者用css中background加载（2）重要的信息比如logo适合用img标签，如果图片特别大，建议用css中的background，这样不会影响整体框架在加载（3）动态的设置img的src信息即可20、函数闭包（1）闭包的例子：oldLog还保持旧值，而getLogNumber用新的值的原因可以从类定义，每个函数方法保存是单独的一份这点来区分。 123456789101112131415161718var gLogNumber, gIncreaseNumber, gSetNumber;function setupSomeGlobals() &#123; // 局部变量num最后会保存在闭包中 var num = 42; // 将一些对于函数的引用存储为全局变量 gLogNumber = function() &#123; console.log(num); &#125; gIncreaseNumber = function() &#123; num++; &#125; gSetNumber = function(x) &#123; num = x; &#125;&#125;setupSomeGlobals();gIncreaseNumber();gLogNumber(); // 43gSetNumber(5);gLogNumber(); // 5var oldLog = gLogNumber;setupSomeGlobals();gLogNumber(); // 42oldLog() // 5 （2）下例中result是闭包变量，i最后值为3，list[3]是undefined 12345678910111213141516function buildList(list) &#123; var result = []; for (var i = 0; i &lt; list.length; i++) &#123; var item = &#x27;item&#x27; + i; result.push( function() &#123;console.log(item + &#x27; &#x27; + list[i])&#125; ); &#125; return result;&#125;function testList() &#123; var fnlist = buildList([1,2,3]); // 使用j是为了防止搞混---可以使用i for (var j = 0; j &lt; fnlist.length; j++) &#123; fnlist[j](); &#125;&#125; testList() //输出 &quot;item2 undefined&quot; 3 次 (3) 总结 函数内使用了关键字function就创建了一个闭包 闭包相当于一个副本，当函数退出时，所有的局部变量保存在其中 闭包函数每次被调用，都会被创建一份新的局部变量存储。21、JS中的this（1）在普通函数中，非严格模式下，this指向window，否则指向undefined；（2）作为构造函数中的this指向实例对象（3）call和apply可以改变this中的指向（4）箭头函数在执行前已经定死了this的指向22、常见的几类前端安全性问题： 老生常谈的XSS（cross site script） 处理方式： 对输入(和URL参数)进行过滤，对输出进行编码。对cookie中的关键信息设置httponly属性，防止被js读取。 警惕iframe带来的风险：防止自己的网页被iframe（1）直接判断当前网页的host是否和window.top的host是否相同(2)后台配置：header(‘X-Frame-Options:Deny’); iframe别人的网页时： 需要iframe设置sandbox属性，禁止iframe脚本、ajax请求、form表单、限制origin等 别被点击劫持了（clickjacking）利用iframe先响应click事件，防御策略是后台配置：header(‘X-Frame-Options:Deny’); 错误的内容推断 (比如：上传的图片是用js片段文件) 防火防盗防猪队友：不安全的第三方依赖包（第三方插件本身存在漏洞） 用了HTTPS也可能掉坑里，比如用户直接输入域名，未指定为https方式，会被拦截者获取并模拟服务器与前端交互，处理方式是强制前端用https进行通信 本地存储数据泄露：本地存储不放敏感信息，只放一些公共信息 缺失静态资源完整性校验：从cdn中获取的js是被拦截处理过的，导致系统不能正常运行。处理方式有：对引用的script或者css加签名，浏览器拿到资源后，首先进行内容hash，值相同才会进行下一步处理，否则不执行。（ Subresource Integrity | 内容安全策略中添加所有的 Content-Security-Policy: require-sri-for script;）23：pwa 离线缓存（1）相当于在浏览器和服务器之间加了一层service worker， 用来控制离线缓存，可以将一些不经常更改的静态文件放到缓存中，提升用户体验。并且还可以生成一个原生的操作图标。但这个强制使用https，且浏览器兼容差。24:Post请求数据的格式：（1）默认：application/x-www-form-urlencoded（2）上传图片： multipart/form-data（3）application/json;charset=utf-8（4）xml25: 硬件加速：将渲染的过程交给GPU进行处理，提高渲染性能。26: let const var区别var支持预定义 以及重复定义 其他二者不可let有了块级作用域const变量不可以改 不可以不赋值","categories":[{"name":"JS/React","slug":"JS-React","permalink":"https://qiongqiongwoo.github.io/blog/categories/JS-React/"}],"tags":[]},{"title":"BSON和JSON区别","slug":"BSON和JSON区别","date":"2018-12-23T08:16:13.000Z","updated":"2019-01-07T03:29:05.000Z","comments":true,"path":"2018/12/23/BSON和JSON区别/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2018/12/23/BSON%E5%92%8CJSON%E5%8C%BA%E5%88%AB/","excerpt":"","text":"BSON是由10gen开发的一个数据格式，目前主要用于MongoDB中，是MongoDB的数据存储格式。BSON基于JSON格式，选择JSON进行改造的原因主要是JSON的通用性及JSON的schemaless的特性。 BSON主要会实现以下三点目标： 1.更快的遍历速度对JSON格式来说，太大的JSON结构会导致数据遍历非常慢。在JSON中，要跳过一个文档进行数据读取，需要对此文档进行扫描才行，需要进行麻烦的数据结构匹配，比如括号的匹配，而BSON对JSON的一大改进就是，它会将JSON的每一个元素的长度存在元素的头部，这样你只需要读取到元素长度就能直接seek到指定的点上进行读取了。MongoDB优化：对于MongoDB来说，由于采用了MMAP来做内存与数据文件的映射，在更新或者获取Document的某一个字段时，如果需要先读取其前面的所有字段，会导致物理内存由于读操作被加载到不必要的字段上，导致资源的不合理分配。而采用BSON只需要读到相应的位置然后跨过无用内容读取需要内容即可。 2.操作更简易对JSON来说，数据存储是无类型的，比如你要修改基本一个值，从9到10，由于从一个字符变成了两个，所以可能其后面的所有内容都需要往后移一位才可以。而使用BSON，你可以指定这个列为数字列，那么无论数字从9长到10还是100，我们都只是在存储数字的那一位上进行修改，不会导致数据总长变大。当然，在MongoDB中，如果数字从整形增大到长整型，还是会导致数据总长变大的。MongoDB优化：所以使用MongoDB的一个技巧是将长度可能变化的字段尽量命名靠后（MongoDB在update操作后会将字段按key值按字母顺序重排，所以靠后的意思是按a－z的顺序取名）。这样在更新的时候如果导致数字变长，不需要移动大量数据。一个典型的例子是如果用二进制类型存储文件时，如果文件名或者文件描述可能会变长，那么尽量将这个字段取名靠后是一个明智的选择，否则在文件名或文件描述字段变化时，会导致移动很长的二进制数据，造成不必要的浪费。 3.增加了额外的数据类型JSON是一个很方便的数据交换格式，但是其类型比较有限。BSON在其基础上增加了“byte array”数据类型。这使得二进制的存储不再需要先base64转换后再存成JSON。大大减少了计算开销和数据大小。当然，在有的时候，BSON相对JSON来说也并没有空间上的优势，比如对{“field”:7}，在JSON的存储上7只使用了一个字节，而如果用BSON，那就是至少4个字节（32位）MongoDB优化：在MongoDB中，如果你的字段是数字型，并且涉及到数据加减操作的，那么建议存在int型，但如果是一个固定不变的数字，并且在四位以下的话，可以考虑存成字符串类型。这样会节省空间。目前在10gen的努力下，BSON已经有了针对多种语言的编码解码包。并且都是Apache 2 license下开源的。并且还在随着MongoDB进一步地发展。","categories":[{"name":"DataBase","slug":"DataBase","permalink":"https://qiongqiongwoo.github.io/blog/categories/DataBase/"}],"tags":[]},{"title":"React diff以及代码实现","slug":"Reactdiff以及代码实现","date":"2018-12-21T09:39:15.000Z","updated":"2019-01-04T10:49:50.000Z","comments":true,"path":"2018/12/21/Reactdiff以及代码实现/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2018/12/21/Reactdiff%E4%BB%A5%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"因为虚拟DOM是内存数据，性能是极高的，而对实际DOM进行操作的仅仅是Diff部分，因而能达到提高性能的目的。这样就需要每次获取dom的diff。react diff（1）diff 流程（2）tree diff: 假设： web ui 中 dom节点跨层级移动的操作很少，可以忽略不计。 优化：两棵树只比较同层节点是否相等，如果不等，直接删除，否则新建。 缺点： 如果出现跨层操作，比如将A整个移动到D下，整个处理过程为：create A -&gt; create B -&gt; create C -&gt; delete A， 效率很低。 指导原则： 不要使用dom节点的跨层级操作，可以用dom的显示和隐藏进行控制。（2）component diff假设：相同类的两个组件拥有相同的结构，不同类的两个组件的结构不同。优化：相同类的两个组件按照virtual dom的方式继续进行比较，不同类的两个组件直接替换，不进行比较，相同类的两个组件可以通过shouldComponentUpdate来进行比较。缺点： 两个component结构相似单直接导致替换，但实际开发中情况很少。指导原则：定义组件的shouldComponentUpdate （3）element diff假设：同一层的一组节点可以通过定个唯一的key来进行区分优化：同一层的一组节点定义唯一的key，通过key进行比较和重建重建方式: 遍历新的节点顺序，如果当前的节点在旧的结构中的挂载Index &lt; 当前的遍历Index值，则对当前节点进行移动，否则不移动。缺点：如果将最后的一个节点移动到了行首，会导致整个链上的节点的移动，效率很低。指导原则：不要讲最后一个节点移动到行首。diff的差异比较过程如下：首先对新集合的节点进行循环遍历，for (name in nextChildren)，通过唯一 key 可以判断新老集合中是否存在相同的节点，if (prevChild === nextChild)，如果存在相同节点，则进行移动操作，但在移动前需要将当前节点在老集合中的位置与 lastIndex 进行比较，if (child._mountIndex &lt; lastIndex)，则进行节点移动操作，否则不执行该操作。这是一种顺序优化手段，lastIndex 一直在更新，表示访问过的节点在老集合中最右的位置（即最大的位置），如果新集合中当前访问的节点比 lastIndex 大，说明当前访问节点在老集合中就比上一个节点位置靠后，则该节点不会影响其他节点的位置，因此不用添加到差异队列中，即不执行移动操作，只有当访问的节点比 lastIndex 小时，才需要进行移动操作。以上图为例，可以更为清晰直观的描述 diff 的差异对比过程： 从新集合中取得 B，判断老集合中存在相同节点 B，通过对比节点位置判断是否进行移动操作，B 在老集合中的位置 B._mountIndex = 1，此时 lastIndex = 0，不满足 child._mountIndex &lt; lastIndex 的条件，因此不对 B 进行移动操作；更新 lastIndex = Math.max(prevChild._mountIndex, lastIndex)，其中 prevChild._mountIndex 表示 B 在老集合中的位置，则 lastIndex ＝ 1，并将 B 的位置更新为新集合中的位置prevChild._mountIndex = nextIndex，此时新集合中 B._mountIndex = 0，nextIndex++ 进入下一个节点的判断。 从新集合中取得 A，判断老集合中存在相同节点 A，通过对比节点位置判断是否进行移动操作，A 在老集合中的位置 A._mountIndex = 0，此时 lastIndex = 1，满足 child._mountIndex &lt; lastIndex的条件，因此对 A 进行移动操作enqueueMove(this, child._mountIndex, toIndex)，其中 toIndex 其实就是 nextIndex，表示 A 需要移动到的位置；更新 lastIndex = Math.max(prevChild._mountIndex, lastIndex)，则 lastIndex ＝ 1，并将 A 的位置更新为新集合中的位置 prevChild._mountIndex = nextIndex，此时新集合中A._mountIndex = 1，nextIndex++ 进入下一个节点的判断。 从新集合中取得 D，判断老集合中存在相同节点 D，通过对比节点位置判断是否进行移动操作，D 在老集合中的位置 D._mountIndex = 3，此时 lastIndex = 1，不满足 child._mountIndex &lt; lastIndex的条件，因此不对 D 进行移动操作；更新 lastIndex = Math.max(prevChild._mountIndex, lastIndex)，则 lastIndex ＝ 3，并将 D 的位置更新为新集合中的位置 prevChild._mountIndex = nextIndex，此时新集合中D._mountIndex = 2，nextIndex++ 进入下一个节点的判断。 从新集合中取得 C，判断老集合中存在相同节点 C，通过对比节点位置判断是否进行移动操作，C 在老集合中的位置 C._mountIndex = 2，此时 lastIndex = 3，满足 child._mountIndex &lt; lastIndex 的条件，因此对 C 进行移动操作 enqueueMove(this, child._mountIndex, toIndex)；更新 lastIndex = Math.max(prevChild._mountIndex, lastIndex)，则 lastIndex ＝ 3，并将 C 的位置更新为新集合中的位置 prevChild._mountIndex = nextIndex，此时新集合中 C._mountIndex = 3，nextIndex++ 进入下一个节点的判断，由于 C 已经是最后一个节点，因此 diff 到此完成。以上主要分析新老集合中存在相同节点但位置不同时，对节点进行位置移动的情况，如果新集合中有新加入的节点且老集合存在需要删除的节点，那么 React diff 又是如何对比运作的呢？以下图为例： 从新集合中取得 B，判断老集合中存在相同节点 B，由于 B 在老集合中的位置 B._mountIndex = 1，此时lastIndex = 0，因此不对 B 进行移动操作；更新 lastIndex ＝ 1，并将 B 的位置更新为新集合中的位置B._mountIndex = 0，nextIndex++进入下一个节点的判断。 从新集合中取得 E，判断老集合中不存在相同节点 E，则创建新节点 E；更新 lastIndex ＝ 1，并将 E 的位置更新为新集合中的位置，nextIndex++进入下一个节点的判断。 从新集合中取得 C，判断老集合中存在相同节点 C，由于 C 在老集合中的位置C._mountIndex = 2，lastIndex = 1，此时 C._mountIndex &gt; lastIndex，因此不对 C 进行移动操作；更新 lastIndex ＝ 2，并将 C 的位置更新为新集合中的位置，nextIndex++ 进入下一个节点的判断。 从新集合中取得 A，判断老集合中存在相同节点 A，由于 A 在老集合中的位置A._mountIndex = 0，lastIndex = 2，此时 A._mountIndex &lt; lastIndex，因此对 A 进行移动操作；更新 lastIndex ＝ 2，并将 A 的位置更新为新集合中的位置，nextIndex++ 进入下一个节点的判断。 当完成新集合中所有节点 diff 时，最后还需要对老集合进行循环遍历，判断是否存在新集合中没有但老集合中仍存在的节点，发现存在这样的节点 D，因此删除节点 D，到此 diff 全部完成。react diff代码实现解析（1）component的mountComponent完成组件的第一次render，receiveComponent完成组件的更新处理。组件的setState的实现即是调用receiveComponent的处理。（2）receiveComponent的处理流程: receiveComponent = function(nextElement, newState) 更新当前组件的currentElement（保存组件的render类型，p还是div，还是自定义的element类型1或者自定义的element2）this._currentElement = nextElement || this._currentElement (组件的render类型对应diff原则中的不同类型的组件重新渲染原则) newState = 旧的state merge newState 如果组件有自定义的shouldComponentUpdate方法，如果此方法返回为false，不再进行更新直接返回。 如果组件有定义componentWillUpdate（更新前的处理方法），调用此方法，表示开始更新。 重新执行组件的render方法，拿到新的element（nextRenderedElemnt）（此过程在内存中进行，而非真正的渲染） 调用全局的shouldUpdateComponent(prevRenderedElement, nextRenderedElement)方法，此方法的输入为两个element，如果element类型为基础类型，直接返回false，否则递归调用子元素的此方法 shouldUpdateComponent(prevRenderedElement, nextRenderedElement)返回为false的情况下（为基础节点或者两个非基础节点，但类型不同），则直接将整个dom节点进行替换，并更新到dom中。（3）shouldUpdateComponent(prevRenderedElement, nextRenderedElement) 为整个diff实现的主要方法，流程如下：（判断：当前节点是进行全局替换还是进行局部比较替换）（生成新的element以及element进行比较的过程是在内存中进行，而非替换真正的dom，所以效率是极高的） 判断prevElement是否为基础类型，如果是基础类型，直接返回nextElement是否为基础类型，如果是基础类型，调用prevElement的更新操作，否则执行render以及整个替换操作 prevElement不是基础类型，并且nextElement也不是基础类型，并且type类型相同且key相同，执行子节点的update操作，否则直接进行整个节点的替换操作（4）receiveComponent逻辑 文本类型：receiveComponent = function (newTextString) { $(‘[data-reactid=“‘+this._rootNodeId+’”]’).html(newTextString); } 基本类型的更新： 首先更新当前节点的props属性，然后递归调用，更新每个子节点（updateDOMChildren）（子节点或者为文本类型或者为基本类型，如果子节点为自定义类型如何处理？）属性的更新过程： 如果在新的属性中不包含的属性，删掉，如果是新添加的属性，添加，否则进行值替换。这些操作为真正的dom操作，不同类型的属性的更新和生效方式也不同，需要特别处理。 自定义类型：(5) updateDOMChildren的处理逻辑（全局的diffQueue队列，diff方法，以及获取到diffQueue后的patch更新操作），所以关键是diff和patch方法。diff操作对应diff原则中的element diff diff方法处理流程： diff(diffQueue, nextChildrenElements) nextChildrenElements利用key或者id处理成map形式,方便下面的diff处理（flatternChildren） 调用gennerateComponentChildren生成新的nextChildren，此方法中根据新旧child的不同调用上面提到的shouldUpdateReactComponent方法做到最小粒度度更新 对新旧children进行比较，标记上三种状态： move_existing(新的componet在旧的中存在，只移动)，insert_makeup(新的不存在或者新旧类型不同，需要新建并且插入)， remove_node(旧的组件在新的中不存在或者类型发生了变化，需要删除) 得到diffQueue后执行patch操作流程 第一遍遍历queue删除所有标记为要删除的节点 第二遍处理插入和要修改的节点 最终迷你版本的react js实现如下： (这个已经不记得转载的哪里的了) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572//component类，用来表示文本在渲染，更新，删除时应该做些什么事情function ReactDOMTextComponent(text) &#123; //存下当前的字符串 this._currentElement = &#x27;&#x27; + text; //用来标识当前component this._rootNodeID = null;&#125;//component渲染时生成的dom结构ReactDOMTextComponent.prototype.mountComponent = function(rootID) &#123; this._rootNodeID = rootID; return &#x27;&lt;span data-reactid=&quot;&#x27; + rootID + &#x27;&quot;&gt;&#x27; + this._currentElement + &#x27;&lt;/span&gt;&#x27;;&#125;ReactDOMTextComponent.prototype.receiveComponent = function(nextText) &#123; var nextStringText = &#x27;&#x27; + nextText; //跟以前保存的字符串比较 if (nextStringText !== this._currentElement) &#123; this._currentElement = nextStringText; //替换整个节点 $(&#x27;[data-reactid=&quot;&#x27; + this._rootNodeID + &#x27;&quot;]&#x27;).html(this._currentElement); &#125;&#125;//component类，用来表示文本在渲染，更新，删除时应该做些什么事情function ReactDOMComponent(element) &#123; //存下当前的element对象引用 this._currentElement = element; this._rootNodeID = null;&#125;//component渲染时生成的dom结构ReactDOMComponent.prototype.mountComponent = function(rootID) &#123; //赋值标识 this._rootNodeID = rootID; var props = this._currentElement.props; var tagOpen = &#x27;&lt;&#x27; + this._currentElement.type; var tagClose = &#x27;&lt;/&#x27; + this._currentElement.type + &#x27;&gt;&#x27;; //加上reactid标识 tagOpen += &#x27; data-reactid=&#x27; + this._rootNodeID; //拼凑出属性 for (var propKey in props) &#123; //这里要做一下事件的监听，就是从属性props里面解析拿出on开头的事件属性的对应事件监听 if (/^on[A-Za-z]/.test(propKey)) &#123; var eventType = propKey.replace(&#x27;on&#x27;, &#x27;&#x27;); //针对当前的节点添加事件代理,以_rootNodeID为命名空间 $(document).delegate(&#x27;[data-reactid=&quot;&#x27; + this._rootNodeID + &#x27;&quot;]&#x27;, eventType + &#x27;.&#x27; + this._rootNodeID, props[propKey]); &#125; //对于children属性以及事件监听的属性不需要进行字符串拼接 //事件会代理到全局。这边不能拼到dom上不然会产生原生的事件监听 if (props[propKey] &amp;&amp; propKey != &#x27;children&#x27; &amp;&amp; !/^on[A-Za-z]/.test(propKey)) &#123; tagOpen += &#x27; &#x27; + propKey + &#x27;=&#x27; + props[propKey]; &#125; &#125; //获取子节点渲染出的内容 var content = &#x27;&#x27;; var children = props.children || []; var childrenInstances = []; //用于保存所有的子节点的componet实例，以后会用到 var that = this; $.each(children, function(key, child) &#123; //这里再次调用了instantiateReactComponent实例化子节点component类，拼接好返回 var childComponentInstance = instantiateReactComponent(child); childComponentInstance._mountIndex = key; childrenInstances.push(childComponentInstance); //子节点的rootId是父节点的rootId加上新的key也就是顺序的值拼成的新值 var curRootId = that._rootNodeID + &#x27;.&#x27; + key; //得到子节点的渲染内容 var childMarkup = childComponentInstance.mountComponent(curRootId); //拼接在一起 content += &#x27; &#x27; + childMarkup; &#125;) //留给以后更新时用的这边先不用管 this._renderedChildren = childrenInstances; //拼出整个html内容 return tagOpen + &#x27;&gt;&#x27; + content + tagClose;&#125;ReactDOMComponent.prototype.receiveComponent = function(nextElement) &#123; var lastProps = this._currentElement.props; var nextProps = nextElement.props; this._currentElement = nextElement; //需要单独的更新属性 this._updateDOMProperties(lastProps, nextProps); //再更新子节点 this._updateDOMChildren(nextElement.props.children);&#125;ReactDOMComponent.prototype._updateDOMProperties = function(lastProps, nextProps) &#123; var propKey; //遍历，当一个老的属性不在新的属性集合里时，需要删除掉。 for (propKey in lastProps) &#123; //新的属性里有，或者propKey是在原型上的直接跳过。这样剩下的都是不在新属性集合里的。需要删除 if (nextProps.hasOwnProperty(propKey) || !lastProps.hasOwnProperty(propKey)) &#123; continue; &#125; //对于那种特殊的，比如这里的事件监听的属性我们需要去掉监听 if (/^on[A-Za-z]/.test(propKey)) &#123; var eventType = propKey.replace(&#x27;on&#x27;, &#x27;&#x27;); //针对当前的节点取消事件代理 $(document).undelegate(&#x27;[data-reactid=&quot;&#x27; + this._rootNodeID + &#x27;&quot;]&#x27;, eventType, lastProps[propKey]); continue; &#125; //从dom上删除不需要的属性 $(&#x27;[data-reactid=&quot;&#x27; + this._rootNodeID + &#x27;&quot;]&#x27;).removeAttr(propKey) &#125; //对于新的属性，需要写到dom节点上 for (propKey in nextProps) &#123; //对于事件监听的属性我们需要特殊处理 if (/^on[A-Za-z]/.test(propKey)) &#123; var eventType = propKey.replace(&#x27;on&#x27;, &#x27;&#x27;); //以前如果已经有，说明有了监听，需要先去掉 lastProps[propKey] &amp;&amp; $(document).undelegate(&#x27;[data-reactid=&quot;&#x27; + this._rootNodeID + &#x27;&quot;]&#x27;, eventType, lastProps[propKey]); //针对当前的节点添加事件代理,以_rootNodeID为命名空间 $(document).delegate(&#x27;[data-reactid=&quot;&#x27; + this._rootNodeID + &#x27;&quot;]&#x27;, eventType + &#x27;.&#x27; + this._rootNodeID, nextProps[propKey]); continue; &#125; if (propKey == &#x27;children&#x27;) continue; //添加新的属性，或者是更新老的同名属性 $(&#x27;[data-reactid=&quot;&#x27; + this._rootNodeID + &#x27;&quot;]&#x27;).prop(propKey, nextProps[propKey]) &#125;&#125;//全局的更新深度标识var updateDepth = 0;//全局的更新队列，所有的差异都存在这里var diffQueue = [];ReactDOMComponent.prototype._updateDOMChildren = function(nextChildrenElements) &#123; updateDepth++ //_diff用来递归找出差别,组装差异对象,添加到更新队列diffQueue。 this._diff(diffQueue, nextChildrenElements); updateDepth-- if (updateDepth == 0) &#123; //在需要的时候调用patch，执行具体的dom操作 this._patch(diffQueue); diffQueue = []; &#125;&#125;//差异更新的几种类型var UPATE_TYPES = &#123; MOVE_EXISTING: 1, REMOVE_NODE: 2, INSERT_MARKUP: 3&#125;//普通的children是一个数组，此方法把它转换成一个map,key就是element的key,如果是text节点或者element创建时并没有传入key,就直接用在数组里的index标识function flattenChildren(componentChildren) &#123; var child; var name; var childrenMap = &#123;&#125;; for (var i = 0; i &lt; componentChildren.length; i++) &#123; child = componentChildren[i]; name = child &amp;&amp; child._currentelement &amp;&amp; child._currentelement.key ? child._currentelement.key : i.toString(36); childrenMap[name] = child; &#125; return childrenMap;&#125;//主要用来生成子节点elements的component集合//这边注意，有个判断逻辑，如果发现是更新，就会继续使用以前的componentInstance,调用对应的receiveComponent。//如果是新的节点，就会重新生成一个新的componentInstance，function generateComponentChildren(prevChildren, nextChildrenElements) &#123; var nextChildren = &#123;&#125;; nextChildrenElements = nextChildrenElements || []; $.each(nextChildrenElements, function(index, element) &#123; var name = element.key ? element.key : index; var prevChild = prevChildren &amp;&amp; prevChildren[name]; var prevElement = prevChild &amp;&amp; prevChild._currentElement; var nextElement = element; //调用_shouldUpdateReactComponent判断是否是更新 if (_shouldUpdateReactComponent(prevElement, nextElement)) &#123; //更新的话直接递归调用子节点的receiveComponent就好了 prevChild.receiveComponent(nextElement); //然后继续使用老的component nextChildren[name] = prevChild; &#125; else &#123; //对于没有老的，那就重新新增一个，重新生成一个component var nextChildInstance = instantiateReactComponent(nextElement, null); //使用新的component nextChildren[name] = nextChildInstance; &#125; &#125;) return nextChildren;&#125;//_diff用来递归找出差别,组装差异对象,添加到更新队列diffQueue。ReactDOMComponent.prototype._diff = function(diffQueue, nextChildrenElements) &#123; var self = this; //拿到之前的子节点的 component类型对象的集合,这个是在刚开始渲染时赋值的，记不得的可以翻上面 //_renderedChildren 本来是数组，我们搞成map var prevChildren = flattenChildren(self._renderedChildren); //生成新的子节点的component对象集合，这里注意，会复用老的component对象 var nextChildren = generateComponentChildren(prevChildren, nextChildrenElements); //重新赋值_renderedChildren，使用最新的。 self._renderedChildren = [] $.each(nextChildren, function(key, instance) &#123; self._renderedChildren.push(instance); &#125;) /**注意新增代码**/ var lastIndex = 0; //代表访问的最后一次的老的集合的位置 var nextIndex = 0; //代表到达的新的节点的index //通过对比两个集合的差异，组装差异节点添加到队列中 for (name in nextChildren) &#123; if (!nextChildren.hasOwnProperty(name)) &#123; continue; &#125; var prevChild = prevChildren &amp;&amp; prevChildren[name]; var nextChild = nextChildren[name]; //相同的话，说明是使用的同一个component,所以我们需要做移动的操作 if (prevChild === nextChild) &#123; //添加差异对象，类型：MOVE_EXISTING /**注意新增代码**/ prevChild._mountIndex &lt; lastIndex &amp;&amp; diffQueue.push(&#123; parentId: self._rootNodeID, parentNode: $(&#x27;[data-reactid=&#x27; + self._rootNodeID + &#x27;]&#x27;), type: UPATE_TYPES.MOVE_EXISTING, fromIndex: prevChild._mountIndex, toIndex: nextIndex &#125;) /**注意新增代码**/ lastIndex = Math.max(prevChild._mountIndex, lastIndex); &#125; else &#123; //如果不相同，说明是新增加的节点 //但是如果老的还存在，就是element不同，但是component一样。我们需要把它对应的老的element删除。 if (prevChild) &#123; //添加差异对象，类型：REMOVE_NODE diffQueue.push(&#123; parentId: self._rootNodeID, parentNode: $(&#x27;[data-reactid=&#x27; + self._rootNodeID + &#x27;]&#x27;), type: UPATE_TYPES.REMOVE_NODE, fromIndex: prevChild._mountIndex, toIndex: null &#125;) //如果以前已经渲染过了，记得先去掉以前所有的事件监听，通过命名空间全部清空 if (prevChild._rootNodeID) &#123; $(document).undelegate(&#x27;.&#x27; + prevChild._rootNodeID); &#125; /**注意新增代码**/ lastIndex = Math.max(prevChild._mountIndex, lastIndex); &#125; //新增加的节点，也组装差异对象放到队列里 //添加差异对象，类型：INSERT_MARKUP diffQueue.push(&#123; parentId: self._rootNodeID, parentNode: $(&#x27;[data-reactid=&#x27; + self._rootNodeID + &#x27;]&#x27;), type: UPATE_TYPES.INSERT_MARKUP, fromIndex: null, toIndex: nextIndex, markup: nextChild.mountComponent(self._rootNodeID + &#x27;.&#x27; + name) //新增的节点，多一个此属性，表示新节点的dom内容 &#125;) &#125; //更新mount的index nextChild._mountIndex = nextIndex; nextIndex++; &#125; //对于老的节点里有，新的节点里没有的那些，也全都删除掉 for (name in prevChildren) &#123; if (prevChildren.hasOwnProperty(name) &amp;&amp; !(nextChildren &amp;&amp; nextChildren.hasOwnProperty(name))) &#123; //添加差异对象，类型：REMOVE_NODE diffQueue.push(&#123; parentId: self._rootNodeID, parentNode: $(&#x27;[data-reactid=&#x27; + self._rootNodeID + &#x27;]&#x27;), type: UPATE_TYPES.REMOVE_NODE, fromIndex: prevChildren[name]._mountIndex, toIndex: null &#125;) //如果以前已经渲染过了，记得先去掉以前所有的事件监听 if (prevChildren[name]._rootNodeID) &#123; $(document).undelegate(&#x27;.&#x27; + prevChildren[name]._rootNodeID); &#125; &#125; &#125;&#125;//用于将childNode插入到指定位置function insertChildAt(parentNode, childNode, index) &#123; var beforeChild = parentNode.children().get(index); beforeChild ? childNode.insertBefore(beforeChild) : childNode.appendTo(parentNode);&#125;ReactDOMComponent.prototype._patch = function(updates) &#123; var update; var initialChildren = &#123;&#125;; var deleteChildren = []; for (var i = 0; i &lt; updates.length; i++) &#123; update = updates[i]; if (update.type === UPATE_TYPES.MOVE_EXISTING || update.type === UPATE_TYPES.REMOVE_NODE) &#123; var updatedIndex = update.fromIndex; var updatedChild = $(update.parentNode.children().get(updatedIndex)); var parentID = update.parentID; //所有需要更新的节点都保存下来，方便后面使用 initialChildren[parentID] = initialChildren[parentID] || []; //使用parentID作为简易命名空间 initialChildren[parentID][updatedIndex] = updatedChild; //所有需要修改的节点先删除,对于move的，后面再重新插入到正确的位置即可 deleteChildren.push(updatedChild) &#125; &#125; //删除所有需要先删除的 $.each(deleteChildren, function(index, child) &#123; $(child).remove(); &#125;) //再遍历一次，这次处理新增的节点，还有修改的节点这里也要重新插入 for (var k = 0; k &lt; updates.length; k++) &#123; update = updates[k]; switch (update.type) &#123; case UPATE_TYPES.INSERT_MARKUP: insertChildAt(update.parentNode, $(update.markup), update.toIndex); break; case UPATE_TYPES.MOVE_EXISTING: insertChildAt(update.parentNode, initialChildren[update.parentID][update.fromIndex], update.toIndex); break; case UPATE_TYPES.REMOVE_NODE: // 什么都不需要做，因为上面已经帮忙删除掉了 break; &#125; &#125;&#125;function ReactCompositeComponent(element) &#123; //存放元素element对象 this._currentElement = element; //存放唯一标识 this._rootNodeID = null; //存放对应的ReactClass的实例 this._instance = null;&#125;//用于返回当前自定义元素渲染时应该返回的内容ReactCompositeComponent.prototype.mountComponent = function(rootID) &#123; this._rootNodeID = rootID; //拿到当前元素对应的属性值 var publicProps = this._currentElement.props; //拿到对应的ReactClass var ReactClass = this._currentElement.type; // Initialize the public class var inst = new ReactClass(publicProps); this._instance = inst; //保留对当前comonent的引用，下面更新会用到 inst._reactInternalInstance = this; if (inst.componentWillMount) &#123; inst.componentWillMount(); //这里在原始的reactjs其实还有一层处理，就是 componentWillMount调用setstate，不会触发rerender而是自动提前合并，这里为了保持简单，就略去了 &#125; //调用ReactClass的实例的render方法,返回一个element或者一个文本节点 var renderedElement = this._instance.render(); //得到renderedElement对应的component类实例 var renderedComponentInstance = instantiateReactComponent(renderedElement); this._renderedComponent = renderedComponentInstance; //存起来留作后用 //拿到渲染之后的字符串内容，将当前的_rootNodeID传给render出的节点 var renderedMarkup = renderedComponentInstance.mountComponent(this._rootNodeID); //之前我们在React.render方法最后触发了mountReady事件，所以这里可以监听，在渲染完成后会触发。 $(document).on(&#x27;mountReady&#x27;, function() &#123; //调用inst.componentDidMount inst.componentDidMount &amp;&amp; inst.componentDidMount(); &#125;); return renderedMarkup;&#125;ReactCompositeComponent.prototype.receiveComponent = function(nextElement, newState) &#123; //如果接受了新的，就使用最新的element this._currentElement = nextElement || this._currentElement var inst = this._instance; //合并state var nextState = $.extend(inst.state, newState); var nextProps = this._currentElement.props; //改写state inst.state = nextState; //如果inst有shouldComponentUpdate并且返回false。说明组件本身判断不要更新，就直接返回。 if (inst.shouldComponentUpdate &amp;&amp; (inst.shouldComponentUpdate(nextProps, nextState) === false)) return; //生命周期管理，如果有componentWillUpdate，就调用，表示开始要更新了。 if (inst.componentWillUpdate) inst.componentWillUpdate(nextProps, nextState); var prevComponentInstance = this._renderedComponent; var prevRenderedElement = prevComponentInstance._currentElement; //重新执行render拿到对应的新element; var nextRenderedElement = this._instance.render(); //判断是需要更新还是直接就重新渲染 //注意这里的_shouldUpdateReactComponent跟上面的不同哦 这个是全局的方法 if (_shouldUpdateReactComponent(prevRenderedElement, nextRenderedElement)) &#123; //如果需要更新，就继续调用子节点的receiveComponent的方法，传入新的element更新子节点。 prevComponentInstance.receiveComponent(nextRenderedElement); //调用componentDidUpdate表示更新完成了 inst.componentDidUpdate &amp;&amp; inst.componentDidUpdate(); &#125; else &#123; //如果发现完全是不同的两种element，那就干脆重新渲染了 var thisID = this._rootNodeID; //重新new一个对应的component， this._renderedComponent = this._instantiateReactComponent(nextRenderedElement); //重新生成对应的元素内容 var nextMarkup = _renderedComponent.mountComponent(thisID); //替换整个节点 $(&#x27;[data-reactid=&quot;&#x27; + this._rootNodeID + &#x27;&quot;]&#x27;).replaceWith(nextMarkup); &#125;&#125;//用来判定两个element需不需要更新//这里的key是我们createElement的时候可以选择性的传入的。用来标识这个element，当发现key不同时，我们就可以直接重新渲染，不需要去更新了。var _shouldUpdateReactComponent = function(prevElement, nextElement) &#123; if (prevElement != null &amp;&amp; nextElement != null) &#123; var prevType = typeof prevElement; var nextType = typeof nextElement; if (prevType === &#x27;string&#x27; || prevType === &#x27;number&#x27;) &#123; return nextType === &#x27;string&#x27; || nextType === &#x27;number&#x27;; &#125; else &#123; return nextType === &#x27;object&#x27; &amp;&amp; prevElement.type === nextElement.type &amp;&amp; prevElement.key === nextElement.key; &#125; &#125; return false;&#125;function instantiateReactComponent(node) &#123; //文本节点的情况 if (typeof node === &#x27;string&#x27; || typeof node === &#x27;number&#x27;) &#123; return new ReactDOMTextComponent(node); &#125; //浏览器默认节点的情况 if (typeof node === &#x27;object&#x27; &amp;&amp; typeof node.type === &#x27;string&#x27;) &#123; //注意这里，使用了一种新的component return new ReactDOMComponent(node); &#125; //自定义的元素节点 if (typeof node === &#x27;object&#x27; &amp;&amp; typeof node.type === &#x27;function&#x27;) &#123; //注意这里，使用新的component,专门针对自定义元素 return new ReactCompositeComponent(node); &#125;&#125;//ReactElement就是虚拟dom的概念，具有一个type属性代表当前的节点类型，还有节点的属性props//比如对于div这样的节点type就是div，props就是那些propibutes//另外这里的key,可以用来标识这个element，用于优化以后的更新，这里可以先不管，知道有这么个东西就好了function ReactElement(type,key,props)&#123; this.type = type; this.key = key; this.props = props;&#125;//定义ReactClass类,所有自定义的超级父类var ReactClass = function() &#123;&#125; //留给子类去继承覆盖ReactClass.prototype.render = function() &#123;&#125;//setStateReactClass.prototype.setState = function(newState) &#123; //还记得我们在ReactCompositeComponent里面mount的时候 做了赋值 //所以这里可以拿到 对应的ReactCompositeComponent的实例_reactInternalInstance this._reactInternalInstance.receiveComponent(null, newState);&#125;React = &#123; nextReactRootIndex: 0, createClass: function(spec) &#123; //生成一个子类 var Constructor = function(props) &#123; this.props = props; this.state = this.getInitialState ? this.getInitialState() : null; &#125; //原型继承，继承超级父类 Constructor.prototype = new ReactClass(); Constructor.prototype.constructor = Constructor; //混入spec到原型 $.extend(Constructor.prototype, spec); return Constructor; &#125;, createElement: function(type, config, children) &#123; var props = &#123;&#125;,propName; config = config || &#123;&#125; //看有没有key，用来标识element的类型，方便以后高效的更新，这里可以先不管 var key = config.key || null; //复制config里的内容到props for (propName in config) &#123; if (config.hasOwnProperty(propName) &amp;&amp; propName !== &#x27;key&#x27;) &#123; props[propName] = config[propName]; &#125; &#125; //处理children,全部挂载到props的children属性上 //支持两种写法，如果只有一个参数，直接赋值给children，否则做合并处理 var childrenLength = arguments.length - 2; if (childrenLength === 1) &#123; props.children = $.isArray(children) ? children : [children] ; &#125; else if (childrenLength &gt; 1) &#123; var childArray = Array(childrenLength); for (var i = 0; i &lt; childrenLength; i++) &#123; childArray[i] = arguments[i + 2]; &#125; props.children = childArray; &#125; return new ReactElement(type, key,props); &#125;, render: function(element, container) &#123; var componentInstance = instantiateReactComponent(element); var markup = componentInstance.mountComponent(React.nextReactRootIndex++); $(container).html(markup); //触发完成mount的事件 $(document).trigger(&#x27;mountReady&#x27;); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html;charset=utf-8&quot;&gt;&lt;script src=&quot;http://apps.bdimg.com/libs/jquery/2.1.4/jquery.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;./react-little.js&quot;&gt;&lt;/script&gt;&lt;style type=&quot;text/css&quot;&gt; #container&#123; width: 500px; background-color: #fafafa; min-height: 200px; margin: 100px auto; text-align: center; padding: 20px; &#125; #container p&#123; display: inline-block; border: 1px solid #999; padding: 5px 5px; cursor: pointer; &#125; #container input&#123; width: 200px; border: 1px solid #999; padding: 6px; vertical-align: 1px; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=&quot;container&quot;&gt;&lt;/div&gt;&lt;script type=&quot;text/javascript&quot;&gt;var TodoList = React.createClass(&#123; getInitialState: function() &#123; return &#123;items: []&#125;; &#125;, add:function()&#123; var nextItems = this.state.items.concat([this.state.text]); this.setState(&#123;items: nextItems, text: &#x27;&#x27;&#125;); &#125;, onChange: function(e) &#123; this.setState(&#123;text: e.target.value&#125;); &#125;, render: function() &#123; var createItem = function(itemText) &#123; return React.createElement(&quot;div&quot;, null, itemText); &#125;; var lists = this.state.items.map(createItem); var input = React.createElement(&quot;input&quot;, &#123;onkeyup: this.onChange.bind(this),value: this.state.text&#125;); var button = React.createElement(&quot;p&quot;, &#123;onclick: this.add.bind(this)&#125;, &#x27;Add#&#x27; + (this.state.items.length + 1)) var children = [input,button].concat(lists) return React.createElement(&quot;div&quot;, null,children); &#125;&#125;);React.render(React.createElement(TodoList), document.getElementById(&quot;container&quot;));&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;","categories":[{"name":"JS/React","slug":"JS-React","permalink":"https://qiongqiongwoo.github.io/blog/categories/JS-React/"}],"tags":[]},{"title":"JS设计模式","slug":"JS设计模式","date":"2018-12-17T09:12:07.000Z","updated":"2019-01-08T04:06:18.000Z","comments":true,"path":"2018/12/17/JS设计模式/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2018/12/17/JS%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"讲 Javascript 设计模式的书还比较少，《 Pro javaScript Design Patterns 》 是比较经典的一本，但是它里面的例子举得比较啰嗦，所以结合我在工作中写过的代码，把我的理解总结一下。如果我的理解出现了偏差，请不吝指正。 单例模式单例模式的定义是产生一个类的唯一实例，但js本身是一种“无类”语言。很多讲js设计模式的文章把{}当成一个单例来使用也勉强说得通。因为js生成对象的方式有很多种，我们来看下另一种更有意义的单例。有这样一个常见的需求，点击某个按钮的时候需要在页面弹出一个遮罩层。这个生成灰色背景遮罩层的代码是很好写的： 1234567var createMask = function()&#123; return document,body.appendChild( document.createElement(div) );&#125;$( &#x27;button&#x27; ).click( function()&#123; var mask = createMask(); mask.show();&#125;) 问题是, 这个遮罩层是全局唯一的, 那么每次调用createMask都会创建一个新的div, 虽然可以在隐藏遮罩层的把它remove掉. 但显然这样做不合理.再看下第二种方案, 在页面的一开始就创建好这个div. 然后用一个变量引用它. 1234var mask = document.body.appendChild( document.createElement( &#x27;&#x27;div&#x27; ) );$( &#x27;&#x27;button&#x27; ).click( function()&#123; mask.show();&#125; ) 这样确实在页面只会创建一个遮罩层div, 但是另外一个问题随之而来, 也许我们永远都不需要这个遮罩层, 那又浪费掉一个div, 对dom节点的任何操作都应该非常吝啬.如果可以借助一个变量. 来判断是否已经创建过div呢? 12345678var mask;var createMask = function()&#123; if ( mask ) return mask; else&#123; mask = document,body.appendChild( document.createElement(div) ); return mask; &#125;&#125; 看起来不错, 到这里的确完成了一个产生单列对象的函数. 我们再仔细看这段代码有什么不妥.首先这个函数是存在一定副作用的, 函数体内改变了外界变量mask的引用, 在多人协作的项目中, createMask是个不安全的函数. 另一方面, mask这个全局变量并不是非需不可. 再来改进一下： 123456var createMask = function()&#123; var mask; return function()&#123; return mask || ( mask = document.body.appendChild( document.createElement(&#x27;div&#x27;) ) ) &#125;&#125;() 用了个简单的闭包把变量mask包起来, 至少对于createMask函数来讲, 它是封闭的。可能看到这里, 会觉得单例模式也太简单了. 的确一些设计模式都是非常简单的, 即使从没关注过设计模式的概念, 在平时的代码中也不知不觉用到了一些设计模式. 就像多年前我明白老汉推车是什么回事的时候也想过尼玛原来这就是老汉推车。GOF里的23种设计模式, 也是在软件开发中早就存在并反复使用的模式. 如果程序员没有明确意识到他使用过某些模式, 那么下次他也许会错过更合适的设计 (这段话来自《松本行弘的程序世界》).再回来正题, 前面那个单例还是有缺点. 它只能用于创建遮罩层. 假如我又需要写一个函数, 用来创建一个唯一的xhr对象呢? 能不能找到一个通用的singleton包装器.js中函数是第一型, 意味着函数也可以当参数传递. 看看最终的代码. 123456789var singleton = function( fn )&#123; var result; return function()&#123; return result || ( result = fn .apply( this, arguments ) ); &#125;&#125;var createMask = singleton( function()&#123; return document.body.appendChild( document.createElement(&#x27;div&#x27;) );&#125;) 用一个变量来保存第一次的返回值, 如果它已经被赋值过, 那么在以后的调用中优先返回该变量. 而真正创建遮罩层的代码是通过回调函数的方式传人到singleton包装器中的. 这种方式其实叫桥接模式. 关于桥接模式, 放在后面一点点来说。然而singleton函数也不是完美的, 它始终还是需要一个变量result来寄存div的引用. 遗憾的是js的函数式特性还不足以完全的消除声明和语句. 简单工厂模式简单工厂模式是由一个方法来决定到底要创建哪个类的实例, 而这些实例经常都拥有相同的接口。这种模式主要用在所实例化的类型在编译期并不能确定， 而是在执行期决定的情况。说的通俗点，就像公司茶水间的饮料机，要咖啡还是牛奶取决于你按哪个按钮。简单工厂模式在创建ajax对象的时候也非常有用。之前我写了一个处理ajax异步嵌套的库，地址在https://github.com/AlloyTeam/DanceRequest.这个库里提供了几种ajax请求的方式，包括xhr对象的get, post, 也包括跨域用的jsonp和iframe. 为了方便使用, 这几种方式都抽象到了同一个接口里面. 123456var request1 = Request(&#x27;cgi.xx.com/xxx&#x27; , &#x27;get&#x27;);request1.start();request1.done(fn);var request2 = Request(&#x27;cgi.xx.com/xxx&#x27; , &#x27;jsonp&#x27;);request2.start();request2.done(fn); Request实际上就是一个工厂方法, 至于到底是产生xhr的实例, 还是jsonp的实例, 是由后来的代码决定的。实际上在js里面，所谓的构造函数也是一个简单工厂。只是批了一件new的衣服。我们扒掉这件衣服看看里面。通过这段代码, 在firefox, chrome等浏览器里，可以完美模拟new. 123456789101112function A( name ) &#123; this.name = name;&#125;function ObjectFactory() &#123; var obj = &#123;&#125;, Constructor = Array.prototype.shift.call( arguments ); obj.__proto__ = typeof Constructor .prototype === &#x27;number&#x27; ? Object.prototype : Constructor .prototype; var ret = Constructor.apply( obj, arguments ); return typeof ret === &#x27;object&#x27; ? ret : obj;&#125;var a = ObjectFactory( A, &#x27;svenzeng&#x27; );alert ( a.name ); //svenzeng 这段代码来自es5的new和构造器的相关说明，可以看到，所谓的new，本身只是一个对象的复制和改写过程，而具体会生成什么是由调用ObjectFactory时传进去的参数所决定的。 观察者模式观察者模式( 又叫发布者-订阅者模式 )应该是最常用的模式之一。在很多语言里都得到大量应用. 包括我们平时接触的dom事件. 也是js和dom之间实现的一种观察者模式. 123div.onclick = function click () &#123; alert ( &#x27;&#x27;click&#x27; )&#125; 只要订阅了div的click事件. 当点击div的时候, function click就会被触发.那么到底什么是观察者模式呢. 先看看生活中的观察者模式。好莱坞有句名言. “不要给我打电话， 我会给你打电话”. 这句话就解释了一个观察者模式的来龙去脉。 其中“我”是发布者， “你”是订阅者。再举个例子，我来公司面试的时候，完事之后每个面试官都会对我说：“请留下你的联系方式， 有消息我们会通知你”。在这里“我”是订阅者， 面试官是发布者。所以我不用每天或者每小时都去询问面试结果， 通讯的主动权掌握在了面试官手上。而我只需要提供一个联系方式。观察者模式可以很好的实现2个模块之间的解耦。假如我正在一个团队里开发一个html5游戏,当游戏开始的时候，需要加载一些图片素材。加载好这些图片之后开始才执行游戏逻辑. 假设这是一个需要多人合作的项目. 我完成了Gamer和Map模块, 而我的同事A写了一个图片加载器loadImage.loadImage的代码如下 1234loadImage(imgAry, function()&#123; Map.init(); Gamer.init();&#125; ) 当图片加载好之后, 再渲染地图, 执行游戏逻辑. 嗯, 这个程序运行良好. 突然有一天, 我想起应该给游戏加上声音功能. 我应该让图片加载器添上一行代码. 12345loadImage( imgAry, function()&#123;Map.init();Gamer.init();Sount.init();&#125; ) 可是写这个模块的同事A去了外地旅游. 于是我打电话给他, 喂. 你的loadImage函数在哪, 我能不能改一下, 改了之后有没有副作用. 如你所想, 各种不淡定的事发生了. 如果当初我们能这样写呢: 123456789loadImage.listen( &#x27;ready&#x27;, function()&#123; Map.init();&#125;)loadImage.listen( &#x27;ready&#x27;, function()&#123; Gamer.init();&#125;)loadImage.listen( &#x27;ready&#x27;, function()&#123; Sount.init();&#125;) loadImage完成之后, 它根本不关心将来会发生什么, 因为它的工作已经完成了. 接下来它只要发布一个信号. 1loadImage.trigger(&#x27;ready’ ); 那么监听了loadImage的’ready’事件的对象都会收到通知. 就像上个面试的例子. 面试官根本不关心面试者们收到面试结果后会去哪吃饭. 他只负责把面试者的简历搜集到一起. 当面试结果出来时照着简历上的电话挨个通知.说了这么多概念, 来一个具体的实现. 实现过程其实很简单. 面试者把简历扔到一个盒子里， 然后面试官在合适的时机拿着盒子里的简历挨个打电话通知结果. 123456789101112131415161718192021222324252627282930313233343536373839404142Events = function() &#123; var listen, log, obj, one, remove, trigger, __this; obj = &#123;&#125;; __this = this; listen = function( key, eventfn ) &#123; //把简历扔盒子, key就是联系方式. var stack, _ref; //stack是盒子 stack = ( _ref = obj[key] ) != null ? _ref : obj[ key ] = []; return stack.push( eventfn ); &#125;; one = function( key, eventfn ) &#123; remove( key ); return listen( key, eventfn ); &#125;; remove = function( key ) &#123; var _ref; return ( _ref = obj[key] ) != null ? _ref.length = 0 : void 0; &#125;; trigger = function() &#123; // 面试官打电话通知面试者 var fn, stack, _i, _len, _ref, key; key = Array.prototype.shift.call( arguments ); stack = ( _ref = obj[ key ] ) != null ? _ref : obj[ key ] = []; for ( _i = 0, _len = stack.length; _i &lt; _len; _i++ ) &#123; fn = stack[ _i ]; if (fn.apply( __this, arguments ) === false) &#123; return false; &#125; &#125; return &#123; listen: listen, one: one, remove: remove, trigger: trigger &#125; &#125;&#125;// 订阅者 最后用观察者模式来做一个成人电视台的小应用.var adultTv = Event();adultTv .listen( &#x27;&#x27;play&#x27;, function( data )&#123; alert ( &quot;今天是谁的电影&quot; + data.name );&#125;);// 发布者adultTv .trigger( &#x27;&#x27;play&#x27;, &#123; &#x27;name&#x27;: &#x27;麻生希&#x27; &#125; ) 适配器模式去年年前当时正在开发dev.qplus.com, 有个存储应用分类id的js文件, 分类id的结构最开始设计的比较笨重. 于是我决定重构它. 我把它定义成一个json树的形式, 大概是这样: 123456var category = &#123; music: &#123; id: 1, children: [ , , , , ] &#125;&#125; dev.qplus.com里大概有4，5个页面都调用这个category对象. 春节前我休了1个星期假. 过年来之后发现邮箱里有封邮件, 设计数据库的同学把category.js也重构了一份, 并且其他几个项目里都是用了这份category.js, 我拿过来一看就傻眼了, 和我之前定的数据结构完全不一样.当然这是一个沟通上的反面例子. 但接下来的重点是我已经在N个文件里用到了之前我定的category.js. 而且惹上了一些复杂的相关逻辑. 怎么改掉我之前的代码呢. 全部重写肯定是不愿意. 所以现在适配器就派上用场了.只需要把同事的category用一个函数转成跟我之前定义的一样. 1my.category = adapterCategory ( afu.category ); 适配器模式的作用很像一个转接口. 本来iphone的充电器是不能直接插在电脑机箱上的, 而通过一个usb转接口就可以了.所以, 在程序里适配器模式也经常用来适配2个接口, 比如你现在正在用一个自定义的js库. 里面有个根据id获取节点的方法$id(). 有天你觉得jquery里的$实现得更酷, 但你又不想让你的工程师去学习新的库和语法. 那一个适配器就能让你完成这件事情. 123$id = function( id )&#123; return jQuery( &#x27;#&#x27; + id )[0];&#125; 代理模式代理模式的定义是把对一个对象的访问, 交给另一个代理对象来操作.实际的编程中， 这种因为性能问题使用代理模式的机会是非常多的。比如频繁的访问dom节点, 频繁的请求远程资源. 可以把操作先存到一个缓冲区, 然后自己选择真正的触发时机.再来个详细的例子，之前我写了一个街头霸王的游戏, 地址在http://alloyteam.github.com/StreetFighter/游戏中隆需要接受键盘的事件, 来完成相应动作.于是我写了一个keyManage类. 其中在游戏主线程里监听keyManage的变化. 1234var keyMgr = keyManage();keyMgr.listen( &#x27;change&#x27;, function( keyCode )&#123; console.log( keyCode );&#125;); 图片里面隆正在放升龙拳, 升龙拳的操作是前下前+拳. 但是这个keyManage类只要发生键盘事件就会触发之前监听的change函数. 这意味着永远只能取得前，后，前，拳这样单独的按键事件，而无法得到一个按键组合。好吧，我决定改写我的keyManage类, 让它也支持传递按键组合. 但是如果我以后写个html5版双截龙，意味着我每次都得改写keyManage.我总是觉得, 这种函数应该可以抽象成一个更底层的方法, 让任何游戏都可以用上它.所以最后的keyManage只负责映射键盘事件. 而隆接受到的动作是通过一个代理对象处理之后的. 1234var keyMgr = keyManage();keyMgr.listen( &#x27;change&#x27;, proxy( function( keyCode )&#123; console.log( keyCode ); //前下前+拳)&#125;); 至于proxy里面怎么实现，完全可以自由发挥。还有个例子就是在调用ajax请求的时候，无论是各种开源库，还是自己写的Ajax类, 都会给xhr对象设置一个代理.我们不可能频繁的去操作xhr对象发请求, 而应该是这样. 1234var request = Ajax.get( &#x27;cgi.xx.com/xxx&#x27; );request.send();request.done(function()&#123;&#125;); 桥接模式桥接模式的作用在于将实现部分和抽象部分分离开来， 以便两者可以独立的变化。在实现api的时候， 桥接模式特别有用。比如最开始的singleton的例子. 123456789var singleton = function( fn )&#123; var result; return function()&#123; return result || ( result = fn .apply( this, arguments ) ); &#125;&#125;var createMask = singleton( function()&#123; return document.body.appendChild( document.createElement(&#x27;div&#x27;) );&#125;) singleton是抽象部分， 而createMask是实现部分。 他们完全可以独自变化互不影响。 如果需要再写一个单例的createScript就一点也不费力. 123var createScript = singleton(function()&#123;return document.body.appendChild( document.createElement(&#x27;script&#x27;) );&#125;) 另外一个常见的例子就是forEach函数的实现, 用来迭代一个数组. 12345678forEach = function( ary, fn )&#123; for ( var i = 0, l = ary.length; i &lt; l; i++ )&#123; var c = ary[ i ]; if ( fn.call( c, i, c ) === false )&#123; return false; &#125; &#125;&#125; 可以看到, forEach函数并不关心fn里面的具体实现. fn里面的逻辑也不会被forEach函数的改写影响. 123456forEach( [1,2,3], function( i, n )&#123; alert ( n*2 )&#125; )forEach( [1,2,3], function( i, n )&#123; alert ( n*3 )&#125; ) 外观模式外观模式(门面模式)，是一种相对简单而又无处不在的模式。外观模式提供一个高层接口，这个接口使得客户端或子系统更加方便调用。用一段再简单不过的代码来表示 123456var getName = function()&#123; return &#x27;&#x27;svenzeng&quot;&#125;var getSex = function()&#123; return &#x27;man&#x27;&#125; 如果你需要分别调用getName和getSex函数. 那可以用一个更高层的接口getUserInfo来调用. 1234var getUserInfo = function()&#123; var info = a() + b(); return info;&#125; 也许你会问为什么一开始不把getName和getSex的代码写到一起, 比如这样 123var getNameAndSex = function()&#123; return &#x27;svenzeng&quot; + &quot;man&quot;;&#125; 答案是显而易见的，饭堂的炒菜师傅不会因为你预定了一份烧鸭和一份白菜就把这两样菜炒在一个锅里。他更愿意给你提供一个烧鸭饭套餐。同样在程序设计中，我们需要保证函数或者对象尽可能的处在一个合理粒度，毕竟不是每个人喜欢吃烧鸭的同时又刚好喜欢吃白菜。外观模式还有一个好处是可以对用户隐藏真正的实现细节，用户只关心最高层的接口。比如在烧鸭饭套餐的故事中，你并不关心师傅是先做烧鸭还是先炒白菜，你也不关心那只鸭子是在哪里成长的。最后写个我们都用过的外观模式例子 1234var stopEvent = function( e )&#123; //同时阻止事件默认行为和冒泡 e.stopPropagation(); e.preventDefault();&#125; 访问者模式访问者模式是表示一个作用于某个对象结构中的各元素的操作。它使可以在不改变各元素的类的前提下定义作用于这些元素的新操作。我们在使用一些操作对不同的对象进行处理时，往往会根据不同的对象选择不同的处理方法和过程。在实际的代码过程中，我们可以发现，如果让所有的操作分散到各个对象中，整个系统会变得难以维护和修改。且增加新的操作通常都要重新编译所有的类。因此，为了解决这个问题，我们可以将每一个类中的相关操作提取出来，包装成一个独立的对象，这个对象我们就称为访问者（Visitor）。利用访问者，对访问的元素进行某些操作时，只需将此对象作为参数传递给当前访问者，然后，访问者会依据被访问者的具体信息，进行相关的操作。据统计，上面这段话只有5%的人会看到最后一句。那么通俗点讲，访问者模式先把一些可复用的行为抽象到一个函数(对象)里，这个函数我们就称为访问者（Visitor）。如果另外一些对象要调用这个函数，只需要把那些对象当作参数传给这个函数，在js里我们经常通过call或者apply的方式传递this对象给一个Visitor函数.访问者模式也被称为GOF总结的23种设计模式中最难理解的一种。不过这有很大一部分原因是因为《设计模式》基于C++和Smalltalk写成. 在强类型语言中需要通过多次重载来实现访问者的接口匹配。而在js这种基于鸭子类型的语言中，访问者模式几乎是原生的实现, 所以我们可以利用apply和call毫不费力的使用访问者模式，这一小节更关心的是这种模式的思想以及在js引擎中的实现。 在js这种弱类型语言里，很多方法里都不做对象的类型检测，而是只关心这些对象能做什么。Array构造器和String构造器的prototype上的方法就被特意设计成了访问者。这些方法不对this的数据类型做任何校验。这也就是为什么arguments能冒充array调用push方法.看下v8引擎里面Array.prototype.push的代码: 123456789function ArrayPush() &#123; var n = TO_UINT32( this.length ); var m = %_ArgumentsLength(); for (var i = 0; i &lt; m; i++) &#123; this[i+n] = %_Arguments(i); //属性拷贝 &#125; this.length = n + m; //修正length return this.length; &#125; 可以看到，ArrayPush方法没有对this的类型做任何显示的限制，所以理论上任何对象都可以被传入ArrayPush这个访问者。不过在代码的执行期，还是会受到一些隐式限制，在上面的例子很容易看出要求:1、 this对象上面可储存属性. //反例: 值类型的数据2、 this的length属性可写. //反例: functon对象, function有一个只读的length属性, 表示形参个数.如果不符合这2条规则的话，代码在执行期会报错. 也就是说, 1Array.prototype.push.call( 1, ‘first’ )和Array.prototoype.push.call( function()&#123;&#125;, ‘first’ )都达不到预期的效果. 利用访问者，我们来做个有趣的事情. 给一个object对象增加push方法. 123456789var Visitor = &#123;&#125;Visitor .push = function()&#123; return Array.prototype.push.apply( this, arguments );&#125;var obj = &#123;&#125;;obj.push = Visitor .push;obj.push( &#x27;&quot;first&quot; );alert ( obj[0] ) //&quot;first&quot;alert ( obj.length ); //1 策略模式策略模式的意义是定义一系列的算法，把它们一个个封装起来，并且使它们可相互替换。一个小例子就能让我们一目了然。回忆下jquery里的animate方法. 12$( div ).animate( &#123;&quot;left: 200px&quot;&#125;, 1000, &#x27;linear&#x27; ); //匀速运动$( div ).animate( &#123;&quot;left: 200px&quot;&#125;, 1000, &#x27;cubic&#x27; ); //三次方的缓动 这2句代码都是让div在1000ms内往右移动200个像素. linear(匀速)和cubic(三次方缓动)就是一种策略模式的封装.再来一个例子. 上半年我写的dev.qplus.com, 很多页面都会有个即时验证的表单. 表单的每个成员都会有一些不同的验证规则.比如姓名框里面， 需要验证非空，敏感词，字符过长这几种情况。 当然是可以写3个if else来解决，不过这样写代码的扩展性和维护性可想而知。如果表单里面的元素多一点，需要校验的情况多一点，加起来写上百个if else也不是没有可能。所以更好的做法是把每种验证规则都用策略模式单独的封装起来。需要哪种验证的时候只需要提供这个策略的名字。就像这样： 123456789101112131415nameInput.addValidata(&#123; notNull: true, dirtyWords: true, maxLength: 30&#125;)而notNull，maxLength等方法只需要统一的返回true或者false，来表示是否通过了验证。```bashvalidataList = &#123; notNull: function( value )&#123; return value !== &#x27;&#x27;; &#125;, maxLength: function( value, maxLen )&#123; return value.length() &gt; maxLen; &#125;&#125; 可以看到，各种验证规则很容易被修改和相互替换。如果某天产品经理建议字符过长的限制改成60个字符。那只需要0.5秒完成这次工作。 模版方法模式模式方法是预先定义一组算法，先把算法的不变部分抽象到父类，再将另外一些可变的步骤延迟到子类去实现。听起来有点像工厂模式( 非前面说过的简单工厂模式 ).最大的区别是,工厂模式的意图是根据子类的实现最终获得一种对象. 而模版方法模式着重于父类对子类的控制.按GOF的描叙，模版方法导致一种反向的控制结构，这种结构有时被称为“好莱坞法则”，即“别找我们，我们找你”。这指的是一个父类调用一个子类的操作，而不是相反。一个很常用的场景是在一个公司的项目中，经常由架构师搭好架构，声明出抽象方法。下面的程序员再去分头重写这些抽象方法。在深入了解之前，容许我先扯远一点。作为一个进化论的反对者，假设这个世界是上帝用代码创造的。那么上帝创造生命的时候可能就用到了模版方法模式。看看他是怎么在生命构造器中声明模版方法的： 1234567891011121314151617181920var Life = function()&#123;&#125;Life.prototype.init = function()&#123; this.DNA复制(); this.出生(); this.成长(); this.衰老(); this.死亡();&#125;this.prototype.DNA复制 = function()&#123; &amp;*$%&amp;^%^&amp;(&amp;(&amp;(&amp;&amp;(^^(*) //看不懂的代码&#125;Life.prototype.出生 = function()&#123;&#125;Life.prototype.成长 = function()&#123;&#125;Life.prototype.衰老 = function()&#123;&#125;Life.prototype.死亡 = function()&#123;&#125; 其中DNA复制是预先定义的算法中不变部分. 所有子类都不能改写它. 如果需要我们可以写成protected的类型.而其他的函数在父类中会被先定义成一个空函数(钩子). 然后被子类重写，这就是模版方法中所谓的可变的步骤。假设有个子类哺乳动物类继承了Life类. 123var Mammal = function()&#123;&#125;Mammal.prototype = Life.prototype; //继承Life 然后重写出生和衰老这两个钩子函数. 12345678910111213141516171819Mammal.prototope.出生 = function()&#123; &#x27;胎生()&#125;Mammal.prototype.成长 = function()&#123; //再留给子类去实现&#125;Mammal.prototope.衰老 = function()&#123; 自由基的过氧化反应()&#125;Life.prototype.死亡 = function()&#123; //再留给子类去实现&#125;//再实现一个Dog类var = Dog = function()&#123;&#125;//Dog继承自哺乳动物.Dog.prototype = Mammal.prototype;var dog = new Dog();dog.init(); 至此，一只小狗的生命会依次经历DNA复制，出生，成长，衰老，死亡这几个过程。这些步骤早在它出生前就决定了。所幸的是，上帝没有安排好它生命的所有细节。它还是能通过对成长函数的重写，来成为一只与众不同的小狗。举个稍微现实点的例子，游戏大厅中的所有游戏都有登录，游戏中，游戏结束这几个过程，而登录和游戏结束之后弹出提示这些函数都是应该公用的。那么首先需要的是一个父类。 12345678910111213141516var gameCenter = function()&#123;&#125;gameCenter.ptototype.init = function()&#123; this.login(); this.gameStart(); this.end();&#125;gameCenter.prototype.login= function()&#123; //do something&#125;gameCenter.prototype.gameStart= function()&#123; //空函数, 留给子类去重写&#125;gameCenter.prototype.end= function()&#123; alert ( &quot;欢迎下次再来玩&quot; );&#125; 接下来创建一个斗地主的新游戏, 只需要继承gameCenter然后重写它的gameStart函数. 1234567var 斗地主 = function()&#123;&#125;斗地主.prototype = gameCenter.prototype; //继承斗地主.prototype.gameStart = function()&#123; //do something&#125;(new 斗地主).init(); 这样一局新的游戏就开始了. 中介者模式中介者对象可以让各个对象之间不需要显示的相互引用，从而使其耦合松散，而且可以独立的改变它们之间的交互。打个比方，军火买卖双方为了安全起见，找了一个信任的中介来进行交易。买家A把钱交给中介B，然后从中介手中得到军火，卖家C把军火卖给中介，然后从中介手中拿回钱。一场交易完毕，A甚至不知道C是一只猴子还是一只猛犸。因为中介的存在，A也未必一定要买C的军火，也可能是D，E，F。银行在存款人和贷款人之间也能看成一个中介。存款人A并不关心他的钱最后被谁借走。贷款人B也不关心他借来的钱来自谁的存款。因为有中介的存在，这场交易才变得如此方便。中介者模式和代理模式有一点点相似。都是第三者对象来连接2个对象的通信。具体差别可以从下图中区别。代理模式：中介者模式代理模式中A必然是知道B的一切，而中介者模式中A,B,C对E,F,G的实现并不关心.而且中介者模式可以连接任意多种对象。切回到程序世界里的mvc，无论是j2ee中struts的Action. 还是js中backbone.js和spine.js里的Controler. 都起到了一个中介者的作用.拿backbone举例. 一个mode里的数据并不确定最后被哪些view使用. view需要的数据也可以来自任意一个mode. 所有的绑定关系都是在controler里决定. 中介者把复杂的多对多关系, 变成了2个相对简单的1对多关系.一段简单的示例代码： 123456789101112var mode1 = Mode.create(), mode2 = Mode.create();var view1 = View.create(), view2 = View.create();var controler1 = Controler.create( mode1, view1, function()&#123; view1.el.find( &#x27;&#x27;div&#x27; ).bind( &#x27;&#x27;click&#x27;, function()&#123; this.innerHTML = mode1.find( &#x27;data&#x27; ); &#125; )&#125;)var controler2 = Controler.create( mode2 view2, function()&#123; view1.el.find( &#x27;&#x27;div&#x27; ).bind( &#x27;&#x27;click&#x27;, function()&#123; this.innerHTML = mode2.find( &#x27;data&#x27; ); &#125; )&#125;) 迭代器模式迭代器模式提供一种方法顺序访问一个聚合对象中各个元素，而又不需要暴露该方法中的内部表示。js中我们经常会封装一个each函数用来实现迭代器。array的迭代器： 1234forEach = function( ary, fn )&#123; for ( var i = 0, l = ary.length; i &lt; l; i++ )&#123; var c = ary[ i ]; if ( fn.call( c, i , c ) === false )&#123; return false; &#125; &#125;&#125;forEach( [ 1, 2, 3 ], function( i, n )&#123; alert ( i );&#125;) obejct的迭代器: 1234forEach = function( obj, fn )&#123; for ( var i in obj )&#123; var c = obj[ i ]; if ( fn.call( c, i, c ) === false )&#123; return false; &#125; &#125;&#125;forEach( &#123;&quot;a&quot;: 1,&quot;b&quot;: 2&#125;, function( i, n )&#123; alert ( i );&#125;) 组合模式组合模式又叫部分-整体模式，它将所有对象组合成树形结构。使得用户只需要操作最上层的接口，就可以对所有成员做相同的操作。一个再好不过的例子就是jquery对象，大家都知道1个jquery对象其实是一组对象集合。比如在这样一个HTML页面 1234&lt;div&gt; &lt;span&gt;&lt;/span&gt; &lt;span&gt;&lt;/span&gt;&lt;/div&gt; 我们想取消所有节点上绑定的事件, 需要这样写 12345var allNodes = document.getElementsByTagName(&quot;*&quot;);var len = allNodes.length;while( len-- )&#123; allNodes.unbind(&quot;*&quot;);&#125; 但既然用了jquery，就肯定不会再做这么搓的事情。我们只需要$( ‘body’ ).unbind( ‘*’ );当每个元素都实现unbind接口, 那么只需调用最上层对象$( ‘body’ )的unbind, 便可自动迭代并调用所有组合元素的unbind方法.再来个具体点的例子， 还是dev.qplus.com这个网站的即时验证表单。注意下面那个修改资料的按钮，如果有任意一个field的验证没有通过，修改资料的按钮都将是灰色不可点的状态。 这意味着我们重新填写了表单内容后, 都得去校验每个field, 保证它们全部OK.这代码不难实现. 123if ( nameField.validata() &amp;&amp; idCard.validata() &amp;&amp; email.validata() &amp;&amp; phone.validata() )&#123; alert ( &quot;验证OK&quot; );&#125; 似乎我们用一个外观模式也能勉强解决这里条件分支堆砌的问题，但真正的问题是，我们并不能保证表单里field的数量，也许明天产品经理就让你删掉一个或者增加两个.那么这样的维护方式显然不能被接受.更好的实现是有一个form.validata函数, 它负责把真正的validata操作分发给每个组合对象.form.validata函数里面会依次遍历所有需要校验的field. 若有一个field校验未通过, form.validata都会返回false. 伪代码如下. 12345678form.validata = function()&#123; forEach( fields, function( index, field )&#123; if ( field.validata() === false )&#123; return false; &#125; &#125;) return true;&#125; 备忘录模式备忘录模式在js中经常用于数据缓存. 比如一个分页控件, 从服务器获得某一页的数据后可以存入缓存。以后再翻回这一页的时候，可以直接使用缓存里的数据而无需再次请求服务器。实现比较简单，伪代码： 12345678910111213141516var Page = function()&#123; var page = 1, cache = &#123;&#125;, data; return function( page )&#123; if ( cache[ page ] )&#123; data = cache[ page ]; render( data ); &#125;else&#123; Ajax.send( &#x27;cgi.xx.com/xxx&#x27;, function( data )&#123; cache[ page ] = data; render( data ); &#125;) &#125; &#125;&#125;() 职责链模式职责链模式是一个对象A向另一个对象B发起请求，如果B不处理，可以把请求转给C，如果C不处理，又可以把请求转给D。一直到有一个对象愿意处理这个请求为止。打个比方，客户让老板写个php程序。老板肯定不写，然后老板交给了部门经理。部门经理不愿意写，又交给项目经理。项目经理不会写，又交给程序员。最后由码农来完成。在这个假设里， 有几条职责链模式的特点。1 老板只跟部门经理打交道，部门经理只联系项目经理，项目经理只找码农的麻烦。2 如果码农也不写，这个项目将会流产。3 客户并不清楚这个程序最后是由谁写出来的。js中的事件冒泡就是作为一个职责链来实现的。一个事件在某个节点上被触发，然后向根节点传递， 直到被节点捕获。 享元模式享元模式主要用来减少程序所需的对象个数. 有一个例子, 我们这边的前端同学几乎人手一本《javascript权威指南》. 从省钱的角度讲, 大约三本就够了. 放在部门的书柜里, 谁需要看的时候就去拿, 看完了还回去. 如果同时有4个同学需要看, 此时再去多买一本.在webqq里面, 打开QQ好友列表往下拉的时候，会为每个好友创建一个div( 如果算上div中的子节点, 还远不只1个元素 ).如果有1000个QQ好友, 意味着如果从头拉到尾, 会创建1000个div, 这时候有些浏览器也许已经假死了. 这还只是一个随便翻翻好友列表的操作.所以我们想到了一种解决办法, 当滚动条滚动的时候, 把已经消失在视线外的div都删除掉. 这样页面可以保持只有一定数量的节点. 问题是这样频繁的添加与删除节点, 也会造成很大的性能开销, 而且这种感觉很不对味.现在享元模式可以登场了. 顾名思义, 享元模式可以提供一些共享的对象以便重复利用. 仔细看下上图, 其实我们一共只需要10个div来显示好友信息,也就是出现在用户视线中的10个div.这10个div就可以写成享元.伪代码如下. 12345678910111213141516171819var getDiv = (function()&#123; var created = []; var create = function()&#123; return document.body.appendChild( document.createElement( &#x27;div&#x27; ) ); &#125; var get = function()&#123; if ( created.length )&#123; return created.shift(); &#125;else&#123; return create(); &#125; &#125; /* 一个假设的事件，用来监听刚消失在视线外的div，实际上可以通过监听滚动条位置来实现 */ userInfoContainer.disappear(function( div )&#123; created.push( div ); &#125;) &#125;)() var div = getDiv(); div.innerHTML = &quot;$&#123;userinfo&#125;&quot;; 原理其实很简单, 把刚隐藏起来的div放到一个数组中, 当需要div的时候, 先从该数组中取, 如果数组中已经没有了, 再重新创建一个. 这个数组里的div就是享元, 它们每一个都可以当作任何用户信息的载体.当然这只是个示例,实际的情况要复杂一些, 比如快速拖动的时候, 我们可能还得为节点设置一个缓冲区. 状态模式状态模式主要可以用于这种场景1 一个对象的行为取决于它的状态2 一个操作中含有庞大的条件分支语句回想下街头霸王的游戏。隆有走动，攻击，防御，跌倒，跳跃等等多种状态，而这些状态之间既有联系又互相约束。比如跳跃的时候是不能攻击和防御的。跌倒的时候既不能攻击又不能防御，而走动的时候既可以攻击也可以跳跃。要完成这样一系列逻辑, 常理下if else是少不了的. 而且数量无法估计, 特别是增加一种新状态的时候, 可能要从代码的第10行一直改到900行. 123456789if ( state === &#x27;jump&#x27; )&#123; if ( currState === &#x27;attack&#x27; || currState === &#x27;defense&#x27; )&#123; return false; &#125;&#125;else if ( state === &#x27;wait&#x27; )&#123; if ( currState === &#x27;attack&#x27; || currState === &#x27;defense&#x27; )&#123; return true; &#125;&#125; 为了消灭这些if else, 并且方便修改和维护, 我们引入一个状态类. 12345678910111213141516171819202122232425262728var StateManager = function()&#123; var currState = &#x27;wait&#x27;; var states = &#123; jump: function( state )&#123; &#125;, wait: function( state )&#123; &#125;, attack: function( state )&#123; &#125;, crouch: function( state )&#123; &#125;, defense: function( state )&#123; if ( currState === &#x27;jump&#x27; )&#123; return false; //不成功，跳跃的时候不能防御 &#125; //do something; //防御的真正逻辑代码, 为了防止状态类的代码过多, 应该把这些逻辑继续扔给真正的fight类来执行. currState = &#x27;defense&#x27;; // 切换状态 &#125; &#125; var changeState = function( state )&#123; states[ state ] &amp;&amp; states[ state ](); &#125; return &#123; changeState : changeState &#125;&#125;var stateManager = StateManager();stateManager.changeState( &#x27;defense&#x27; ); 通过这个状态类，可以把散落在世界各地的条件分支集中管理到一个类里，并且可以很容易的添加一种新的状态。而作为调用者，只需要通过暴露的changeState接口来切换人物的状态。 结束语GOF提出的23种设计模式，至此已经写完大半。还有一些要么是js里不太适用，要么是js中已有原生自带的实现，所以就没再去深究。这2篇文章里的大部分例子都来自或改写自工作和学习中的代码。我对设计模式的看法是不用刻意去学习设计模式，平时我们接触的很多代码里已经包含了一些设计模式的实现。我的过程是读过prototype和jquery的源码后，回头翻设计模式的书，发现不知觉中已经接触过十之六七。同样在实际的编码中也没有必要刻意去使用一些设计模式。就如同tokyo hot 32式一样，在一场友好的papapa过程中，没有必要去刻意使用某种姿势。一切还是看需求和感觉。","categories":[{"name":"JS/React","slug":"JS-React","permalink":"https://qiongqiongwoo.github.io/blog/categories/JS-React/"}],"tags":[]},{"title":"浏览器渲染","slug":"浏览器渲染","date":"2018-12-14T06:21:42.000Z","updated":"2021-03-21T07:41:16.201Z","comments":true,"path":"2018/12/14/浏览器渲染/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2018/12/14/%E6%B5%8F%E8%A7%88%E5%99%A8%E6%B8%B2%E6%9F%93/","excerpt":"","text":"1、浏览器是多进程的比如chrome browser进程：与用户交互、浏览器的前进后退、各个tab页面的管理等 GPU进程：3D页面绘制等 浏览器渲染进程（Render进程，其内部是多线程的）每个tab对应一个，相互独立。2、如上所述Render进程是多线程的 JS引擎线程—– 主线程（JS内核负责解析和运行代码，一个Render进程只有一个JS引擎线程） GUI渲染线程：负责渲染浏览器界面，当界面需要repaint或者reflow时就会执行。 事件触发线程：事件被触发时，将事件添加到事件处理队列等待JS引擎被执行。 定时触发线程：setTimeout、setInterval所在线程 异步请求线程：XMLHttpRequest在连接后通过浏览器开一个线程请求3、JS引擎和渲染引擎之间的关系 JS引擎线程和GUI渲染线程是互斥的，JS引擎执行时，GUI渲染线程会被挂起。 JS引擎花费时间过多时，会出现浏览器卡死的情况。 JS是单线程是指解释和执行JS的线程只有一个，即主线程、JS引擎线程。4、JS的运行机制如下 所有的同步任务都在主线程上执行，形成一个函数执行栈 主线程之外有个任务队列 一旦stack为空，主线程就去读取任务队列中的异步任务进行执行 主线程循环重复上面三个步骤 事件触发线程注册函数，当事件触发时，被推入event loop（消息队列的形式，消息队列中每一条信息都对应着一个事件） 主线程函数栈执行完后，循环从消息队列中取消息进行处理5、web worker &amp; share worker JS引擎向浏览器申请开一个子线程做一些耗时处理（此子线程不能操作dom，完全受JS引擎的控制） share worker是浏览器的多个tab共享的，web worker属于单独的一个tab6、宏任务（macro-task）和微任务(micro-task)的执行 宏任务： script\\setTimeout\\setTimeInterval\\setTimeImmediate\\ 微任务： promise、process.nextTick、mutationObserver 根据html standard，在每个macro-task执行完之后，UI都会重新渲染，如果再micro-task中完成数据的处理，则当前task执行完之后就可以得到最终的UI，但如果在一个新的task中进行执行，需要两次渲染才能得到最终的UI，这也是promise要好于setTimeOut的地方。12345678910111213setTimeout(function()&#123; console.log(&#x27;定时器开始啦’) &#125;); new Promise(function(resolve)&#123; console.log(&#x27;马上执行for循环啦’); for(var i = 0; i &lt; 10000; i++)&#123; i == 99 &amp;&amp; resolve(); &#125; &#125;).then(function()&#123; console.log(&#x27;执行then函数啦’) &#125;); console.log(&#x27;代码执行结束’); // 浏览器的执行结果为 马上执行for循环啦 -&gt; 代码执行结束 -&gt; 执行then函数啦 -&gt; 定时器开始啦 1.整体script作为第一个宏任务进入主线程，这是第一轮宏任务。2.遇到setTimeout，其回调函数被分发到宏任务Event Queue中，这是第二个宏任务。3.继续执行，打印【马上执行for循环啦】4.遇到promise.then()微任务，这是第一轮宏任务下的微任务，因为整体script是第一轮宏任务嘛5.继续执行，打印【代码执行结束】6.现在整体script作为第一轮宏任务，去检查这一轮下的微任务，发现有一个promise.then()，去执行它（至此现在第一轮宏任务，以及这一轮宏任务下的微任务都被执行过了）7.开始第二轮宏任务，发现宏任务队列里有一个setTimeout，执行它，就打印了【定时器开始啦】// 注意： node中的执行结果和上面是不同的7、浏览器渲染流程style Tree的结构 Dom树构建的过程包括符号化和构建树两个过程，符号化采用符号识别算法 DomContentLoaded仅当dom加载完成不包括样式表，onload事件是dom、样式、图片、脚本全都执行完毕了 从上图可以看到、Css的加载不会阻塞dom树的解析但会阻塞render树的渲染 Web模式是同步的，遇到script标签，会执行完js再进行后续的解析，遇到引用外部的script，同样会等到js下载完，这样会阻塞后续的资源下载，因此出现了预解析。 预解析分析引用的外部资源，同步进行下载以提高速度，但并不构建dom树。 渲染树和dom树不是一一对应的，不可见的dom元素不会插入到渲染树中，display为none的元素也不会插入。8、dom树的构建过程 二进制字节流 — -1—&gt; 字符流 —–2—-&gt; 词语 ——-3–&gt; 多个节点 -—-4——-&gt;Dom树 1是根据页面的编码格式， 2根据词法分析（基于状态机的符号识别算法） 4可以利用栈（所有的标签都是闭合的），3是存储类似于 在步骤3中会识别出全局的JavaScript代码，此时dom树尚未创建，因此不能访问dom。9、layout(reflow)和repaint，layout就是计算元素的大小位置等信息，确定每个元素在页面上的位置 Layout(reflow):表示元素的内容、结构、尺寸位置发生了变化，需要重新计算样式和渲染树 repaint:元素的背景色、边框文字颜色发生变化。 reflow的成本要高于repaint，应该尽量避免reflow，回流一定伴随着重绘，重绘却会单独出现10、引起layout（reflow）的情况 dom结构改变比如删除一个节点 render树变化，比如padding变化 窗口resize font字体大小发生变化 获取一些属性时会引发回流，比如： offset（height/width…）、scroll（height/width…）、client（height/width…）,width，height，getComputedStyle等12345678var s = document.body.style;s.padding = &quot;2px&quot;; // 回流+重绘s.border = &quot;1px solid red&quot;; // 再一次 回流+重绘s.color = &quot;blue&quot;; // 再一次重绘s.backgroundColor = &quot;#ccc&quot;; // 再一次 重绘s.fontSize = &quot;14px&quot;; // 再一次 回流+重绘// 添加node，再一次 回流+重绘document.body.appendChild(document.createTextNode(&#x27;abc!&#x27;)); 11、reflow的优化方案 style的改变一次性改，比如通过class改变 避免循环添加dom，统一处理一次添加 将复杂的元素绝对或者固定定位，脱离文档流，减少回流代价12、防止浏览器卡死的方式 优化循环12345678910111213function chunk(array, process, context) &#123; setTimeout(function inner() &#123; var item = array.shift(); process.call(context, item); if (array.length &gt; 0) &#123; setTimeout(inner, 100); &#125; &#125;, 100);&#125; // 此处递归操作直接用inner 而不是直接调用chunk的原因如下：Var chunkObj = chunkchunObj(array, process, context) // 可以正常执行chunk = function(array, process, context) &#123; console.log(‘fadfdasfds’)&#125;chunObj(array, process, context) // 不能正常执行，其内部的 chunk已经被新的定义替代 如果函数体内有不相干的、执行也没有先后的操作，则可以用chunk方式进行拆分或者直接交给浏览器去调度1234567891011121314151617181920function doSomething()&#123; setTimeout（dosomething1, 0） setTimeout（dosomething2, 0）&#125;* 优化递归操作function fac(num) &#123; var tmp = &#123;&#125; return (function fn(n)&#123; var res; if (tmp[n])&#123; res= tmp[n]; console.log(&#x27;match&#x27;+n) // 此处通过暂存数据，将减少递归层次， 这种优化牺牲了空间，还有一种方式是中间的结果不暂存， 利用迭代操作进行优化。 &#125; else &#123; if(n &lt;= 1) res = 1; else res = fn(n-2) + fn(n-1) &#125; tmp[n] = res; return res; &#125;)(num)&#125; 减少dom操作： 例如改变style的三个值不如通过设置一个class效率更高13、外链css的下载会阻塞JS的执行1234567891011121314151617&lt;html&gt;&lt;body&gt; &lt;h2&gt;Hello&lt;/h2&gt; &lt;script&gt; function printH2() &#123; console.log(&#x27;first script&#x27;, document.querySelectorAll(&#x27;h2&#x27;)); &#125; printH2() setTimeout(printH2) // JS脚本之前如果没有css标签，这部分的执行是不会被阻塞的 &lt;/script&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;http://cdn.bootcss.com/bootstrap/4.0.0-alpha.4/css/bootstrap.css&quot;&gt; &lt;h2&gt;World&lt;/h2&gt; &lt;script&gt; console.log(&#x27;second script’); // 此处的执行会受到css的下载的影响 &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 14、两个js的执行并非等到完全下载完1234&lt;body&gt;&lt;script src=&quot;1.js&quot;&gt;&lt;/script&gt; // 如果1下载5s， 2下载10s，1在5s后执行，2在10s后执行&lt;script src=&quot;2.js&quot;&gt;&lt;/script&gt; // 如果1下载10s， 2下载5s, 1在10s后执行，1执行完再执行2&lt;/body&gt; 15：渲染过程的一个例子（一下为firefox的例子）123456789&lt;doc&gt;&lt;title&gt;A few quotes&lt;/title&gt;&lt;para class=&quot;emph&quot;&gt; Franklin said that &lt;quote&gt;&quot;A penny saved is a penny earned.&quot;&lt;/quote&gt;&lt;/para&gt;&lt;para&gt; FDR said &lt;quote&gt;&quot;We have nothing to fear but &lt;span class=&quot;emph&quot;&gt;fear itself.&lt;/span&gt;&quot;&lt;/quote&gt;&lt;/para&gt;&lt;/doc&gt; css 规则如下：1234 /* rule 1 */ doc &#123; display: block; text-indent: 1em; &#125;/* rule 2 */ title &#123; display: block; font-size: 3em; &#125;/* rule 3 */ para &#123; display: block; &#125;/* rule 4 */ [class=&quot;emph&quot;] &#123; font-style: italic; &#125; 对应的dom树、css规则树以及style context tree分别为：(此段描述的未 attachment的过程：其实就是dom树上的每个节点，找到其对应的style的过程) css rule tree结构为（css rule tree是根据dom树构建出来的，所以4节点有两个 CSS匹配HTML元素是一个相当复杂和有性能问题的事情。所以，你就会在N多地方看到很多人都告诉你，DOM树要小，CSS尽量用id和class，千万不要过渡层叠下去 chrom中不存在规则树，他直接将节点的style存在了dom树的节点上 接下来开始计算CSS样式（每个dom节点的）—&gt;构建Render Tree -&gt; Layout(定位坐标和大小，换行、position, overflow, z-index等）—&gt;composition -&gt; paint","categories":[{"name":"网络","slug":"网络","permalink":"https://qiongqiongwoo.github.io/blog/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"整理的css知识","slug":"整理的css知识","date":"2018-12-14T05:01:21.000Z","updated":"2019-01-04T10:49:59.000Z","comments":true,"path":"2018/12/14/整理的css知识/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2018/12/14/%E6%95%B4%E7%90%86%E7%9A%84css%E7%9F%A5%E8%AF%86/","excerpt":"","text":"css标准地址 https://www.w3.org/TR/CSS2/visuren.html#inline-formatting1、block、inline、inline-block每个页面元素都有一个display属性，每个元素的display属性都有一个默认值，比如div的display属性为block，span的display属性为inline，inline元素不会自动换行且没有宽和高、block元素有宽和高度，且会自动换行。常见的元素分类如下：（1）block元素：body form textarea h1 - h6 html table button p ul ol div（2）inline元素：title span a em b strong I map 等（3）inline-block元素：img input td select textarea label区别方式为：是否可以设置宽、高、margin、padding值、是否会换行。对inline元素这只padding-top padding-bottom margin-bottom margin-top不会对周边元素产生影响，会加大自身的范围。2、嵌套规则：（1）块状元素可以包含内联元素或者块元素，内连元素不可以包含块元素只包含内连元素 123&lt;a href=&quot;#&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/a&gt; — 正确&lt;div&gt;&lt;h1&gt;&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;/div&gt; — 正确&lt;span&gt;&lt;div&gt;&lt;/div&gt;&lt;/span&gt; — 正确 （2）h1- h6、p、 dt这几个块元素只能包含内联元素或者可变元素 12&lt;p&gt;&lt;ol&gt;&lt;li&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/p&gt; -- wrong&lt;p&gt;&lt;div&gt;&lt;/div&gt;&lt;/p&gt; — wrong （3）特殊的li标签内可以出现div标签（4）块级元素可以与块级元素并列、内联元素可以和内联元素并列 123&lt;div&gt;&lt;h2&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;/div&gt; — right&lt;div&gt;&lt;a href=&quot;#&quot;&gt;&lt;/a&gt;&lt;span&gt;&lt;/span&gt;&lt;/div&gt; — right&lt;div&gt;&lt;h2&gt;&lt;/h2&gt;&lt;span&gt;&lt;/span&gt;&lt;/div&gt; -- wrong 3、inline元素改为block元素的方式（1）直接将display值设置为block/inline-block（2）直接将position设置为absolute或者fix4、inline-block元素出现缝隙的解决方式（1）两个inline-block元素之间不能出现换行、空格等（2）设置margin-right值为负值（3）将父元素的font-size、letter-spacing、word-spacing值5、block元素内的inline-block元素出现底部空白或者两个inline-block元素无法对齐的情况（1）使用vertical-align：top（2）例子： https://segmentfault.com/a/11900000109349286、em: 相对于父级元素font-size的比例。rem：相对于根元素html的font-size比例。ex：所用字体中x的高度，通常取em的一半。7、css的三种定位机制：普通流、浮动和绝对定位。position有relative、absolute、fix、staticrelative：相对于元素应该出现的位置的相对位置。absolute：绝对定位的盒子是相对于离他最近的一个已定位的盒子进行定位的，可能是relative，可能是absolute。默认是body。浮动和绝对定位都将元素剥离了文档流。8、background-origin: 取值可以为content-box、padding-box、border-box，规定背景图放置的位置。9、box盒子模型（1）ie设置的height和 width = margin + padding +content-width（2）标准的盒子模型的 width = content-width（3）css3中加了一个属性叫box-sizing 来区分上面的情况（content-box \\ border-box \\ padding-box）10、formatting context: 它是页面中的一块渲染区域、并且有自己的一套渲染规则、他决定了元素如何定位以及与其他元素如何相互作用。常见的类别有：（1）BFC (block formatting context) BFC是一个独立的区域，不受外部元素影响也不影响外部元素 只有块级元素参加 box会在垂直方向上一个接一个的放置 属于同一个BFC的相邻的两个box的margin会重叠 计算BFC高度时，浮动元素也参与计算 每个元素的margin box的左边与包含块的border box的左边相接处，存在浮动也是如此会生成BFC的方式： 根元素比如body float不为none position为absolute或者fixed display为inline-block、table-cell、table-caption、flex、inline-flex overflow为hidden、scroll、auto例子： https://www.jianshu.com/p/66632298e355（2）IFC (inline formatting context) 只会在一个块级元素中只包含内连级别元素时才会生成。 行内级元素（inline-level element）的display为inline、inline-block、inline-table 行内级元素生成行内盒（inline-level box），参与行内格式化上下文 行框的宽度由其内部包含的块以及浮动元素所决定 如果几个行内框无法放入一个行框内，他们可能分配在两个或者多个垂直的行框内 同一个行内框如果不能放入一个行框内，也会分配到多个垂直的行框 行框的高度可以容纳所包含的框，对齐标准为vertical-align（此处会引入下面的12问题）（3）GFC（4）FFC11、line-height: 设置行间的距离，可以设置的方式（1）number：以当前的字体属性值来设置行高(不同的浏览器默认值不同， 介于1 - 1.2之间)（2）百分比：以当前字体属性的百分比来设置（3）length：固定的值12、vertical-align: 默认值为baseline，即按照基线进行对齐，此值是和line-height相关的。（1）css中对基线的定义为：inline-block元素的基线是标准流中最后一个行框的基线， 除非这个行框没有行盒子或者本身overflow属性计算值不是visible，这种情况下，基线是该元素margin底边缘。（2）inline元素有两个高度：和字体相关的content-area，以及实际区域virtual-area（line-height）","categories":[{"name":"JS/React","slug":"JS-React","permalink":"https://qiongqiongwoo.github.io/blog/categories/JS-React/"}],"tags":[]},{"title":"compose的执行和实现方式","slug":"compose的执行和实现方式","date":"2018-12-13T07:11:11.000Z","updated":"2019-01-04T10:49:35.000Z","comments":true,"path":"2018/12/13/compose的执行和实现方式/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2018/12/13/compose%E7%9A%84%E6%89%A7%E8%A1%8C%E5%92%8C%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/","excerpt":"","text":"compose：执行一系列任务的函数 tasks = [ step1, step2, step3… ] Bulleted List 执行顺序从右到左边 第一个函数的参数可以是多个，后面的函数参数只能是一个 函数的执行是同步的 let init = (…args) =&gt; args.reduce((ele1, ele2) =&gt; ele1 + ele2, 0)let step2 = (val) =&gt; val + 2let step3 = (val) =&gt; val + 3let step4 = (val) =&gt; val + 4输出： 15 compose的实现（1）lodash中的实现 123456789101112131415161718var flow = function（funcs）&#123; Var length = funcs.length Var index = length while (index--) &#123; if (typeof funcs[index] !== &#x27;function&#x27;) &#123; throw new TypeError(&#x27;Expected a function&#x27;); &#125; &#125; Return function(…args) &#123; var index = 0 var result = length ? funcs[index].apply(this, args) : args[0] while (++index &lt; length) &#123; result = funcs[index].call(this, result) &#125; return result &#125;&#125; （2）promise实现compose 12345678910const compose = function(…funcs) &#123; let init = funcs.pop() return function(...arg) &#123; return funcs.reverse().reduce(function(sequence, func) &#123; return sequence.then(function(result) &#123; return func.call(null, result) &#125;) &#125;, Promise.resolve(init.apply(null, arg))) &#125;&#125;","categories":[{"name":"JS/React","slug":"JS-React","permalink":"https://qiongqiongwoo.github.io/blog/categories/JS-React/"}],"tags":[]},{"title":"客户端http请求的header信息","slug":"客户端http请求的header信息","date":"2018-12-12T07:41:21.000Z","updated":"2021-03-21T07:42:02.913Z","comments":true,"path":"2018/12/12/客户端http请求的header信息/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2018/12/12/%E5%AE%A2%E6%88%B7%E7%AB%AFhttp%E8%AF%B7%E6%B1%82%E7%9A%84header%E4%BF%A1%E6%81%AF/","excerpt":"","text":"1、HTTP请求方式GET：向Web服务器请求一个文件POST：向Web服务器发送数据让Web服务器进行处理PUT：向Web服务器发送数据并存储在Web服务器内部HEAD：检查一个对象是否存在DELETE：从Web服务器上删除一个文件CONNECT：对通道提供支持TRACE：跟踪到服务器的路径OPTIONS：查询Web服务器的性能请求说明：主要使用到“GET”和“POST”。实例：POST /test/tupian/cm HTTP/1.1分成三部分：（1）POST：HTTP请求方式（2）/test/tupian/cm：请求Web服务器的目录地址（或者指令）（3）HTTP/1.1: URI（Uniform Resource Identifier，统一资源标识符）及其版本 2、Host说明：请求的web服务器域名地址实例：例如web请求URL：http://zjm-forum-test10.zjm.baidu.com:8088/test/tupian/cmHost就为zjm-forum-test10.zjm.baidu.com:8088 3、User-Agent说明：HTTP客户端运行的浏览器类型的详细信息。通过该头部信息，web服务器可以判断到当前HTTP请求的客户端浏览器类别。实例：User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11 4、Accept说明：指定客户端能够接收的内容类型，内容类型中的先后次序表示客户端接收的先后次序。实例：例如：Accept:text/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,/;q=0.5备注：在Prototyp（1.5）的Ajax代码封装中，将Accept默认设置为“text/javascript, text/html, application/xml, text/xml, */*”。这是因为Ajax默认获取服务器返回的Json数据模式。在Ajax代码中，可以使用XMLHttpRequest 对象中setRequestHeader函数方法来动态设置这些Header信息。 5、Accept-Language说明：指定HTTP客户端浏览器用来展示返回信息所优先选择的语言。实例：Accept-Language: zh-cn,zh;q=0.5这里默认为中文。 6、Accept-Encoding说明：指定客户端浏览器可以支持的web服务器返回内容压缩编码类型。表示允许服务器在将输出内容发送到客户端以前进行压缩，以节约带宽。而这里设置的就是客户端浏览器所能够支持的返回压缩格式。实例：Accept-Encoding: gzip,deflate备注：其实在百度很多产品线中，apache在给客户端返回页面数据之前，将数据以gzip格式进行压缩。另外有关deflate压缩介绍：http://man.chinaunix.net/newsoft/ApacheMenual_CN_2.2new/mod/mod_deflate.html 7、Accept-Charset说明：浏览器可以接受的字符编码集。实例：Accept-Charset: gb2312,utf-8;q=0.7,*;q=0.7 8、Content-Type说明：显示此HTTP请求提交的内容类型。一般只有post提交时才需要设置该属性。实例：Content-type: application/x-www-form-urlencoded;charset:UTF-8有关Content-Type属性值可以如下两种编码类型：（1）“application/x-www-form-urlencoded”： 表单数据向服务器提交时所采用的编码类型，默认的缺省值就是“application/x-www-form-urlencoded”。 然而，在向服务器发送大量的文本、包含非ASCII字符的文本或二进制数据时这种编码方式效率很低。（2）“multipart/form-data”： 在文件上载时，所使用的编码类型应当是“multipart/form-data”，它既可以发送文本数据，也支持二进制数据上载。当提交为单单数据时，可以使用“application/x-www-form-urlencoded”；当提交的是文件时，就需要使用“multipart/form-data”编码类型。在Content-Type属性当中还是指定提交内容的charset字符编码。一般不进行设置，它只是告诉web服务器post提交的数据采用的何种字符编码。一般在开发过程，是由前端工程与后端UI工程师商量好使用什么字符编码格式来post提交的，然后后端ui工程师按照固定的字符编码来解析提交的数据。所以这里设置的charset没有多大作用。 9、Connection说明：表示是否需要持久连接。如果web服务器端看到这里的值为“Keep-Alive”，或者看到请求使用的是HTTP 1.1（HTTP 1.1默认进行持久连接），它就可以利用持久连接的优点，当页面包含多个元素时（例如Applet，图片），显著地减少下载所需要的时间。要实现这一点， web服务器需要在返回给客户端HTTP头信息中发送一个Content-Length（返回信息正文的长度）头，最简单的实现方法是：先把内容写入ByteArrayOutputStream，然 后在正式写出内容之前计算它的大小。实例：Connection: keep-alive 10、Keep-Alive说明：显示此HTTP连接的Keep-Alive时间。使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive功能避免了建立或者重新建立连接。以前HTTP请求是一站式连接，从HTTP/1.1协议之后，就有了长连接，即在规定的Keep-Alive时间内，连接是不会断开的。实例：Keep-Alive: 300 11、cookie说明：HTTP请求发送时，会把保存在该请求域名下的所有cookie值一起发送给web服务器。 12、Referer说明：包含一个URL，用户从该URL代表的页面出发访问当前请求的页面服务器端返回HTTP头部信息1、Content-Length说明：表示web服务器返回消息正文的长度2、Content-Type:说明：返回数据的类型（例如text/html文本类型）和字符编码格式。实例：Content-Type: text/html;charset=utf-83、Date说明：显示当前的时间","categories":[{"name":"网络","slug":"网络","permalink":"https://qiongqiongwoo.github.io/blog/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[]},{"title":"ES6中的proxy和应用","slug":"ES6中的proxy和应用","date":"2018-11-14T10:18:15.000Z","updated":"2019-01-04T10:49:38.000Z","comments":true,"path":"2018/11/14/ES6中的proxy和应用/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2018/11/14/ES6%E4%B8%AD%E7%9A%84proxy%E5%92%8C%E5%BA%94%E7%94%A8/","excerpt":"","text":"1、ES6 中的Proxy的使用 1234567891011121314151617var p = new Proxy(target, handler) // target为被包裹的对象，handler为处理方式handler能代理的方法有： get、set、has、constructvar target = &#123; a : ‘111’, ‘b’: ‘fasdf&#x27;&#125;Var newObj = Proxy(target, &#123; Set: function(target, key, value) &#123; console.log(key, ‘被设置。。。’) target[key] = value &#125;， get: function(target, key) &#123; console.log(key, ‘被读取。。。’) return target[key] &#125;&#125;)newObj.name = ‘fasdfdf’console.log(nameObj.name) 2、Proxy的应用（1）添加虚拟属性 1234567891011121314151617181920212223242526var person = &#123; fisrsName: &#x27;张&#x27;, lastName: &#x27;小白&#x27;&#125;;var proxyedPerson = new Proxy(person, &#123; get: function (target, key) &#123; if(key === &#x27;fullName&#x27;)&#123; return [target.fisrsName, target.lastName].join(&#x27; &#x27;); &#125; return target[key]; &#125;, set: function (target, key, value) &#123; if(key === &#x27;fullName&#x27;)&#123; var fullNameInfo = value.split(&#x27; &#x27;); target.fisrsName = fullNameInfo[0]; target.lastName = fullNameInfo[1]; &#125; else &#123; target[key] = value; &#125; &#125;&#125;);console.log(&#x27;姓:%s, 名:%s, 全名: %s&#x27;, proxyedPerson.fisrsName, proxyedPerson.lastName, proxyedPerson.fullName);// 姓:张, 名:小白, 全名: 张 小白proxyedPerson.fullName = &#x27;李 小露&#x27;;console.log(&#x27;姓:%s, 名:%s, 全名: %s&#x27;, proxyedPerson.fisrsName, proxyedPerson.lastName, proxyedPerson.fullName);// 姓:李, 名:小露, 全名: 李 小露 （2）用来做私有变量隐藏 12345678910111213141516171819202122232425262728293031var api = &#123; _secret: &#x27;xxxx&#x27;, _otherSec: &#x27;bbb&#x27;, ver: &#x27;v0.0.1&#x27;&#125;;api = new Proxy(api, &#123; get: function(target, key) &#123; // 以 _ 下划线开头的都认为是 私有的 if (key.startsWith(&#x27;_&#x27;)) &#123; console.log(&#x27;私有变量不能被访问&#x27;); return false; &#125; return target[key]; &#125;, set: function(target, key, value) &#123; if (key.startsWith(&#x27;_&#x27;)) &#123; console.log(&#x27;私有变量不能被修改&#x27;); return false; &#125; target[key] = value; &#125;, has: function(target, key) &#123; return key.startsWith(&#x27;_&#x27;) ? false : (key in target); &#125;&#125;);api._secret; // 私有变量不能被访问console.log(api.ver); // v0.0.1api._otherSec = 3; // 私有变量不能被修改console.log(&#x27;_secret&#x27; in api); // trueconsole.log(&#x27;ver&#x27; in api); // false （3）在代理中实现属性赋值的校验 1234567891011121314151617181920212223242526272829function Animal() &#123; return createValidator(this, animalValidator);&#125;var animalValidator = &#123; name: function(name) &#123; // 动物的名字必须是字符串类型的 return typeof name === &#x27;string&#x27;; &#125;&#125;;function createValidator(target, validator) &#123; return new Proxy(target, &#123; set: function(target, key, value) &#123; if (validator[key]) &#123; // 符合验证条件 if (validator[key](value)) &#123; target[key] = value; &#125; else &#123; throw Error(`Cannot set $&#123;key&#125; to $&#123;value&#125;. Invalid.`); &#125; &#125; else &#123; target[key] = value &#125; &#125; &#125;);&#125;var dog = new Animal();dog.name = &#x27;dog&#x27;;console.log(dog.name);dog.name = 123; // Uncaught Error: Cannot set name to 123. Invalid. 3、用ES5实现Proxy 1234567891011121314151617181920212223242526272829303132333435363738394041function clone(myObj)&#123; if(typeof(myObj) != &#x27;object&#x27; || myObj == null) return myObj; var newObj = new Object(); for(var i in myObj)&#123; newObj[i] = clone(myObj[i]); &#125; return newObj;&#125;/*代理实现类*/function ProxyCopy(target,handle)&#123; var targetCopy = clone(target); Object.keys(targetCopy).forEach(function(key)&#123; Object.defineProperty(targetCopy, key, &#123; get: function() &#123; return handle.get &amp;&amp; handle.get(target,key); &#125;, set: function(newVal) &#123; handle.set &amp;&amp; handle.set(); target[key] = newVal; &#125; &#125;); &#125;) return targetCopy;&#125;var person = &#123;name:&#x27;&#x27;&#125;;var personCopy = new ProxyCopy(person,&#123; get(target,key)&#123; console.log(&#x27;get方法被拦截。。。&#x27;); return target[key]; &#125;, set(target,key,value)&#123; console.log(&#x27;set方法被拦截。。。&#x27;) // return true; &#125;&#125;)person.name = &#x27;arvin&#x27;; // 未有拦截日志打出personCopy.name = &#x27;arvin&#x27;; // set方法被拦截。。。console.log(person.name); // 未有拦截日志打出console.log(personCopy.name); // get方法被拦截。。。// 这个的缺点是不能检测新添加的属性 4、以上es5中的实现利用了Object.defineProperty作用 123456789101112131415Object.defineProperty(obj, prop, descriptor) // 返回 objDescriptor是一个obj属性有：value： 属性值writable：是否可以重写enumerable: 是否可以被枚举configurable: 目标属性是否可以被删除或者再次修改除此之外，还有set和get属性，当给一个属性定义getter和setter时，这个属性称之为访问描述符， js会忽略他本身的value以及writable属性，取而代之的访问set和get函数。Object.defineProperty(obj, key, &#123; set: function()&#123; console.log(’set….&#x27;) &#125;, get: function()&#123; console.log(‘get...&#x27;) &#125;&#125;) 5、proxy在vue中的作用（实现双向绑定，即监听值的变化）","categories":[{"name":"JS/React","slug":"JS-React","permalink":"https://qiongqiongwoo.github.io/blog/categories/JS-React/"}],"tags":[]},{"title":"聚类方法","slug":"聚类方法","date":"2018-11-12T07:18:05.000Z","updated":"2021-03-22T03:03:50.874Z","comments":true,"path":"2018/11/12/聚类方法/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2018/11/12/%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95/","excerpt":"","text":"（1）文本表示的方法一般使用向量空间模型，粒度为一个词语，即将文本表示为N维空间中的一个规范化的特征矢量。（2）特征选取特征的选择分为两种，一种是每一类选取一部分词语作为特征词，二是整个系统作为一个整体来选择特征值。特征选择的几种方式：tf-idf：文档频率和反文档频率。信息增益：整个系统选择一部分特征词。它的衡量方式是有特征和无特征的情况下，整个系统的信息熵的变化。 （4）相似度计算两个向量之间计算距离的几种方式： 欧氏距离 曼哈顿距离 余弦夹角 汉明距离将一个字符串转换为另一个字符串时所作的最小替换次数。 信息熵（5）新闻聚类中采取的方式feature词表fearture词表是采用tf-idf来提取的，分别训练出了每一类的特征词以及所对应的权重，以及整个系统的特征词以及权重。聚类拿的是系统的特征词表。一篇文档的处理：首先对文档进行分词，查看是否出现特征词，计算特征词的权重，形成一个向量。tf：在当前文档中出现的次数idf：从分类特征中加载的idf12345678910111213weight = tf * log(1/idf +0.01)Topic质心的计算方式(term1......termm)page1： weight11，weight12，weight1mpage2： weight21，weight22，weight2mpagen： weightn1，weightn2，weightnm首先计算平均值：w1= ( weight11+weight21+weighn1)/nw2= (weight12+weight22+...weightn2)/nwm=（weight1m+weight2m+...weightnm）/n用阈值过滤（weight值最大不可超过阈值）归一化w1 = w1 /(w1*w1 + w2*w2 + ... wm *wm)wm = wm /(w1*w1 + w2*w2 + ... wm *wm) （6）处理的流程将每一个文档都当做一个topic；选择距离最近的两个topic；计算两个topic合并前后的凝聚力大小变化（凝聚力为topic下文档两两之间距离的均值（此距离用的是欧式距离）），变化过大则跳转到第二步，重新选择；合并两个topic，更新新的topic的质心，并重新计算该topic和其他topic之间的距离如果topic的数量少于最少的topic数目，跳出循环返回，否则跳转到第二步； （7）两个topic之间距离的计算，最大为1，最小为0 1234567topic 1: X1 = (w11, w21, ...... wm1)topic 2: X2 = (w12, w22, ...... wm2)sum = w11 *w12 + .... wm1* wm2num = (w11 &amp; w12 ? 1:0)+ ..... (wm1&amp;wm2?1:0）avg = sum /numdis = (w11 &amp; w12)?(w11*w12-avg)*(w11*w12-avg):0 + ...... (wm1 &amp; wm2)?(wm1*wm2-avg)*(wm1*wm2-avg):0dis = dis / num （8）聚类的结果调整同一个网站发布了大量同一个类的文章，比如某一时间段健康频道下会出现大量的关于某一疾病的说明、治疗方式等，这个可以通过url过滤掉。同一个网站不同频道发布的也算。影响聚类结果调整的参数：topic之间的相似度、topic的凝聚力、特征选取的多少topic的排序：按照转载量，即每个topic下的文章的数量（焦点新闻）（9）KNN算法接受一个未标记的数据集，然后将数据聚类成不同的组。首先随机的选取K个点，作为聚类的中心。对于每一篇文档计算与聚类中心的距离，将其归类为距离最小的那一组中，并更新该组的聚类中心。直到中心点不再变化。","categories":[{"name":"NLP","slug":"NLP","permalink":"https://qiongqiongwoo.github.io/blog/categories/NLP/"}],"tags":[]},{"title":"SVM分类","slug":"SVM","date":"2018-11-07T08:17:58.000Z","updated":"2021-05-06T07:35:52.891Z","comments":true,"path":"2018/11/07/SVM/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2018/11/07/SVM/","excerpt":"","text":"svm的作用SVM是一个二分类的模型，优化目标是找到集合间隔最大的分离超平面；对于给定的训练样本集D={(x1,y1), (x2,y2),… (xn,yn)}，yi属于{-1，+1}，希望能找出一个超平面，把不同类别的数据集分开，对于线性可分的数据集来说，这样的超平面有无穷多个，而最优的超平面即是分隔间距最大的中间那个超平面。 SVM的三类问题 训练数据是线性可分：通过硬间隔最大化，学习一个线性分类器。 训练数据近似线性可分：通过引入松弛变量（作用是允许一些样本点出错） 训练数据不可分时，引入核函数，学习非线性支持向量机；核函数数学上已经证明，如果原始空间是有限维，则一定存在一个高维度空间使得高为特征空间使样本可分；libSVM库中的核函数有：（libsvm库中有svmTrain和svmPredict分别来做训练和预测） 线性核函数: 一般用于线性可分的情况，参数少，训练快； 多项式核函数； RBF核函数：高斯核，用于线性不可分的情况，参数多； sigmoid tanh核函数； precomputed： 用户自定义的核函数；一般建议用RBF核函数；特征选取svm模型训练的前提是特征的选取、表示以及模型的训练。特征选取后，将文本映射为向量，进而表示为高纬空间的一个点，调用分类器，判断其类别。 tf * idf方法：tf表示该词在文档中的词频，idf，出现的文档数据。 信息增益的方法：特征能够为整个系统所带来的信息量，带来的信息量越大，信息增益越大；","categories":[{"name":"NLP","slug":"NLP","permalink":"https://qiongqiongwoo.github.io/blog/categories/NLP/"}],"tags":[]},{"title":"webpack","slug":"webpack","date":"2018-11-07T06:42:44.000Z","updated":"2021-03-22T03:08:35.405Z","comments":true,"path":"2018/11/07/webpack/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2018/11/07/webpack/","excerpt":"","text":"概念webpack把项目当作一个整体，通过一个给定的的主文件，webpack将从这个文件开始找到你的项目的所有依赖文件，使用loaders处理它们，最后打包成一个或多个浏览器可识别的js文件。install 首先添加我们即将使用的包： 1npm install webpack webpack-dev-server --save-dev webpack是我们需要的模块打包机，webpack-dev-server用来创建本地服务器，监听你的代码修改，并自动刷新修改后的结果。这些是有关devServer的配置 123456789contentBase, // 为文件提供本地服务器port, // 监听端口，默认8080inline, // 设置为true,源文件发生改变自动刷新页面historyApiFallback // 依赖HTML5 history API,如果设置为true,所有的页面跳转指向index.htmldevServer:&#123; contentBase: &#x27;./src&#x27; // 本地服务器所加载的页面所在的目录 historyApiFallback: true, // 不跳转 inline: true // 实时刷新&#125; 然后我们在根目录下创建一个’webpack.config.js’，在’package.json’添加两个命令用于本地开发和生产发布 1234&quot;scripts&quot;: &#123; &quot;start&quot;: &quot;webpack-dev-server&quot;, &quot;build&quot;: &quot;webpack&quot;&#125; 在使用webpack命令的时候，他将接受webpack的配置文件，除非我们使用其他的操作 entry: 用来写入口文件，它将是整个依赖关系的根 123var baseConfig = &#123; entry: &#x27;./src/index.js&#x27;&#125; 当我们需要多个入口文件的时候，可以把entry写成一个对象 12345var baseConfig = &#123; entry: &#123; main: &#x27;./src/index.js&#x27; &#125; &#125; 我建议使用后面一种方法，因为他的规模会随你的项目增大而变得繁琐 output: 即使入口文件有多个，但是只有一个输出配置 1234567891011var path = require(&#x27;path&#x27;) var baseConfig = &#123; entry: &#123; main: &#x27;./src/index.js&#x27; &#125;, output: &#123; filename: &#x27;main.js&#x27;, path: path.resolve(&#x27;./build&#x27;) &#125; &#125;module.exports = baseConfig 如果你定义的入口文件有多个，那么我们需要使用占位符来确保输出文件的唯一性 1234output: &#123; filename: &#x27;[name].js&#x27;, path: path.resolve(&#x27;./build&#x27;) &#125; 如今这么少的配置，就能够让你运行一个服务器并在本地使用命令npm start或者npm run build来打包我们的代码进行发布Loader loader的作用：1、实现对不同格式的文件的处理，比如说将scss转换为css，或者typescript转化为js2、转换这些文件，从而使其能够被添加到依赖图中loader是webpack最重要的部分之一，通过使用不同的Loader，我们能够调用外部的脚本或者工具，实现对不同格式文件的处理，loader需要在webpack.config.js里边单独用module进行配置，配置如下： test: 匹配所处理文件的扩展名的正则表达式（必须）loader: loader的名称（必须）include/exclude: 手动添加处理的文件，屏蔽不需要处理的文件（可选）query: 为loaders提供额外的设置选项 123456789101112131415ex:var baseConfig = &#123; // ... module: &#123; rules: [ &#123; test: /*匹配文件后缀名的正则*/, use: [ loader: /*loader名字*/, query: /*额外配置*/ ] &#125; ] &#125;&#125; 要是loader工作，我们需要一个正则表达式来标识我们要修改的文件，然后有一个数组表示我们表示我们即将使用的Loader,当然我们需要的loader需要通过npm 进行安装。例如我们需要解析less的文件，那么webpack.config.js的配置如下： 123456789101112131415161718192021222324252627var baseConfig = &#123; entry: &#123; main: &#x27;./src/index.js&#x27; &#125;, output: &#123; filename: &#x27;[name].js&#x27;, path: path.resolve(&#x27;./build&#x27;) &#125;, devServer: &#123; contentBase: &#x27;./src&#x27;, historyApiFallBack: true, inline: true &#125;, module: &#123; rules: [ &#123; test: /\\.less$/, use: [ &#123;loader: &#x27;style-loader&#x27;&#125;, &#123;loader: &#x27;css-loader&#x27;&#125;, &#123;loader: &#x27;less-loader&#x27;&#125; ], exclude: /node_modules/ &#125; ] &#125;&#125; 这里介绍几个常用的loader：babel-loader： 让下一代的js文件转换成现代浏览器能够支持的JS文件。babel有些复杂，所以大多数都会新建一个.babelrc进行配置css-loader,style-loader:两个建议配合使用，用来解析css文件，能够解释@import,url()如果需要解析less就在后面加一个less-loaderfile-loader: 生成的文件名就是文件内容的MD5哈希值并会保留所引用资源的原始扩展名url-loader: 功能类似 file-loader,但是文件大小低于指定的限制时，可以返回一个DataURL事实上，在使用less,scss,stylus这些的时候，npm会提示你差什么插件，差什么，你就安上就行了 Pluginsplugins和loader很容易搞混，说都是外部引用有什么区别呢？ 事实上他们是两个完全不同的东西。这么说loaders负责的是处理源文件的如css、jsx，一次处理一个文件。而plugins并不是直接操作单个文件，它直接对整个构建过程起作用下面列举了一些我们常用的plugins和他的用法ExtractTextWebpackPlugin: 它会将入口中引用css文件，都打包都独立的css文件中，而不是内嵌在js打包文件中。下面是他的应用 1234567891011121314151617181920var ExtractTextPlugin = require(&#x27;extract-text-webpack-plugin&#x27;)var lessRules = &#123; use: [ &#123;loader: &#x27;css-loader&#x27;&#125;, &#123;loader: &#x27;less-loader&#x27;&#125; ]&#125;var baseConfig = &#123; // ... module: &#123; rules: [ // ... &#123;test: /\\.less$/, use: ExtractTextPlugin.extract(lessRules)&#125; ] &#125;, plugins: [ new ExtractTextPlugin(&#x27;main.css&#x27;) ]&#125; HtmlWebpackPlugin:作用： 依据一个简单的index.html模版，生成一个自动引用你打包后的js文件的新index.html 1234567var HTMLWebpackPlugin = require(&#x27;html-webpack-plugin&#x27;)var baseConfig = &#123; // ... plugins: [ new HTMLWebpackPlugin() ]&#125; HotModuleReplacementPlugin: 它允许你在修改组件代码时，自动刷新实时预览修改后的结果注意永远不要在生产环境中使用HMR。这儿说一下一般情况分为开发环境，测试环境，生产环境。用法如 new webpack.HotModuleReplacementPlugin()webapck.config.js的全部内容 const webpack = require(“webpack”)const HtmlWebpackPlugin = require(“html-webpack-plugin”)var ExtractTextPlugin = require(‘extract-text-webpack-plugin’)var lessRules = { use: [ {loader: ‘css-loader’}, {loader: ‘less-loader’} ]}module.exports = { entry: { main: ‘./src/index.js’ }, output: { filename: ‘[name].js’, path: path.resolve(‘./build’) }, devServer: { contentBase: ‘/src’, historyApiFallback: true, inline: true, hot: true }, module: { rules: [ {test: /.less$/, use: ExtractTextPlugin.extract(lessRules)} ] }, plugins: [ new ExtractTextPlugin(‘main.css’) ]}产品阶段的构建 目前为止，在开发阶段的东西我们已经基本完成了。但是在产品阶段，还需要对资源进行别的处理，例如压缩，优化，缓存，分离css和js。首先我们来定义产品环境 var ENV = process.env.NODE_ENVvar baseConfig = { // … plugins: [ new webpack.DefinePlugin({ ‘process.env.NODE_ENV’: JSON.stringify(ENV) }) ]}然后还需要修改我们的script命令 “scripts”: { “start”: “NODE_ENV=development webpack-dev-server”, “build”: “NODE_ENV=production webpack”} process.env.NODE_ENV 将被一个字符串替代，它运行压缩器排除那些不可到达的开发代码分支。当你引入那些不会进行生产的代码，下面这个代码将非常有用。 if (process.env.NODE_ENV === ‘development’) { console.warn(‘这个警告会在生产阶段消失’)}优化插件 下面介绍几个插件用来优化代码OccurenceOrderPlugin: 为组件分配ID,通过这个插件webpack可以分析和优先考虑使用最多 的模块，然后为他们分配最小的IDUglifyJsPlugin: 压缩代码下面是他们的使用方法var baseConfig = { // … new webpack.optimize.OccurenceOrderPlugin() new webpack.optimize.UglifyJsPlugin()}然后在我们使用npm run build会发现代码是压缩的","categories":[{"name":"JS/React","slug":"JS-React","permalink":"https://qiongqiongwoo.github.io/blog/categories/JS-React/"}],"tags":[]},{"title":"MongoDB","slug":"MongoDB","date":"2018-11-04T10:08:15.000Z","updated":"2019-01-04T10:49:47.000Z","comments":true,"path":"2018/11/04/MongoDB/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2018/11/04/MongoDB/","excerpt":"","text":"NoSql非关系型数据库，常见的集中NoSql数据库有MongoDB。提到数据库不可避免的提到CAP和ACID。ACID是关系型数据库CAP三要素只可以同时实现两点，不能兼顾三者，这三者是指：一致性consistency：什么时候访问的数据都是一致的。使用Nosql必须习惯于它的弱一致性。可用性availability：一般牺牲一致性来换取高可用性。分区容忍性partition tolerance：这一点是基本要求 （1）mongoDB的特点Mongodb是时下流行的NoSql数据库，特点是高性能、开源、无模式。特点有： 面向集合存储，易存储对象类型的数据。 模式自由。 支持动态查询。 支持完全索引，包含内部对象。 支持查询。 支持复制和故障恢复。 使用高效的二进制数据存储，包括大型对象（如视频等）。 自动处理碎片，以支持云计算层次的扩展性 支持Python，PHP，Ruby，Java，C，C#，Javascript，Perl及C++语言的驱动程序，社区中也提供了对Erlang及.NET等平台的驱动程序。 文件存储格式为BSON（一种JSON的扩展）。 可通过网络访问。 （2）MongoDB内部存储空间的分配首先：mongoDB中数据是以collection为单位的，其实一个collection只存储一个名字空间（包括大小，块数，第一个块的位置，最后一个块的位置，被删除的块的信息，以及索引信息）。一个collection中的数据被划分为一个个的extent，extent之间是双向链表组织的。extent中保存的信息有：自己的位置，上一个extent以及下一个extent的位置，第一条以及最后一条doc的位置。doc之间也是用双向链表进行组织的。doc中存储的是一条条的数据。 （3）索引的组织数据库索引的方式有两种，一种是hash索引一种是Btree索引。hash索引不支持对部分索引键查询，以为它是对所有的字段组合取的hash。hash索引无法避免表扫描，因为有值相等的情况。hash索引遇到大量hash值相等的情况下，效率不比Btree高。hash索引只能满足相等，大于，小于的查询，不能进行范围的查询。 （4）内存映射MMAPMongoDB是通过内存映射的方式提高性能的，因此不要在32位的机器上使用mongodb。因为32位的机器的寻址空间为4G，其中1G被内核使用，0.5G被mongoDB的栈使用，因此数据空间只有2.5G。 （5）master-slaver方式Mongodb(M)表示主节点，Mongodb(S)表示备节点，Mongodb(A)表示仲裁节点。主备节点存储数据，仲裁节点不存储数据。客户端同时连接主节点与备节点，不连接仲裁节点。默认设置下，主节点提供所有增删查改服务，备节点不提供任何服务。但是可以通过设置使备节点提供查询服务，这样就可以减少主节点的压力，当客户端进行数据查询时，请求自动转到备节点上。这个设置叫做Read Preference Modes。仲裁节点是一种特殊的节点，它本身并没有不存储数据，主要的作用是决定哪一个备节点在主节点挂掉之后提升为主节点，所以客户端不需要连接此节点。这里虽然只有一个备节点，但是仍然需要一个仲裁节点来提升备节点级别。master——slaver同步的方式有：异步复制、强同步复制、以及半同步方式。异步复制是指master更新后，直接更新自己log，slaver自己同步，这种情况会出现丢信息的情况。强同步复制是指master先同步信息到slaver，全部同步成功后，再更新自己。半同步方式是指，只要成功同步的salver数目大于一个给定的值K后，master就可以同步信息到自己。 （6）replica sets红色箭头表示写操作可以写到Primary上，然后异步同步到多个Secondary上。蓝色箭头表示读操作可以从Primary或Secondary任意一个中读取。各个Primary与Secondary之间一直保持心跳同步检测，用于判断Replica Sets的状态。（7）chunkMongoDB的分片是指定一个分片key来进行，数据按范围分成不同的chunk，每个chunk的大小有限制。有多个分片节点保存这些chunk，每个节点保存一部分的chunk。每一个分片节点都是一个Replica Sets，这样保证数据的安全性。当一个chunk超过其限制的最大体积时，会分裂成两个小的chunk。当chunk在分片节点中分布不均衡时，会引发chunk迁移操作(move chunk)。 （8）sharding（分片）sharding是将一个大数据库按照一定规则拆分成多个小数据库的一门技术。常用的sharding方案有以下几种，按功能划分（垂直切分）将不同功能相关的表放到不同的数据库中，譬如将用户管理相关表放到shard 1上，将blog相关表放到shard 2上。。。这样做的好处是非常直观，当需要用户列表时，我就到shard 1上获取。。。。这样也有一个问题，当某一部分的功能其数据量或性能要求超出了可控的范围，我们就需要继续对其进行深入的sharding。按表中某一字段值的范围划分（水平切分）当伴随着某一个表的数据量越来越大，以至于不能承受的时候，就需要对她进行进一步的切分。一种选择是根据key的范围来做切分，譬如userID为1-10000的放到shard 10上，userID为10000到20000的放到shanrd 11上。。。这样的扩展就是可预见的。另一种是根据某一字段值得来划分，譬如根据用户名的首字母，如果是a-d，就属于shard 20，e-h就属于shard 21。。。这样做也存在不均衡性，当某个范围超出了shard所能承受的范围就需要继续切分。还有按日期切分等等，基于hash的切分类似于memcached的key hash算法，一开始确定切分数据库的个数，通过hash取模来决定使用哪台shard。这种方法能够平均的来分配数据，但是伴随着数据量的增大，需要进行扩展的时候，这种方式无法做到在线扩容。每增加节点的时候，就需要对hash算法重新运算，数据需要重新割接。基于路由表的切分前面的几种方式都是跟据应用的数据来决定操作的shard，基于路由表的切分是一种更加松散的方法。它单独维护一张路由表，根据用户的某一属性来查找路由表决定使用哪个shard，这种方式是一种更加通用的方案。譬如我们在系统中维护一张表-（用户所属省-〉shard），这样每个用户我们知道是哪个省的，去路由表查找，就知道它所在的shard。因为每次数据操作的时候都需要进行路由的查找，所以将这些内容存储到一台独立cache上是一个非常好的方式，譬如memcached。这种切分的方式同时也带来了另一个好处，当需要增加shard的时候，可以在不影响在线应用的情况下来执行，当然这也跟应用程序的架构设计相关，你的设计必须适用这种增加。虽然应用sharding会带来显而易见的好处，但是它也有一些固有的问题需要我们了解，这些问题大致分成以下几类，1。shard的扩容当当前的shard已经不能适用当前的应用需求时，就需要对shard数据库进行扩容，增加shard意味着需要对原有的shard数据进行迁移，这个过程是非常复杂，而且可能会导致数据的不一致（一边写、一边迁移）或者其他应用问题，因此扩容一般选择在凌晨等时间进行。2。联合多个shard的表数据查询这个是shard固有的问题，当遇到这样的问题时，你需要获取各个shard的数据，然后对这些数据进行汇总，很多时候因为现在的网络速度比较发达这个问题可以几乎被忽略掉。但是如果要进行数据的分析或挖掘，shard就会存在问题，通常面对这种对于数据要求不是那么实时的情况下，可以采用将shard数据同步到汇总数据库的方案，olap可以在这台汇总数据库上进行，这就需要在每台shard上进行数据的定时同步，这增加了程序的复杂性；如果要求实时的情况下，采用sharding方案会是一个毁灭性打击。3。其他我们现在做的系统就是采用的按照路由表切分的sharding方案，而且我们需要要求不是那么实时的汇总数据以提供数据的分析和挖掘，同时我们的基础数据都是在汇总数据库中进行管理，通过oracle的高级复制到shard节点上。在shard数据库向汇总数据库同步数据的时候，我们是通过oracle数据库的存储过程实现的，这种架构方式导致了数据库非常的复杂，同时还存在了一些其他问题，譬如同步会无缘无故的断掉。。。这就需要采用一些其他手段来维持数据的延迟一致性。(9) mongosmongos是路由节点，客户端通过mongos来进行读写。config服务器保存了两个映射关系，一个是key值的区间对应哪一个chunk的映射关系，另一个是chunk存在哪一个分片节点的映射关系。路由节点通过config服务器获取数据信息，通过这些信息，找到真正存放数据的分片节点进行对应操作。路由节点还会在写操作时判断当前chunk是否超出限定大小。如果超出，就分列成两个chunk。对于按分片key进行的查询和update操作来说，路由节点会查到具体的chunk然后再进行相关的工作。对于不按分片key进行的查询和update操作来说，mongos会对所有下属节点发送请求然后再对返回结果进行合并。（10）具体的例子：(11) mongodb的安全权限设置mongodb默认是没有用户名和口令的,启动后,可以直接用mongoDB连接,并且对所有的库具有root权限,为了安全,必须给其设置用户名和口令.只需要再启动的时候,指定auth参数.就可以阻止客户端的访问和连接,如下 123456789101112131415161718eg.&gt;mongod -auth --dbpath=../data --logpath=../logs/mongodb.logs想要登录验证模块生效,必须在admin库中添加一个用户,同时要指定auth参数.D:\\program files\\mongo\\bin&gt;mongoMongoDB shell version: 1.8.1connecting to: test]]&gt; use adminswitched to db admin&gt; db.addUser(&quot;root&quot;,&quot;root123&quot;);&#123; &quot;user&quot; : &quot;root&quot;, &quot;readOnly&quot; : false, &quot;pwd&quot; : &quot;81c5bca573e01b632d18a459c6cec418&quot;&#125;&gt; db.auth(&quot;root&quot;,&quot;root123&quot;);1&gt; 此时建立了系统root用户.也可以对某个特定的数据库设置用户,这样权限的细粒度划分,也方便进行用户管理.注意:建立指定权限的用户只能用系统用户来操作.","categories":[{"name":"DataBase","slug":"DataBase","permalink":"https://qiongqiongwoo.github.io/blog/categories/DataBase/"}],"tags":[]},{"title":"JS中class深入","slug":"JS中class深入","date":"2018-10-11T10:24:27.000Z","updated":"2019-01-04T10:49:41.000Z","comments":true,"path":"2018/10/11/JS中class深入/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2018/10/11/JS%E4%B8%ADclass%E6%B7%B1%E5%85%A5/","excerpt":"","text":"1、es6中的class（1）es6中定义一个class的实例 1234567891011121314151617181920class Person&#123; constructor(name)&#123; this.name = name &#125; Hello2 = () =&gt; &#123; // console.log(‘hello 2 是原型方法，每个实例对象都包含一个，而不是放在__proto——中的&#x27;) &#125; hello()&#123; console.log(&#x27;my name is&#x27;+this.name) &#125;&#125;var xiaoming = new Person(&#x27;xiaoming&#x27;)xiaoming.hello() // my name is xiaomingvar lisi = new Person(‘lisi&#x27;)lisi.hello() // my name is lisitypeof Person // functionxiaoming.__proto__ === lisi.__proto__ // truexiaoming.__proto__ === Person.prototype // trueXiaoming.hello = Person.prototype.hello // true Es5中定义的类中的方法和es6中定义的类中的方法的区别： Es5中定义的方法是可以枚举的Object.keys(Person1.__proto) : [‘hello’], 而es6中的不可以枚举 es6中的方法定义时不要带function且方法名可以用参数 Es6中的class和5中的区别并不大，只是一个语法糖（便于书写的东西） 在ES6里如果要使用super使用父类的同名方法，父类的方法不能设置为实例方法（2）Person结构（3）es5中创建一个类的方式1234567891011121314function Person(name) &#123; // 以function的形式创建类 this.name = name&#125;Person.prototype.describe = function()&#123; console.log(&#x27;my name is&#x27;+this.name)&#125;var jany = new Person(&#x27;jany&#x27;)jany.__proto__ === Person.prototype // truejany.describe()function superMan(name,age)&#123; Person.call(this,name) // Person.apply(this, args) this.age = age&#125;superMan.prototype = Object.create(Person.prototype) // Objcet.create是用创建一个新的obj，并将obj.__proto__指向当前的obj。 以上代码执行的过程为 首先给Person.prototype属性所指的原型对象上添加一个方法describe 在使用new关键字创建对象时，会默认给当前对象添加一个原型属性__proto__并指向Person.prototype 在读取describe时候，jany本身并不包含该方法，于是到原型链上去查找。（4）js中object中包含两部分：普通属性和原型属性__proto__，从结构中可以看到__proto__仍然是一个对象，即原型对象。而prototype是function独有的属性，再调用new时用来生成__proto__。constructor是比较特殊的属性，用来指向类本身。（5）object function之间的关系图(Object和Function互为实例)（6）es6中extends的实现123456789101112131415161718192021class Foo &#123; constructor(who)&#123; this.me = who; &#125; identify()&#123; return &quot;I am &quot; + this.me; &#125;&#125;class Bar extends Foo &#123; constructor(who)&#123; // super() 指的是调用父类 （super关键字指代父类的实例即this对象） // 调用的同时，会绑定 this 。 // 如：Foo.call(this, who) super(who); &#125; speak() &#123; alert( &quot;Hello, &quot; + this.identify() + &quot;.&quot; ); &#125;&#125;var b1 = new Bar( &quot;b1&quot; );b1.speak(); Foo和Bar的关系图如下（可以看到Bar的prototype是Foo的一个实例，在Bar的prototype中找不到的属性到Foo中去找）（7）instance of的原理：检测左侧的__proto__原型链上是不是存在右侧的prototype1L instanceof R // L.__proto__.__proto__….. === R.prototype （8） es6之前没有类的概念，为了实现继承需要采用一些手段， 以下描述了类继承的一些进展1、通过原型链继承 - js原型链条的特性导致如果一个object中找不到当前属性可以按照prototype往上找，因此为了实现继承，可以将child的prototype设置为parent的一个实例。12345678910111213141516function Parent(name) &#123; this.name = name;&#125;Parent.prototype.sayName = function()&#123; console.log(‘parent name’, this.name)&#125;function Child(name) &#123; this.name = name;&#125;Child.prototype = new Parent(‘zhang’);Child.prototype.constructor = Child;Child.prototype.sayName = function() &#123; console.log(‘child name’, this.name)&#125;var child = new Child(’son’);child.sayName(); // parent个人的一些属性对于child的多个实体来说是一份 2、为了解决上面的属性不能继承的问题，可以利用类继承的方式1234567891011121314function Parent(name) &#123; this.name = name;console.log(&#x27;set parent name&#x27;, name);&#125;Parent.prototype.sayName = function() &#123; console.log(&#x27;parent name:&#x27;, this.name);&#125;Parent.prototype.doSomthing = function() &#123; console.log(&#x27;parent do something!&#x27;);&#125;function Child(name, parentName) &#123; Parent.call(this, parentName); this.child_name = name;&#125;var child = new Child(&#x27;son’); child有两个属性分别为name和child_name，但是方法确继承不下来了。 3、将上面属性继承和方法继承组合在一起 12345678910111213141516function Parent(name) &#123; this.parent_name = name;&#125;Parent.prototype.sayName = function()&#123; console.log(&#x27;parent name&#x27;, this.name)&#125;function Child(chiild_name, parent_name) &#123; Parent.call(this, parent_name) this.child_name = chiild_name;&#125;Child.prototype = new Parent(&#x27;zhang&#x27;);Child.prototype.constructor = Child;Child.prototype.sayName = function() &#123; console.log(&#x27;child name&#x27;, this.name)&#125;var child = new Child(&#x27;son&#x27;, &#x27;li&#x27;); 此时既做到了属性继承也做到了方法继承， child的结构为： 4、上述两次冗余的地方目的是为了将子类的prototype的__proto__指向父类，因此可以创建一个空函数， 空函数的prototype指向parent的prototype，而子类为此空函数的子类即可。 1Child.prototype = new Parent(&#x27;zhang’); 可以升级为 child.prototype = Object.create(Parent.prototype) 阿拉蕾的class实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159// The base Class implementation.function Class(o) &#123; //这个判断用来支持 将一个已有普通类转换成 阿拉蕾的类 if (!(this instanceof Class) &amp;&amp; isFunction(o)) &#123; //原理是给这个函数增加extend，implement方法 return classify(o) &#125;&#125;//用于创建一个类，第一个参数可选，可以直接创建时就指定继承的父类。//第二个参数也可选，用来表明需要混入的类属性。//有三个特殊的属性为Extends,Implements,Statics.分别代表要继承的父类，需要混入原型的东西，还有静态属性。Class.create = function(parent, properties) &#123; //创建一个类时可以不指定要继承的父类。直接传入属性对象。 if (!isFunction(parent)) &#123; properties = parent parent = null &#125; properties || (properties = &#123;&#125;) //没有指定父类的话 就查看有没有Extends特殊属性，都没有的话就用Class作为父类 parent || (parent = properties.Extends || Class) properties.Extends = parent // 子类构造函数的定义 function SubClass() &#123; // 自动帮忙调用父类的构造函数 parent.apply(this, arguments) // Only call initialize in self constructor. //真正的构造函数放在initialize里面 if (this.constructor === SubClass &amp;&amp; this.initialize) &#123; this.initialize.apply(this, arguments) &#125; &#125; // Inherit class (static) properties from parent. // parent为Class就没必要混入 if (parent !== Class) &#123; //将父类里面的属性都混入到子类里面这边主要是静态属性 mix(SubClass, parent, parent.StaticsWhiteList) &#125; // Add instance properties to the subclass. // 调用implement将自定义的属性混入到子类原型里面。遇到特殊值会单独处理，真正的继承也是发生在这里面 //这边把属性也都弄到了原型上，因为这边每次create或者extend都会生成一个新的SubClass。 //所以倒也不会发生属性公用的问题。但是总感觉不大好 implement.call(SubClass, properties) // Make subclass extendable. //给生成的子类增加extend和implement方法，可以在类定义完后，再去继承，去混入其他属性。 return classify(SubClass)&#125;// Create a sub Class based on `Class`.Class.extend = function(properties) &#123; properties || (properties = &#123;&#125;) //定义继承的对象是自己 properties.Extends = this //调用Class.create实现继承的流程 return Class.create(properties)&#125;// 这里定义了一些特殊的属性，阿拉蕾遍历时发现key是这里面的一个时，会调用这里面的方法处理。Class.Mutators = &#123; //这个定义了继承的真正操作代码。 &#x27;Extends&#x27;: function(parent) &#123; //这边的this指向子类 var existed = this.prototype //生成一个中介原型，就是之前我们实现的objectCreat var proto = createProto(parent.prototype) //将子类原型有的方法混入到新的中介原型上 mix(proto, existed) // 改变构造函数指向子类 proto.constructor = this // 改变原型 完成继承 this.prototype = proto //为子类增加superclass属性，这样可以调用父类原型的方法。 this.superclass = parent.prototype &#125;, //这个有点类似组合的概念，支持数组。将其他类的属性混入到子类原型上 &#x27;Implements&#x27;: function(items) &#123; isArray(items) || (items = [items]) var proto = this.prototype, item while (item = items.shift()) &#123; mix(proto, item.prototype || item) &#125; &#125;, //传入静态属性 &#x27;Statics&#x27;: function(staticProperties) &#123; mix(this, staticProperties) &#125;&#125;// Shared empty constructor function to aid in prototype-chain creation.function Ctor() &#123;&#125;// 用于在类定义之后，往类里面添加方法。提供了之后修改类的可能。// 类似上面defjs实现的open函数。function implement(properties) &#123; var key, value for (key in properties) &#123; value = properties[key] //发现属性是特殊的值时，调用对应的处理函数处理 if (Class.Mutators.hasOwnProperty(key)) &#123; Class.Mutators[key].call(this, value) &#125; else &#123; this.prototype[key] = value &#125; &#125;&#125;//给一个普通的函数 增加extend和implement方法。function classify(cls) &#123; cls.extend = Class.extend cls.implement = implement return cls&#125;//用来支持 commonjs的模块规范。module.exports = Class// 使用// Create a new Class.// var SuperPig = Class.create(&#123;// Extends: Animal,// Implements: Flyable,// initialize: function() &#123;// SuperPig.superclass.initialize.apply(this, arguments)// &#125;,// Statics: &#123;// COLOR: &#x27;red&#x27;// &#125;// &#125;)//// 这个方法就是我们之前实现的objectCreat，用来使用一个中介者来处理原型的问题，// 当浏览器支持`__proto__`时可以直接使用。// 否则新建一个空函数再将父类的原型赋值给这个空函数，返回这个空函数的实例var createProto = Object.__proto__ ? function(proto) &#123; return &#123; __proto__: proto &#125; &#125; : function(proto) &#123; Ctor.prototype = proto return new Ctor() &#125;// Helpers 下面都是些辅助方法，很简单就不说了function mix(r, s, wl) &#123; // Copy &quot;all&quot; properties including inherited ones. for (var p in s) &#123; //过滤掉原型链上面的属性 if (s.hasOwnProperty(p)) &#123; if (wl &amp;&amp; indexOf(wl, p) === -1) continue // 在 iPhone 1 代等设备的 Safari 中，prototype 也会被枚举出来，需排除 if (p !== &#x27;prototype&#x27;) &#123; r[p] = s[p] &#125; &#125; &#125;&#125;","categories":[{"name":"JS/React","slug":"JS-React","permalink":"https://qiongqiongwoo.github.io/blog/categories/JS-React/"}],"tags":[]},{"title":"缓存架构","slug":"缓存架构","date":"2018-01-08T02:49:25.000Z","updated":"2021-03-26T08:17:58.749Z","comments":true,"path":"2018/01/08/缓存架构/","link":"","permalink":"https://qiongqiongwoo.github.io/blog/2018/01/08/%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84/","excerpt":"","text":"商品详情页缓存架构图：具体流程为： 用户访问nginx，会先从 nginx 的本地缓存获取数据渲染后返回，这个速度很快，因为全是内存操作。 nginx缓存数据一般是主动过期，比如10分钟后自动过期。nginx缓存抗的是热数据的高并发访问。 如果nginx本地缓存失效，会从 redis 中获取数据回来并缓存上。 假如 redis 中的数据失效，会从缓存数据生产服务中获取数据并缓存上。redis抗的是高频的离散访问，能缓存1T+的数据，qps可以达到几十万。（利用redis cluster的多master写入）redis缓存过期采用LRU策略； 缓存数据生产服务，本地也有一个缓存，比如用的是 ehcache 他们通过队列监听商品修改等事件，让自己的缓存数据及时更新。（tomcat jvm堆内存缓存） 其他服务，商品、店铺等服务能获取到商品的修改事件等，及时往 mq 中发出商品的修改事件， 并提供商品原始数据的查询。这里可能是直接从 mysql 库中查询的。 这样一来，在缓存上其实就挡掉了很多数据，一层一层的挡并发。 缓存淘汰策略最常用的缓存淘汰策略： FIFO：先进先出，可以用链表实现，链表尾部进入，头部出。 LRU： 最近最少使用的；用链表实现，每次被访问的直接移动到链表头；从链表尾部清理； LFU：最不经常使用；可以使用有序链表实现，链表的值保存访问次数，每次从尾部移除数据. 缓存更新策略数据发生变动时，需要先删除缓存，然后再更新mysql中的数据。 此处是删除缓存而不是更新缓存，主动更新缓存的代价很高，一般不这么干。 顺序是先删除缓存，再更新数据库，因为反过来如果更新数据库成功，删除缓存失败，会有不一致的情况； 在已经删除缓存，但更新数据库还没有完成，此时如果有请求过来，会将旧的数据更新到缓存；这样会导致数据库和缓存数据的不一致；解决方式：将修改数据库和更新缓存做成异步串行。（虽然有阻塞的风险，但是大概率是读请求多，写请求少） 缓存需要保证同一个商品的读写操作路由到同一台机器中，否则缓存就失去意义。 缓存策略在高并发下，需要严格的压测和计算； 缓存维度化比如商品详情页，库存的更新频率和商品属性的更新频率是不一致的，如果所有信息都放到同一个value中，会导致缓存频繁失效。解决方式就是缓存维度化，只更新维度信息。 缓存穿透缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题。解决方法： 不存在的仍然以key-null的形式存储到缓存，但过期时间要设置的足够短。 将存在的数据存到一个很大的bitmap或者bloom Filter中，通过bitmap来判断是否存在，然后这样可以降低对mysql的访问； 缓存击穿缓存击穿是指数据库中有而缓存中不存的key，持续的大并发会击破缓存，直接请求数据。比如key不在缓存，某一时刻大量的请求key直接击穿缓存到达数据库。解决方法： 设置热点数据常驻缓存不失效； 通过设置互斥锁（采用SETNX（set if not exists）来设置另一个短期key来锁住当前key的访问，访问结束再删除该短期key)来减缓对缓存数据的大流量； 缓存雪崩缓存中的大批量的key过期，所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃。解决办法： 缓存中数据过期时间设置为随机，防止同一时间大批量的key同时到期； 如果是分布式的，将热点数据分步到不同的数据库。 牺牲用户体验，做限流、降级 添加预警机制 缓存预热系统新上线或者是缓存崩掉重启后需要先预热缓存数据，否则容易造成mysql的压力过大；解决思路： 直接写个缓存刷新页面，上线时手工操作下； 数据量不大，可以在项目启动的时候自动进行加载； 日常例行统计数据访问记录，定时刷新缓存； 缓存降级缓存失效或者挂掉的情况下，直接返回默认数据，也不去请求数据库。通过提供有损服务来降低对整个业务的影响。","categories":[{"name":"后端","slug":"后端","permalink":"https://qiongqiongwoo.github.io/blog/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[]}]}